UID,abstract
Q2-16,"GPT-3.5/4 や LLaMA などの大規模言語モデル（Large Language Models, LLM）は、自然言語処理における様々なタスクの性能を大きく発展させた．しかし，生成テキストに誤情報を含む「幻覚」をはじめとした品質の低い出力が依然として存在するため，特に医療や金融といった確実性が重要な領域での活用には課題が残されている．本研究では，生成テキストの品質向上を目指す復号手法が，質問応答と要約タスクにおいて大規模言語モデルの不確実性推定性能に与える影響を調査した．実験により，貪欲探索やビーム探索のようなシンプルな復号手法が，不確実性推定性能の観点で優れていることが判明した．"
D10-3,質問応答タスクにおいて、大規模言語モデル(LLM)の知識を補うために検索拡張生成(RAG)がよく使われるが、Retriever により得られた複数の異なるコンテキストを活用する方法に課題がある。一般的にはコンテキストを逐次的に入力しながら前の答えを書き直すかどうかを LLM 自身に判定させる(逐次 RAG)。一方で fusion-in-decoder と呼ばれる方法では得られたコンテキストをすべて結合してデコーダーに入力し、デコーダーに回答を生成させる。ここでは LLM を並列に用いて質問応答を行う方法(fusion-in-LLM)を提案し、AI 王を用いたクイズのための質問応答タスクの実験により、逐次 RAGよりも fusion-in-LLM のほうが質問応答タスクに回答する性能が高いことを示す。
D8-3,本研究では，人とロボットのインタラクションにおいて生じる異常を自動で検出するモデルを構築することを目的とし，データセットの作成および異常検出モデルの構築を行った．具体的には，人とロボットのインタラクションに問題が生じた際に人間が介入する複数人同時対話の枠組みにおいて収集されたインタラクション映像に対して，正常か異常かを人手でアノテーションすることでデータセットを作成した．そして，作成したデータセットを用いて分類モデルを学習することで異常検出モデルを構築した．さらに，複数人同時対話の枠組みを検証する実証実験を実施し，モデルの検出結果をアラートとして提示することがオペレータの介入に有用であることを確認した．
Q5-23,入力文の意味を保持したまま否定的な感情を肯定的な感情へ変換するポジティブテキストリフレーミング(PTR)タスクは，大規模言語モデルの進展により広く研究されている．PTR タスクでは，事前学習済のモデルを利用し，対象データに併せてファインチューニングする手法が多く提案されている．しかし，PTR タスクにおけるファインチューニングでは，ソース文とターゲット文は同義であり，ソース文は否定を，ターゲット文は肯定を表す大量のパラレルデータが必要であることから，データ不足が問題となることが多い．本研究は，データ拡張手法により生成したパラレルデータを用いることにより，PTR の精度向上を目指す．
P2-9,トークナイザは単語を複数のサブワードに分割することがあるが，その分割が言語的に意味のあるものになるとは限らない．推論の段階仮説（Stages ofinference hypothesis）では，言語モデルの序盤層はこうしたサブワードトークン列をより意味のある表現に変換(Detokenize)するとされている．本研究では，従来のプロービングや因果介入などの経験的手法に依存せず，Detokenization をモデルの重みに基づく解析によって観測できることを示す．具体的には，GPT-2 の第 1 層の注意機構を解析的に分解し，トークンタイプに由来する寄与とトークンの位置に由来する項の寄与とを切り分けた分析を行い，近いトークンや頻出 Bigram への注意の偏りを明らかにする1）．
Q1-3,本研究では、日本語道徳理解度評価用データセット JETHICS を提案する。JETHICS は、英語の既存データセットである ETHICS の構築方法を踏襲し作成されており、正義、功利主義、義務論、徳倫理、常識道徳の五つのカテゴリから構成され、約 7.8 万件のデータが含まれる。常識道徳を除く各カテゴリは全て規範倫理学・政治哲学の理論や概念を参考にして作成されている。公開されている大規模言語モデル(Large Languge Model: LLM)および商用モデルとして GPT-4o を対象として評価実験を行ったところ、GPT-4o であっても平均評価値が約 0.7、平均評価値が最も高い公開 LLM では約 0.5 となり、既存のLLM には改善の余地があることが示された。
E5-6,本研究は，エネルギー関連のコモディティ先物市場におけるベージュブック情報の影響を分析する．ベージュブックは，地域経済の景況感や多様なトピックを含むテキスト情報を持つ．ベージュブックが様々な資産に影響を与えることが実証されているが，本研究では，まず，ベージュブックの発表が市場に影響を与えるかを分析する．次に，ベージュブックのどのセンチメントやトピックが影響を与えるかを検証する．結果，一部のエネルギー関連のコモディティがベージュブックの情報に特に敏感に反応することが示された．
C6-5,"Text simpliﬁcation is widely believed to enhancecomprehension for non-native readers, and has, there-fore, been the focus of extensive research. However,conventional text simpliﬁcation often involves remov-ing a considerable amount of complex content, whichmay reduce valuable information and potentially limitopportunities to engage with challenging concepts. Inthis work, we speciﬁcally address the needs of lan-guage learners by focusing on elaborative text simpli-ﬁcation, a process involving content addition, such asproviding speciﬁc explanations and clariﬁcations thatcould make a text comprehensible within its context.We introduce a novel data-driven approach for guidedelaboration generation, demonstrating that explicitlyspecifying elaboration targets leads to improved per-formance."
P2-13,近年の自然言語処理技術の発展に伴い，大規模言語モデル(LLM)は様々な言語を扱うことが可能となっている．一方でこれらのモデルを用いた推論・生成では，英語で指示を与える際に，他の言語で指示を与える場合よりも性能が高くなる現象が確認されている．本研究では，誤差の大小の解釈が容易な「数」に着目したタスク設定を行い，指示言語によって生じる LLM の性能差のより精緻な検証を試みた．結果として指示言語の特徴により生成結果の誤差の生じ方に差が生じ，言語的特徴が性能に影響を及ぼしていることの示唆を得た．
B9-2,70 万語超を収録した大規模医療用語辞書 JMED-DICT の構築方法およびメンテナンスについて報告する．JMED-DICT は，LLM をはじめとして計算機によって利用されることを想定した，医療用語間の対応関係を保持する辞書である．本稿では，本辞書の仕様，データ構築の手法，メンテナンス方法を紹介する．また，メンテナンスの効率化のために開発した各種ツールおよび，本辞書を利用した応用例である API についても併せて述べる．
Q3-1,本研究では，移動軌跡データに関する質問応答（QA）データセットを構築した．より具体的には，事実照会問題，選択式問題，自由記述式問題という3 種類の QA タスクを定義し，それぞれに対して 500件の問題・回答ペアを作成した．構築したデータを使用して大規模言語モデルの性能を評価し，一日における移動軌跡データに関する QA よりも，複数日にまたがる移動軌跡データに関する QA の方が難易度が高いことがわかった．
E7-4,大規模言語モデル（LLM）は幅広い分野で応用が進んでおり，会計ドメインにおいても活用が期待されている．そこで本論文では，弥生株式会社の持つ会計業務に関する質問の解説ページを収集し，検索システム構築および精度評価に用いることのできる弥生 QA v1 データセットを構築した．このデータセットを用いて既存のベクトル検索手法の評価を行い，さらにその検索結果を LLM によって順位付けした．この結果，順位付けを実施しない従来手法に比べて正答率の向上が見られ，会計ドメインにおいて有効となる検索手法を示した．
A2-4,本研究では，固有表現抽出におけるタスク特化型BERT モデルと大規模言語モデル（Large LanguageModels，LLM）の一つである Gemini との性能と実用性を比較評価した．独自に構築したデータセットを用いて，few-shot 学習とﬁne-tuning の両方の学習方法での性能を分析し，タスク適合性やコストなどを考慮に入れて実用面での評価も行った．結果として，タスク特化型 BERT のﬁne-tuning において最も高い性能を示し，Gemini は few-shot 学習での柔軟性と，ﬁne-tuning による性能向上の可能性を示した．本研究の知見は，実用的な固有表現抽出システムの設計と実装に貢献すると期待される．
P8-2,事業セグメントに着目した類似企業の特定は，ポートフォリオの構築や，資産価格や債券金利の適切な設定など金融機関の主要業務に関わる重要な課題とされている．類似企業の特定は，各社の事業セグメントに基づき異なる粒度で各企業に独自のカテゴリーを割り当てた業種分類に基づいて行われる．しかし，複数の業種にまたがる事業をもつ企業の場合，ひとつの企業に複数の業種を割り当てることができないため，類似企業を適切に特定することが困難である．そこで本研究では，有価証券報告書で報告された事業セグメントの記述よりキーワードを抽出し，その周辺のコンテキストを含めてベクトル化することで，多様な意味や潜在的な文脈を抽出する手法と，大規模言語モデルの内部知識に基づき企業の一般的な業種イメージをキーワードとして表現する手法を組み合わせるハイブリッド検索手法を提案した．これにより，従来の業種分類では困難だった，事業セグメントを考慮した類似企業検索を実現した．評価実験により，業種抽出性能と株式投資のリターン相関の評価において，提案モデルがベースラインモデルを上回る性能を示した．
P7-23,文章の内容的な誤りを正す校閲は，文章の質を担保するために重要な工程である．本研究では，大規模言語モデル(LLM)を活用した校閲支援の実現に向け，人間が書いた文章に生じる Hallucination の特徴を分析し，LLM の校閲能力を評価するベンチマークを構築する．新聞の訂正記事を用いた分析では，漢字誤変換や数字の桁のずれといった，人間が書いた文章ならではの特徴があるとわかった．分析結果をもとに人間が起こしやすい Hallucination を含む文章を自動生成し LLM を評価した結果，LLM にとって校閲は困難なタスクであることを確認した．
Q5-7,近年の大規模言語モデル（LLM）を活用した対話システムの飛躍的な発展に伴い，対話システムのパーソナライズへの関心も高まってきている．しかし新たな性格のテキスト生成モデルを表現するには，表現したい感情の強さや混ざり具合に応じたモデルを個別に作らなければならない．本研究では，個別の感情を表現することに特化したモデルを感情ごとに作成し，タスクベクトル演算を用いてモデルを合成することで，感情の強弱や複合感情を表現する手法を提案する．LLM を用いたテキスト評価実験の結果，対象感情の強弱と感情の複合いずれについても生成テキストで表現できていることが確認された．
Q10-3,材料・化学分野のテキストに対して，固有表現抽出を試みる場合，学習に使えるデータが十分でないことやアノテーションに高度な専門知識が必要であるという問題点がある．一方で，大規模言語モデル（LLM）は少量事例（few-shot 例）に基づき，分類や推論が可能である．LLM は提供する事例によって回答の精度が大きく変化することから，適切な例を選択するための方法を設計することが重要である．本研究では，文の意味的類似性とセットカバレッジを考慮した few-shot 例選出手法 Hybrid-SET を提案する．実験結果から Hybrid-SET は既存の選択手法より優れていることを示す．
C2-1,近年，株価予測の分野では，SNS 文書の感情分析を通じて市場の感情を推定し，予測精度を向上させる研究が注目されている．しかし，SNS 特有の主観的な感情表現と金融特有の専門用語が混在する金融SNSドメインに適応したアノテーション済みデータの不足が課題となっている．本稿では，汎用，SNS，金融，金融 SNS といった 4 つのドメインにおける感情分析の精度比較とターゲットドメイン特化型学習の評価を行った．また，疑似データ生成を活用し，ポジネガ分析を用いた株価予測実験において，予測精度の向上を実現した．本稿は，金融市場において有効性を示し，他の複雑なドメインにおいても適応可能性を持つものである．
E1-2,文法化とは内容語が機能語に変わる通時変化のことである．本稿では，文法化の度合いをコーパスデータに基づいて定量化する三種類の手法を提案する．提案手法は従来手法と異なり汎用性が高いにもかかわらず，人手の分析で得られた文法化度と中程度〜高い相関を示す．また，提案手法を歴史コーパスに適用して文法化の一方向仮説の吟味を行う．
A4-2,"心の理論とは,他者の心の状態や意図を理解する能力である.近年,大規模言語モデル（LLM）の発展に伴い,その能力を評価するための分析が進められている.その中でも,尺度表現に対して聞き手が文字通りの意味を超えた推論を行う「尺度推意」は注目される課題の一つである.しかし,これまでの研究では,自然なテキストに基づく評価は十分に行われていなかった.そこで本研究では,尺度推意に関する自然なテキストデータセットを構築し, LLM の尺度推意の推論能力を評価する.結果から, GPT-4o, Llama3.1 の尺度推意の推論能力には改善の余地があることを明らかにした."
P10-6,本稿では、擬似的な選好データを用いた選好チューニングによって、対話応答生成におけるペルソナと生成応答の間の一貫性を向上させる手法を提案する。提案手法では、あるペルソナ情報付き対話データに対して、他の対話からランダムに抽出したペルソナ情報を用いて応答を生成し、これらの応答を擬似負例として扱う。参照応答を正例として扱うことで、擬似的な選好データを作成する。実験では、擬似選好データを用いて選好チューニングを行ったモデルが、通常の教師あり学習のみを用いたモデルや、ペルソナと発話間の含意関係に基づく報酬によって強化学習したモデルと比較して、より一貫性のある自然な応答を生成することを示す。
Q7-5,LLM に外部知識を統合する手法である RAG は，情報を検索する「検索器」と，その情報を基に回答を生成する「生成器」から構成されることが一般的である．本研究の目的は，検索器の能力が十分高い場合，SLM を生成器として用いても RAG が有効に機能するかを検証することである．実験では，JQaRA データセットを用いた QA タスクを実施し，検索器が常に正解文書を検索できるという理想的な条件を仮定した．その結果，検索器の性能が高い場合でも，生成器として性能の高いモデルを使用する方が全体の回答精度が向上することが示された．また，生成器の機構に関して，複数の SLM をアンサンブルとして組み合わせることで，全体の正解率を大幅に向上させる可能性が示された．
A6-1,大規模言語モデルは優れた多言語能力と広範な知識を有するが，これらの能力が内部的に形成される過程は定かでない．本研究ではこの疑問を解明するため，モデルの内部表現に含まれる情報が学習経過に伴いどう変化していくかを分析する．具体的には，モデルのチェックポイント別にスパースオートエンコーダーを学習し，その解釈結果をチェックポイント横断で比較する．実験の結果，大規模言語モデルは言語を個別に学習した後に言語間の対応関係を学習すること，トークンレベルの知識を学習した後に抽象度の高い概念レベルの学習をすることが明らかとなった．
E3-1,デジタル人文学やコーパス言語学研究に重要な日本語長単位語に対する語彙素を推定する試みを行った．語彙素の推定にはエンコーダ・デコーダ型の言語モデル(T5)を用い，長単位語の品詞や表層形の他，長単位語を構成する短単位語の品詞・語彙素，および本文を入力として，長単位語の語彙素を出力させた．短単位語彙素をベースラインとした推定に対し，本手法は高い性能が得られた．検討の結果，短単位語は長単位語彙素推定に有効であるが，事例検討から，特に口語的な表現や動詞の付属部などに関しては文脈情報(本文)が推定に有効であった．
Q7-4,ハンセン病回復者の語り部との対話を通した人権学習は，自身の考えや価値観を見つめ直す対話型体験学習として重要である．しかし，語り部の高齢化やハンセン病を取り巻く環境などの背景から，次世代の語り部への記憶の継承が難しい．本研究では，語り部の実体験や記憶を後世に継承するために，ハンセン病回復者の語り部との対話による対話型体験学習の効果を再現できる質問応答システムの構築を目指す．本論文においては，質問応答システム構築の事前実験として，証言記録のテキストにベクトル検索を適用した場合の精度を検証する．実験の結果，GLuCoSE-base-ja-v2 が最も高い性能を発揮した．
P10-7,過去情報の整合性を維持しながら応答を生成する「長期一貫性」能力は，人間らしい対話システム構築において重要な要素の一つである．これを可能にする手法として，人間の長期記憶を模したメモリモジュールを用いる手法がある[1]．最も単純な方法は，対話履歴をメモリに保存し，次の応答生成時にその対話履歴をユーザの応答とともにプロンプト入力に加えることだが，入力可能なシーケンス長の制限や V-RAM 消費量の増大など，様々な問題が発生する．本研究では，これらの問題を解決するため，長期一貫性を持ったオープンドメイン対話が可能なMemochat[2]と対話圧縮モジュールを組み合わせて，高効率なメモリモジュールを持った対話システムを提案する．対話履歴を保存する際，トピックごとに対話履歴を分割し，それらの要約と対話，トピック名を三つ組にしたメモを生成する．さらに，単純な対話圧縮モデルを用いて対話内容を短縮してメモリに保存し，後の応答生成の際にそれを利用することで，モデルへの入力トークン数を抑えつつ，過去記憶に忠実な応答生成を可能にする．公開されたデータセット及び[2]で採用されたデータセットを基に訓練用データセットを再構築し，メモ生成，検索，長期一貫性を持った応答能力の向上を図る．また，メモ生成時に分割した対話履歴内の助詞，助動詞を除去するモジュールで対話を圧縮することで，メモリモジュールの記憶効率性を上げる．最後に，対話ターンが長い対話データセットを用いて長期一貫性及びメモリ効率を検証し，その有効性を確認した．
Q9-22,条件付きテキスト埋め込みは、特定の側面に焦点を当てたテキストの埋め込み表現であり、与えられた条件に基づくテキスト同士の類似度の算出を可能にする。従来手法は、大規模な訓練データによる指示学習や意味的テキスト類似度算出タスクによる微調整が求められ、開発コストが高い。そこで本研究では、生成型 LLM をテキストエンコーダとして条件付き一語制約プロンプトを用いる、訓練不要で高品質な条件付きテキスト埋め込み PonTE を提案する。条件付き意味的類似度テキスト類似度とテキストクラスタリングによる二つの実験を通じて、提案手法は追加の訓練なしで従来手法以上の性能を達成することを示す。
E1-3,墨によって書かれた文書は，墨の濃淡情報を用いることで，その文書が作成された筆記過程を分析できる可能性がある．われわれは，墨の濃淡情報を時系列データとして分析し，墨が徐々に薄くなって，再び濃くなった箇所を筆に墨を含めなおした点として推定する手法を考えた．この手法による分析結果を人の眼で判断した正解と比較検討することで，われわれの手法の性能評価を行なった．
A4-3,深層ニューラルネットワーク（Deep NeuralNetwork: DNN）は，微小な変更が加えられた入力データである敵対的事例（Adversarial Examples: AE）を誤認識してしまう脆弱性が存在する．日本語処理用の DNN も同様の脆弱性が存在し，このような脆弱性は，DNN を実世界の課題に応用する上で重大な障害となり得る．本研究では，AE に対する日本語処理モデルの頑健性向上を目的とし，日本語に特化した再攻撃による敵対的防御手法を提案する．実験により，提案手法が通常事例の分類精度を維持しつつ，AE の矯正を行えることを確認した．
Q10-2,エンティティの内容を表す名前や説明などのテキストで表される様々な異なる種類の属性情報に含まれるエンティティの内容的な特徴を反映したエンティティ表現を獲得する新たなハイパーグラフ表現学習手法を提案する．具体的には，属性情報をエンティティとは異なるノードとして統合したハイパーグラフを定義し，その上で新たに提案するアテンション機構を利用した異種ハイパーグラフエンコーダと属性情報からエンティティを予測するエンティティ予測損失を導入し，属性情報に含まれるエンティティの内容的な特徴をエンティティ表現に統合する．PubMed データセットを対象としたノード分類において，提案手法が既存手法と比較して高い分類性能を示すことを確認した．
Q5-6,"This paper presents a case study that examines the dis-tribution of training loss values in a Japanese advertisingtext generation model. Using a LongT5 architecture, weanalyze the characteristics of training examples that exhibitboth high and low loss values. Our ﬁndings reveal severalkey patterns: low-loss examples often contain repetitivephrases and standardized advertising terminology, whilehigh-loss examples tend to feature more complex gram-matical structures and natural language patterns. We alsoidentify potential issues in training data quality and dis-cuss their implications for model performance. We ﬁndthat measuring training loss per example in the trainingdata is a useful diagnostic tool, for better understandingmodel characteristics."
P7-22,"高性能な大規模言語モデル（Large Language Model,LLM）の開発には，高品質な学習データの収集が不可欠である．しかし，データ収集には多くの課題が伴い，データ提供者とモデル開発者が異なるケースでは，組織間でのデータ共有が避けられない場合がある．この共有プロセスにおいて，データの不適切な利用や漏洩リスクは重大な課題となる．そのため，データに適切な保護処理を施し，LLM の学習以外での利用を防ぐことが必要不可欠となる．同時に，保護されたデータを用いて構築した LLM において，モデル性能が大幅に低下しないことも求められる．本研究では，保護処理を施したデータを学習データとして使用した場合における LLM への影響を，特にコード生成能力を指標として評価する．"
P8-3,本研究では、事故・不具合問い合わせの解析・類似事例の検索・回答文の生成といった作業を自動で行うシステムの実現を目指しており、本稿では、現場からの問い合わせに対し、企業に蓄積されている文書から目的の類似事例を得るための絞り込み手法を提案する。製造業の企業における現場からの問い合わせは抽象的であるため、問い合わせ意図を検索結果に反映することが難しく、1 度の問い合わせで目的の類似事例文書を得ることは難しい。そのため、本稿では、現場利用者の情報要求に応じた類似事例文書を得るために、事故事例文書の絞り込みを行うシステムを構築することを目的とし、問い合わせ文からの問い合わせ意図推定、システムが能動的に行う質問に対してユーザが回答文を入力するやり取りの中でのスロットフィリング、スロットフィリングで得られた情報をもとにリランキングを行い絞り込みを行う手法を提案する。また、提案手法の有効性を検証するために、提案手法を扱うシステムを作成し評価実験を行った。抽象的な問い合わせ文を入力とし、提示する質問に回答していくことで、正解文書が初期の検索結果でのランクよりも上位にリランキングされることを確認した。
C4-6,"CLIP は視覚言語モデルのコンポーネントとして採用される事例が増えており,重要性が増している.しかし,オープンな日本語画像・テキスト対データセットは不足しており,モデル開発の障壁となっている.本研究では,オープン LLM を用いた機械翻訳により, 20 億事例の日本語画像・テキスト対データセットを構築し,日本語 CLIP を学習した.学習済みモデルの性能を, 7 つの評価データセットを用いて評価した結果,平均スコアが同程度のモデルサイズにおいて高水準であった一方,日本文化に関するタスクの性能が低いことがわかった.学習済みモデル1）2）,学習データセット3）,翻訳ツール4）,評価コード5）は公開する."
E7-5,大規模言語モデル(LLM)の発展に伴い，資産運用業界においても LLM への期待が高まっているが，実際には様々な課題が存在する．これまで自然言語処理(NLP)技術の発展に伴い，金融テキストを対象にしたセンチメント分析も発展してきたが，その変化はセンチメント付与の手法やモデルの切り替わりが中心であり，根本的な課題や問題に対して十分な議論が不足している．そこで本研究では，従来の金融テキストにおけるセンチメント分析の課題とその解決の糸口をいくつか示す．課題を明確に示し，整理することで，金融テキストにおけるセンチメント分析が今後より発展することを期待している．
A2-5,規範的推論は、義務や許容(許可)といった規範的・義務論的なモダリティが関与する推論である。本論文では、大規模言語モデル(LLM)の規範的推論能力が持つ特徴を明らかにするために、論理的な妥当性や非妥当性との比較、人間のリーズニングとの比較という 2 つの観点から LLM の規範的推論能力の評価と分析を行った。その結果、推論のモダリティの種類(規範的推論と認識的推論)での比較や、一部の推論パターンにおいて、LLM における規範的推論が人間のリーズニングの場合とは異なる傾向を示すことが示唆された。
B9-3,自然言語処理において，最も早くから利用されてきたリソースが辞書である．辞書は多様なタスクに有用であるが，構築やメンテナンスに要するコストが課題である．我々は，辞書データへの人手の修正履歴を活用し，未修正の用語に対して修正を自動提案するシステムを構築することで，質を担保しつつ低コストでメンテナンスが可能になると考えた．本研究では，構築中の 50 万語を超える大規模医療辞書において，医療用語のメタデータを自動修正する手法を提案する．実験では，専門的な医学知識を必要とする遺伝子バイオマーカの表記ゆれの修正性能を検証した結果を報告する．本手法は，多くの辞書メンテナンス負担軽減に貢献するものである．
P2-12,本研究は，Transformer 言語モデルにおける内部表現を解釈するために，擬似直交性の概念を新たに導入してそのアテンション層および FFN 出力層の部分空間の幾何的関係を分析する．FFN 層のウェイト行列の行空間が語彙空間と擬似直交していることを示した上で，FFN 層からの出力が意味的概念を担うコンセプトベクトルとして機能し，内部表現の文脈化に寄与している可能性を明らかにする．
C6-4,小学校の作文教育における内容に関する指導では出来事の具体的な描写を促すといったことが行われる．しかし，児童にとっては具体的なイメージがわかず詳述化が困難となることもある．これに対し，作文に内容に対する質問を児童に行うことで修正の指針を示すことができると考えられるが，多くの児童の作文に対し質問を考えることは教師にとって大きな負荷となる．そこで本研究では，内容の詳述化のための質問生成に大規模言語モデルが利用できるかについて，小学生に対して行った調査に基づき検討を行った．
Q1-2,本稿では，『現代日本語書き言葉均衡コーパス』（BCCWJ）の長単位への分類語彙表番号アノテーション作業とその結果について報告する．今回構築した BCCWJ-WLSP-LUW は，BCCWJ の書籍・新聞・雑誌データに対し，『分類語彙表増補改訂版』を基に分類語彙表番号を付与し，長単位の文脈的な意味分類を可能にしたアノテーションデータである．短単位への分類語彙表番号付与作業を基盤としつつ，未定義の長単位語義については一部手作業による対応を行った．これにより，長単位においても短単位と同様に分類語彙表を用いた詳細な意味分析が可能となった．
P2-8,Transformer に基づく大規模言語モデル(LLM)の構成要素の一つであるフィードフォワードネットワーク(FFN)に着目し，モデル内の配置場所に依存した重要度を検証する．具体的には，モデル全体のパラメータ数を維持したまま，一部の連続する層でFFN の中間次元を拡大し，残りの層から FFN を除去したモデル構成を用いて標準的なタスク性能を比較する．複数のモデルサイズで評価を行った結果，全層数の 70 – 90%の連続した中間から後方の層に FFNを集中配置することで，複数の下流タスクでベースラインの性能を上回った．この結果から FNN は入力に近い層より中間から後方の層で特に重要であると示唆される結果が得られた．
D10-2,本論文では，大規模言語モデルを活用して，韓国語における刑事業務に関連する法規の解釈に基づく質問応答の性能を改善する手法を提案する．本論文においては，インターネットで公開されている刑事業務に関する法令の条文および判例情報を蓄積し，RAG(Retrieval-AugmentedGeneration，検索拡張生成)の枠組みのもとで質問に関連する法令条文および判例を検索し，これらの関連法令・判例をふまえて，大規模言語モデルによって質問に関する推論を行うことにより，質問に対する的確な回答を生成するシステムを開発する．本システムの応用事例として，韓国の刑法分野において，捜査における意思決定および法的解釈の局面での支援用途が挙げられる．
Q5-22,LLM による発話生成時にキャラクター性を持たせ一貫したペルソナで会話させることは、人間であるユーザと自然な会話を実現させるうえで重要な要素である.その手法としてプロンプトエンジニアリングや Fine-tune があるが、どのような設定の組み合わせが最適かよくわかっていない。本研究では、5 名のキャラクターを対象に、4 種類の LLM を用いて、プロンプトと Fine-tune の効果比較を行った。実験の結果、few-shot を中心にプロンプトの有効性を確認したと同時に、実験の範囲では小規模なFine-tune が総合的に良い結果を示した。
D8-2,ユーザーをポジティブな感情に誘導する対話システムのパーソナライズを目指し，性格特性による感情誘導効果の違いを検証した．ビッグファイブの性格特性ごとに高低特性を持つ 10 種の擬似ユーザーエージェントを構築し，感情誘導実験を行なった結果，外向性，開放性，誠実性，調和性が高い場合，または神経症傾向が低い場合に，ポジティブな感情誘導効果が高まる可能性が示唆された．本研究は，性格特性を考慮した感情誘導対話システムの設計に向けた基礎的知見を提供する．
Q2-17,大規模言語モデルの hallucination（与えられた情報源に存在しない内容を生成する現象）は，実応用上での重要な課題となっている．本研究では，日本語における hallucination 評価のための包括的なベンチマーク JHARS （Japanese Hallucination Assessmentin RAG Settings）を構築し，最新の GPT-4o を含む3 つのモデルを対象に分析を行った．その結果，hallucination 発生率は低い一方，事実確認が必要な重大な hallucination が検出された．また，自動検出における高い適合率と再現率の両立は困難であるものの，重大な hallucination に関しては高い再現率で検出可能であることが示された．これは，LLM 自身による出力の検証が，ユーザへの事実確認支援として機能する可能性を示唆している．
Q2-15,近年では，SNS や大規模言語モデルの普及に伴い，誤った情報が拡散しやすくなっている．誤った情報の影響を抑えるには，Fact-checking が重要となる．Fact-checking は，判定対象が誤っていないか，外部のデータベースに基づいて判定するタスクである．このタスクでは，判定に必要な情報を外部データベースから検索することが求められる．本研究では，情報検索を行った後に，補足コンテキストの生成を行うことで，より多くの判定に有用な情報の取得を試みた．
Q5-20,"We propose an iterative graph-to-text generation methodto produce coherent scientiﬁc abstracts from paragraph-level knowledge graphs. The method segments the graphsinto smaller, context-speciﬁc components using functionallabels, which guide each generation step and inﬂuence sub-sequent outputs. Experimental results demonstrate thatﬁne-tuning the proposed method enhances the alignmentof Large Language Models (LLMs) with target seman-tics. Moreover, incorporating functional labels and itera-tive generation further improves semantic accuracy, struc-tural clarity, and logical organization, providing a scalablesolution for high-quality abstract generation."
C6-6,本研究は，日本語学習者向けの文章の難易度判定の可視化と日本語能力試験（JLPT）との対応付けを行うものである．別の研究で提案した分類精度が 88.0%の 35 の言語指標集合を基に，難易度を文字語彙，文構造，談話構造の 3 観点から捉え，それぞれリッジ回帰モデルを構築し，スコアを可視化した．JLPT の読解文章を用いて提案手法を検証した結果，提案モデルは全体的に判定精度が高く，観点別の難易度スコアを科学的根拠に基づいて提示できる点で，大規模言語モデルを用いた判定手法に対して優位性を示した．さらに，日本語教育における難易度と教育枠組みの関連性を明らかにするため，一般の日本語文章と JLPT の読解文章における観点別難易度の相対位置を可視化した．これらの成果は学習者のレベルに合わせた読解教材の作成・開発に貢献することが期待される．
E5-5,"近年,拡大する ESG 投資に対し,従来の評価基準における開示の有無だけでは不十分という課題を解決すべく,バリューモデルは 81 の明確な目標を設定し企業のサステナビリティ活動を評価する枠組みを提示している.本稿では,バリューモデルの 168 のサブゴールうち従業員向け 42 サブゴールを対象に,大規模言語モデル（LLM）を用いた情報抽出を検証した.具体的には,企業のサステナビリティレポートトに対し「従業員のメンタルヘルス施策」などの定量および定性情報を抽出するプロンプトを設計し, LLM のツールのひとつである ChatPDF からの回答を人手で検証したところ,報告書の表のレイアウトや類義語の違いなどに起因して未抽出情報率が企業ごとに 20～40%台と大きく異なることが示された.この結果は, LLM 活用の際,レポート側のレイアウトや抽出に適した類義語のプロンプト設計が重要であることを示している."
P5-19,近年，音声言語処理の新たな手法として TextlessNLP（テキスト資源に頼らず音声資源のみを用いてNLP システムを構築する試み）が注目を集めている．その基盤となる「音声言語モデル」は，音声シグナルを「トークナイズ」して離散表現に変換した上で言語モデルを学習し，音声言語処理の実現を目指すものである．本研究では，計 36 通りの音声トークナイズ手法を用いて音声言語モデルを学習して性能を比較し，音声トークナイズが音声言語モデルの性能に与える影響を調査した．実験の結果，音声シグナルを適切な粒度で分節すること，離散化時のクラスタ数を増やすことの有用性が示唆された．
P2-10,本研究では，言語の埋め込み表現である単語ベクトルや埋め込み層について，表現に必要十分な次元である内在次元(Intrinsic Dimension; ID)を計測し，その冗長度合いを定量評価する．具体的には，(1)Word2Vec や GloVe などの小規模モデルの埋め込みが持つ ID を推定し，(2) Pythia 系列を代表とする大規模言語モデルの埋め込み層における ID をスケール別・学習過程別に解析する．実験の結果，埋め込み空間が外在的な次元に比べ低い次元の多様体上に分布する傾向が見られた．また，モデル規模の拡大に伴う冗長率の変化や，学習初期における急激な IDの形成が見られた．
B9-1,ダイエットカフェ株式会社から国立情報学研究所（NII）を通じて研究者に提供されているデータセットである「ダイエット口コミデータセット」の貸与を受けた。合計約 19 万 9 千件の口コミから成る当該データセットのうち，ダイエットドリンク約４万 3千件，ダイエット食品約 8 千件について，出現する単語の共起ネットワーク図を作成したので報告する。
E10-5,大規模言語モデル（LLMs）の学習時，ある能力を学習過程で突然獲得する現象が知られている．このような LLMs の変化は相転移（Phase Transition）現象と呼ばれ，その原因として LLMs の内部状態における相転移が示唆されているが，その実態は未解明の点が多い．本研究で我々は LLMs の相転移について LLMs の内部表現とヒト脳活動を対比させることにより解釈することを試みる．具体的には，学習過程における，LLMsと脳の類似度，LLMsの内部状態，下流タスク精度の変化という 3 つの観点を統合した解析を行い，LLMs の学習ダイナミクスに新たな解釈を与える．我々は，LLMs が下流タスクの能力を獲得する過程で，脳との対応や内部状態に 3 段階の相転移が起きることを示す．
Q3-2,強力な視覚言語モデル(VLM)を構築するためには、画像・テキスト対データや交互配置(interleaved)データ、指示データなどのマルチモーダルデータが必要である。しかし、英語のデータは豊富にあるが、日本語のデータは限られている。この問題に対処するため、我々はゼロから日本語のマルチモーダルデータセットを構築する。我々はウェブ上の画像・テキスト対データと interleaved データを構築し、さらに既存の大規模言語モデル(LLM)や VLM を利用して日本語のマルチモーダル指示データを構築する。これらのデータセットを利用して学習したモデルは、先行研究の機械翻訳を用いて構築したデータによるモデルよりも高い性能を示した。
C4-4,画像言語モデルは、与えられた画像と矛盾する出力を生成することが報告されている。この現象はハルシネーションと呼ばれ、画像言語モデルの信用を損ない、普及を阻害する要因となっている。しかし、ハルシネーションの発生と、画像言語モデルがテキスト生成時に画像の適切な領域へ注目しているかどうかは関連すると予想されるが、データでは示されていない。本研究では、ハルシネーションの有無に関する評価指標である POPE を用い、画像内に実際に写っている物体と写っていない物体を対象として、ハルシネーションの発生と画像内の注目領域との関係を検証する。
P8-1,Retrieval-augmented generation（RAG）は，コーパスからの情報検索を活用することにより，大規模言語モデル（LLM）の性能を大幅に向上させる．RAG の性能は，RAG パイプラインにおけるハイパーパラメータと，LLM に与えるプロンプトに大きく依存する．本研究で提案する UniOptRAG フレームワークでは，単変量最適化アルゴリズムを組み合わせることで，ハイパーパラメータとプロンプトを同時に最適化する．この同時最適化によっていずれか一方のみを最適化する場合の性能を上回り，既存研究でファインチューニングや高度な推論パイプラインを用いた場合と同等の性能を達成することを示す．
P7-20,人工知能が高度な汎化能力を持つためには，少数の例からパターンを抽出し，新しい入力に適用する抽象推論能力の向上が重要である．しかしながら，既存の大規模言語モデルは未だ十分な抽象推論能力を有しておらず，その能力について詳細な分析が必要である．本稿ではこれらの能力を評価する代表的なデータセットである ARC（Abstraction andReasoning Corpus ）について few-shot 学習を通して実際に解かせ，ARC の各タスクに必要な処理を能力ごとに分解し分類した上で，能力ごとの精度を分析することで大規模言語モデルの抽象推論能力を詳細に評価する．
P9-19,YouTuber や VTuber などの動画配信への関心が高まっている。しかし、動画配信を支援するソフトウェアの複雑さや、実況能力への不安から動画配信の参入障壁は高い。本研究では、大規模言語モデル等を活用して気軽な実況配信を実現するシステム:TEPPAY を提案する。TEPPAY はシーン検出や発話生成などを行う 7 つのモジュールで構成されている。TEPPAY を構成するモジュールの性能調査の結果、配信に必要な最低限の性能は担保しているものの、視聴者の興味を惹く魅力的な実況動画を作成する上でいくつか課題があることを確認した。
Q5-4,"Large Language Models (LLMs) have revolutionized theNLP landscape overnight. However, they still struggle inout-of-distribution (OOD) scenarios. We present a casestudy on the performance of LLMs in the ad title gen-eration task, which represents an OOD scenario. LLMsperform better than we expected. Instruction-tuned mod-els are signiﬁcantly more stable than non-tuned ones. Adistilled Llama 3.2 performs signiﬁcantly worse than thebase Llama 3.1. General chat instruction-tuned modelsyield mixed results compared to non-tuned models."
A4-1,大規模言語モデル(LLM)における倫理観の調整は、有用性とのトレードオフを伴う。過剰に安全性を優先した LLM では、無害なプロンプトに対して応答を拒否する事例が確認されており、このような境界領域の分析や評価は、安全性強化において重要である。しかし、日本語においてこうした過剰な拒否がどのような条件下で発生するのかについては、体系的な調査や評価手法が十分に確立されていない。本研究では、LLM にとって安全性と有用性の境界付近に位置するケースを網羅的に整理し、各ケースに対するモデルの応答を評価する「日本語安全性境界テスト」を提案する。本データセットを用いて8 種類の LLM を評価し、日本語安全性境界における性能を初めて定量的に分析した。本稿とデータセットには有害な文章が含まれる。1）
E1-1,本稿は、テキストデータから求めた指標の大小でクレオールと非クレオールを峻別できるか検証した。データとして、いずれの言語においても同一内容が保証されている聖書を用いた。実験の結果、両者を峻別こそできないが、複数の指標で大別することができた。これは、クレオールが非クレオールとは異なる性質を保有している可能性を示唆している。また、部分的に単純説を支持する結果を得た。
C2-2,自然言語処理分野において，データラベリングに高いコストが伴う問題を解決するために，データ拡張および自己教師あり学習手法が大きく発展してきた．感情認識・分類タスクにおいても Park らは，Valence-Arousal-Dominance（VAD）フレームワークを利用することにより，感情のカテゴリラベル付きコーパスを相互に比較・統合し，データセットの拡充ができる可能性があることが示している[1]．本研究では，限られたデータセットを効果的に活用し，感情認識対応チャットシステムを訓練するための新しいアプローチを提案する．具体的には，否定語に影響を受ける動詞と形容詞の V スコアを反転し，LLM のアテンションロジットを加重値として用いることで，感情ラベルが付いていないデータに対して近似 VAD スコアを求める．単に文章中の単語のVADを平均する従来手法と比べ，精度が向上することを示す．
Q9-20,"対話システムが物語を理解できれば，話者の価値観や経験などをより深く理解することができるようになると考えられる．先行研究で我々は，物語の表現として Elson によって提案された Story IntentionGraph (SIG)に着目し，大規模言語モデル（LLM）を用いて，物語文から SIG の自動生成に取り組んだ．しかしながら，SIG の構造は複雑であり，物語文から SIG を自動生成する精度は高くなかった．本研究では，より高度な推論が可能と考えられるLLM を用いた SIG の自動生成の改善を行う．具体的には, LLM として GPT-4o,および，推論力に優れた OpenAI o1 を採用し,プロンプトへの shot の導入を行った．実験では，自動生成された SIG を，人手によって作成された SIG と比較した．その結果，OpenAI o1 に shot の追加を行うことで，人手作成SIG の約 76%という比較的高い精度で SIG を自動生成可能なことが分かった．"
Q9-9,"This paper proposes a method for word sense disam-biguation in historical Chinese texts using general-purposeLLMs (GPT-4o and GPT-4o-mini). The results show thatthe larger model performs better and few-shot examplesimprove performance, though the eﬀectiveness of dynamicexample selection remains unclear. The best-performingsetup is applied to visualize the change in meaning of acharacter over approximately 3,000 years of Chinese textdata, demonstrating the potential of this approach for track-ing semantic evolution."
Q7-19,本研究は，仮想エージェントと歩行しながら対話する音声対話システムを提案する．AR グラスなどの持ち運びのしやすい端末に実装し，仮想エージェントと自由に移動しながらの対話を目指す．対話文生成では仮想エージェントの発話内容，動作内容の順で生成する．対話中にユーザと仮想エージェントの歩行軌道を記録した結果，仮想エージェントがユーザと横並びで対話できる事が確認された．
P10-5,ユーザにコンテンツを長く楽しんでもらう方法の 1 つとして，既存キャラクターを模した対話システムの実現がある．実現にはユーザがキャラクターらしさを感じる応答の生成が重要である．先行研究ではキャラクターの性格の一貫性が重視されてきたが，主に表出している性格から考えると意外性を感じさせる性格（以降，2 面性）の表出もキャラクターの再現には重要だと考えられる．そこで，本研究では LLM が 2 面性を表出した発話生成が可能かを調査した．結果として 2 面性を感じさせるような発話を生成できない場合が多いことを明らかにした．そして，2 面性を表出できていない発話の特徴分析を行い，今後の展望を明らかにした．
Q7-6,本研究では、Yahoo!知恵袋に投稿された質問と回答文を対象とし、Sentence-BERT で得た文ベクトルを LightGBM で学習することでベストアンサー予測するモデルを構築した。回答のみより質問文＋回答文を併用した方が高精度となり、人間の予測精度を上回る結果を得た。一方でカテゴリ別分析では、恋愛や政治といった正解が定まらない領域で精度が低く、質問者の主観や好みが BA 選定に大きく影響する傾向が示唆された。
E3-3,満洲語における母音調和は他の言語における母音調和と異なる性質を持っており、今日まで様々な記述がなされてきた。17 世紀ごろの満洲語に限れば、文字資料のみを用いてこの音声現象に向き合わねばならず、これには当時の文書を包括的に扱う必要がある。そこで本研究では Brown Clustering による母音・音節の分類と隠れマルコフモデルによる音韻環境と確率の計算を用いて母音のグルーピングと、母音¯u についての考察を行う。結果として、[±RTR]の調和があるが、母音の階層性によって調和が阻害されることがわかり、¯u は非円唇母音、あるいは弱い円唇性を持つ母音であると示唆された。
A6-3,本稿では，競技クイズを題材として，問題文や正解1）の特性が LLM と人間の解答の正答率にもたらす影響について調査し，人間と LLM における「難しさ」の違いを明らかにする．人間の正答率が付与されたクイズデータを収集し，クイズの正解のWikipedia エントリが存在するか，正解の文字種が何であるか，問題文中で解答候補が列挙されているか，という 3 つの観点で分類する．GPT-4o など 6 つの LLM にクイズを解答させ，各観点による分類ごとの LLM と人間の正答率の差を明らかにする．
E3-2,場所表現の地理的曖昧性は，ジオコーディングにおいて重要な課題である．従来の研究では，場所表現が登場する文脈情報の有用性が示されている一方で，文脈情報を考慮しても位置が特定できない場合も少なくない．そこで，本研究では，曖昧な場所表現の位置を特定するためのユーザへの質問内容生成を目的として，複数の場所候補を絞り込む上で手がかりとなるランドマークの抽出を試みた．実験では，GPT-4o を使用し，人手で作成した評価データを用いてその有用性を評価した．結果として，モデルは中程度の精度を示したが，カテゴリの曖昧さや過剰な推測に起因する正解ランドマークの見逃しが多い傾向にあることが分かった．
A6-2,大規模言語モデル（LLM）の利活用が進む一方で，その推論過程や内部表現は不透明である．本研究では，LLM の内部表現における数値属性の構造に着目し，部分的最小二乗法（PLS）を用いた probingを通じて，異なる属性間で共通する「数値を変調する方向成分（スケーリングベクトル）」の存在を明らかにする．さらに，異なる属性間の交絡は，特定属性への介入操作や few-shot プロンプティングによる出力に副作用を及ぼすことを実験的に示す．この結果は，LLM の内部表現に対する解釈可能性と実用上の制御手法を結び付け，LLM の出力の公平性や頑健性の研究に貢献しうる示唆を提供する．
Q7-7,本論文では，大量かつ複雑な構造を持った PDF 文書を扱う際に，Retrieval- Augmented Generation (RAG)の利用において，OCR ライブラリ surya1）を利用したチャンキング手法を提案する。surya を用いてタイトルや表を自動判定し，それぞれの構造に応じた処理を適用することで精度の向上を目指す．学内事務手続き PDF を用いた RAG による質問応答実験では，単純なテキスト分割と比べて BLEU およびROUGE 各種指標で高い性能を示した．その際特に表領域の処理の効果が確認された．
P10-4,対話における応答タイミングは発話者の意図を表現するための有用な手段である．この観点から応答タイミングを予測する手法の研究が進んでいる．他方で，このような手法を有効に活用するためには，音声合成などの生成モジュールの遅延を緩和する仕組みが必要となる．このような背景に基づき，応答タイミングと遅延緩和のための短文応答を同時予測するモデルを提案する．提案手法は応答すべきか否かを連続的に予測しながら，応答と判定した際に対照学習に基づくランキング付けにより適切な短文応答を選ぶ．二つのタスクでの客観評価を行い，応答タイミング，短文応答選択の両方で同条件の比較手法に対して優れた結果であることを確認した．
Q7-18,本研究では，北海道十勝管内の自治体を対象とし，現地調査に基づき特定された課題と議会会議録を対象とした農政政策に関する議論分析を組み合わせることによって，農業政策と営農活動に関する課題の体系的な分析を行う．
Q9-8,大規模言語モデル(LLM)を用いた外来語の意味推論において、和製英語の存在など元来の英単語の意味との違いがモデルの精度に影響を与える可能性がある。外来語の意味を正確に捉えるために、本研究では BCCWJ から抽出したデータで LLM をFine-tuning し、現状のカタカナ語の意味推論の精度及び出力傾向を分析、精度向上への方策を探る。複数の実験の結果、Zero-shot learning では Fine-tuningの有効性が確認できなかったが、対照的に Few-shotlearning では約 10 ％の精度の向上が見られた。出力傾向分析によってモデルの苦手な語義や単語の傾向を得られたため、今後の研究への寄与を期待する。
Q9-21,"本研究は,文の埋め込みに有効な静的単語ベクトル(Static Word Embedding)を提案する.文ベクトルを出力するように事前学習された Sentence Transformerから単語ベクトルを抽出し,さらに主成分分析と知識蒸留を行うことで文表現に適した単語ベクトルを獲得する.計 56 個の英語のデータセットから成るMassive Text Embedding Benchmark (MTEB)で実験を行い,既存手法の精度を大幅に上回ることを示した."
C2-3,Russell 円環モデルは，感情を「感情価（Valence）」と「覚醒度（Arousal）」の二軸で表現し，感情分布が円環状に配置されるを視覚化し，感情の認知構造を直感的に説明する枠組みとして広く利用される．本研究では，BERT モデルを用い，Russell 円環モデルに基づく感情分布を検証するために，次の 2 つの手法を提案する．一つ目は BERT の CLS トークンを特徴量として用いる方法（方法 1），二つ目は BERTの Attention ウェイトを利用して文全体の感情値を算出する方法（方法 2）である．これらの手法を用いて複数の実感情データセットを用いて実際の感情分布を分析し，この理論モデルの妥当性を検証するとともに，感情分布の実態に即した新たな知見を提供することを目的とする．
Q5-5,特許出願における特許請求の範囲の自動補正は，知的財産戦略の観点から極めて重要である。本研究では、データセットと書き換えモデルを含む特許文書の自動補正のための新しいフレームワーク“ClaimBrush”を提案する。具体的には，特許請求の範囲の自動補正モデルを学習・評価するためのデータセットを，特許審査過程における実際の特許請求の範囲の補正事例を大量に収集することによって構築した。構築したデータセットを用いて，大規模言語モデルを微調整することにより，特許請求の範囲の自動補正モデルを構築した。さらに，特許審査官による特許出願の拒絶査定の自動予測結果に基づいた選好最適化を適用することで，提案した特許請求の範囲の自動補正モデルの性能を向上させた。評価実験の結果，提案した特許請求の範囲の自動補正モデルは，経験則に基づいたベースラインや最先端の大規模言語モデルを用いたゼロショット学習手法を凌駕することが示された。さらに，特許審査官による拒絶査定の予測結果に基づいた選好最適化により特許文書の補正性能が向上することを示した。
Q10-1,筆者らは技能者からその技能について聞き出すインタビューを収集した技能者インタビュー対話コーパスを構築し，このコーパスを用いてコツを含む発話(コツ発話)を効果的に引き出すインタビューの特徴を解明することを目的として研究を行っている．本論文はこの技能者インタビュー対話コーパスにおける多面的なアノテーションを用いて，コツ発話の表出を予測するロジスティック回帰モデルを構築し，その予測精度とモデルの特徴，またそこから考察されるコツ発話の表出に関わるインタビューの特徴について報告する．
P9-18,大規模言語モデル(LLM)の発展に伴い，旅行計画や経路探索などの実世界の応用タスクを自律的に解決する LLM エージェントの実現が期待されている．しかし，単一の LLM エージェントが複数の制約を同時に満たすプランニングを行うことは依然として困難である．この課題に対し，タスクを細分化して負荷を分散させるマルチエージェントシステムの協調アプローチが有効であると考えられる．本研究では，実世界旅行計画ベンチマーク『TravelPlanner』を対象とし，複数制約充足プランニングにおけるマルチエージェントシステムの有効性を検証した．実験の結果，制約充足率の向上が確認された一方で，エージェント間の情報伝達の欠落など，マルチエージェントシステム特有の課題も確認された．
P7-21,農業の栽培技術や取り組みは、国内の各自治体や公共団体、農協、その他の民間企業などがそれぞれ独自に取りまとめたデータがそれぞれのサイト上などから公開されている。しかしながら、これらの知識は機械可読な形式で提供されていることは稀で、現状の生成 AI などでうまく活用できているとは言い難い。本研究では、そのようなデータから、AI で利用しやすい形のデータセットとして、インストラクション形式でのデータの半自動構築を行う手法を提案する。また、既存の生成 AI がこれらのウェブ上のデータに含まれる知識をどの程度学習しているかについても検証を行った。
A2-6,本稿では，選択体系機能言語学の理論枠組みに基づき，大規模言語モデル（LLM）の社会的知能を評価するための新しいフレームワーク「JaSocial」を提案する．この理論を日本語敬語の使用に適用することで，敬語表現が持つ社会的背景や役割に基づき，より詳細かつ包括的に LLM の能力を分析することができるフレームワークを設計した．さらに，このフレームワークの運用を支える専用の評価データセットを新たに構築し，様々な LLM による日本語敬語生成の適切性を多角的に検証するための土台を提供する．
C4-5,VLM の工業製品画像に対する認識性能を調査するため，MVTec-AD データセットに含まれる 15 種類の工業製品画像を使い VQA タスクを実施した．実験では，VLM に被写体とその状態に対する質問と回答の選択肢を入力し，VLM の回答の再現率を評価した．その際，参考画像を与える場合と与えない場合の二通りを評価した．被写体に関する質問では，参考画像を与えなくても高い再現率となる製品があることや，参考画像を与えることで再現率が上昇する製品があることを確認した．一方で，参考画像を与えることでかえって再現率が低下する製品も存在した．被写体の状態に関しては，参考画像を与えることで回答の再現率は上昇する傾向があるが，全体的には被写体を回答することに比べ再現率は低いことを確認した．
Q3-3,自動運転技術の関連研究に用いられる走行データを効率良く応用する場合，交通状況を理解するための詳細な認識が重要である．そこで，走行データの認識に，走行中の自車から撮影されたカメラ画像を深層学習ベースモデルによる分類で得られる情報を用いることが有効な手段として挙げられる．本研究では，画像情報のみを扱う Convolutional  neuralnetwork(CNN)ベースモデルと画像とテキストの両方の情報を扱える Vision Language Model(VLM)の走行画像認識性能を評価・比較する．実験の結果，VLM が詳細なラベルである走行エリア，走行場所，路面状況，渋滞状況，掠れた白線の有無，工事規制されている車線の有無のラベルにおいて，CNN ベースモデルの精度を上回ったことが確認された．
E10-4,"In natural language processing, it has been empiricallyknown that skip-grams, co-occurrence statistics of twowords with some number of words in between them, isan eﬀective source of data to learn semantic nature of thewords. In this study, we propose a new theoretical accountfor why a set of skip-grams is eﬀective at least for two-wordlanguages, by giving a theorem that a set of trigram prob-abilities is representable with a set of skip bigrams. Thisrepresentation theorem justiﬁes the use of skip bigrams orso-called shiftgrams as a computationally eﬃcient sourceto access higher order n-gram."
P5-18,対話履歴に基づき、合成音声のスタイルを制御する手法を検討する。対話履歴を考慮するため、提案モデルは、大規模言語モデルによって得られた対話履歴の埋め込みに基づき音声を合成する。実験では、Emotional Speech Database を用いて擬似対話履歴付き音声データセットを作成し、モデルを学習した。実音声と合成音声の発話スタイルの類似度を 5段階で主観評価し、提案モデルに対話履歴を入力せずに音声を合成する手法と性能を比較した。その結果、提案手法は 3.1 ± 0.18、比較手法は 2.3 ± 0.19 となり、対話履歴に基づく発話スタイル制御の有効性が示された。
P2-11,本論文では，FFN 層のニューロンや，アテンション層のアテンションヘッドが誤字を認識・修復しているという仮説を立て，誤字を含む文が入力されたときに活発に働く，誤字ニューロンおよび誤字ヘッドを特定する．我々の実験結果から以下のことが判明した．1)初期層と中間層前半に誤字の認識と修復を行うニューロンが存在し，中間層前半にあるニューロンが誤字の修復の中核である．2)広く文脈情報を捉えるヘッドが誤字の修復に貢献している．3)誤字ヘッドの中には，単語の意味的な繋がりを認識するヘッドが存在した．
E5-4,出資判断や自社 IR 活動，テーマ型投資信託の組成，事業推進時のパートナー選定といった金融実務の場において，類似企業間や競合企業間での比較分析を行うことが多い．ここで，「企業間類似度の算出」に関する有用なのがテキスト情報に対し BERT等を活用することで獲得できる企業埋込表現である．このテキストデータをベースとする埋込表現は有効である一方，経済・金融分野においては株価や売上の推移やセグメント別売上等の数値データや株のや特定投資株式を始めとする株式保有情報等，企業間類似度を測る上で有用と考えられる数値データも多く存在し，これらの金融数値データとテキストデータを組み合わせることでより有用な「企業間類似度」を算出することが期待される．そこで，本研究では，銘柄テキスト情報だけでなく，セグメント別売上や株価時系列データ，株式保有情報も活用した「テキスト情報」と「数値情報」をハイブリッドに活用した企業間類似度を提案する．
Q1-1,孤独感に苛まれている人を発見し介入するために，ウェブ上のテキストから孤独感を捉えるためのデータセットがいくつか構築されている．しかし，既存のデータセットは，主に読み手による評価に基づいており，書き手自身が感じる孤独感と乖離している可能性がある．本研究では，孤独感に関する自由記述と書き手自身の孤独感の程度をクラウドソーシングにより収集し，この自由記述に対する読み手の評価も含めたデータセットを構築した．さらに，そのデータセットを用いて，書き手との孤独感を機械学習モデルが予測可能か検証した．コーパスを構築した結果，読み手と書き手の評価の一致率は0.666 に留まり，一定の難しさがあることがわかった．さらに，これを機械学習で予測した結果，書き手の孤独感の予測は正解率が 0.771，F 値が 0.633 で困難であることが明らかとなった．
Q5-21,"テキスト埋め込みから元のテキストを復元する方法を, Vec2Text[1]とは別のアプローチで考えた.そのアプローチは,テキスト生成において予測制御の考えを用いる方法である.予測制御によるテキスト生成を用いると, Greedy Search によりテキスト生成した場合よりも性能が向上した.具体的には, 2 つのテキストの内容が一致する割合が最大 0.120 だけ向上した."
D8-1,本研究では，対話時のターンテイキングにおけるターン速度の違いとその要因を明らかにするため，話者の役割，関係性，性格特性に着目し分析を行った．その結果，ターン速度は話者の役割や関係性，個人特性に大きく依存することが確認された．初学者と専門家間の対話では，初学者が発話の準備に時間を要するためターン速度が遅くなる傾向が確認された．また，友人同士の会話では沈黙が許容されやすく，初対面に比べてターン速度が遅い結果が得られた．さらに，BIG5 の性格特性において，開放性，協調性，勤勉性および神経症傾向がターン速度に影響を与えることが明らかになった．
D10-1,生成モデルとして広く使用されるようになった大規模言語モデル(LLM)の使用用途の 1 つとして、学習データ生成が検討、研究されている。本研究では、LLM を用いたクイズデータの自動生成と評価により、学習データの拡張を実施し、質問応答に応用する。生成したクイズについて LLM と人手による評価を比較した結果、LLM は基本的なルールや文法を理解してデータを評価できる一方で、文字数のカウントなど一部に苦手な要素が存在することを確認した。また、生成されたクイズデータを質問応答システムに応用した結果、人手の学習データには及ばないものの、学習効果があることを確認した。
Q2-14,本論文では，評価結果の予測確率を用いる大規模言語モデル（LLM）による LLM の新たな相対評価手法を提案する．従来の相対評価では，評価対象LLM の提示順を入れ替えた際に評価結果が変動する位置バイアスが生じた際，最終的な評価結果を適切に定める手法が確立されていない．そこで，本研究では，位置バイアスが生じた際に，提示順入れ替え前後の評価結果の予測確率の平均が最も高い結果を最終的な評価結果とする手法を提案する．そして，本提案手法を文章作成等のビジネスタスクを対象に評価し，有効性を確認した．
D10-5,少子高齢化が進む中で，高齢者の健康状況を適切に把握することは重要な課題である．そこで本研究では，日常的な雑談の中で所望のアンケートの回答を聞き出し，高齢者の負担なく健康状態を把握することができる質問誘導に基づくアンケート対話システムを提案する．また，対話で得られた回答を適切な選択肢に対応づけることで，アンケートと同じ形式の回答を得る手法を提案する．人間評価実験と，高齢者に実生活でアンケート対話システムと 2 週間対話してもらう実証実験を行い，アンケート対話システムがアンケートを代替し得るかを検証した．
D8-5,小説中の発話文の発話者がどの登場人物かを分類する発話者分類タスクは，小説や登場人物の分析において重要なタスクである．英語・中国語小説を対象とした発話者分類では深層学習モデルを用いた手法の有効性が確認されているが，日本語小説に対する先行研究では主に規則を用いた手法が検討されている．そこで本論文では，日本語小説を対象とした発話者分類タスクに大規模言語モデル(GPT-4o，Gemini，Claude)を適用した際の性能評価を行う．評価用データとして，複数のウェブ小説に発話者情報をアノテーションしたデータを用いる．本論文では，大規模言語モデルを用いて「小説登場人物名リスト作成」・「発話文への発話者対応付け」という二段階の処理を行い，小説登場人物を回答単位とした発話者の推論を行う．この結果，どの大規模言語モデルにおいても正答率が 85%を超え，日本語小説を対象とした発話者分類における大規模言語モデルの利用が効果的であることを示した．
Q2-10,"Given the growing use of Large Language Models(LLMs) in diverse cultural contexts, this study examinestheir adaptability to Japanese workplace norms using Hof-stede’s Cultural Dimensions Framework. Five multilingualLLMs from Japanese, English, and Chinese backgroundswere tested with prompts reﬂecting six cultural dimensions,and their outputs were analyzed for alignment through sen-timent analysis. Results reveal varying levels of culturalalignment, with models reﬂecting biases tied to their train-ing contexts. The study highlights the importance of di-verse and culturally representative datasets to improve theadaptability of LLMs in speciﬁc cultural settings."
Q5-19,講演を対象とした字幕生成システムにおいて，講演文特有の長い文が複数行にまたがって表示されると読みやすさが低下するため，適切な位置に改行を挿入し，読みやすい字幕を生成する必要がある．本稿では，読みやすい字幕を生成するための要素技術として，文末を未知とした問題設定において，漸進的係り受け解析結果と残存文長推定結果を考慮した逐次的な改行挿入手法を提案する．
C6-3,近年，深層学習を用いて任意の難易度で読解問題を生成できる技術が提案されている．しかし，従来手法は，読解対象文中から答えを抜き出して回答する形式の問題のみを対象としており，教育現場で広く使われている多肢選択式問題を生成できない．加えて，従来手法では訓練データ中の問題の単語列に対する尤度を最大化するように深層学習モデルを訓練しており，難易度調整精度を直接最適化していないため，難易度調整精度に改善の余地が残る．そこで本研究では，自己回帰型の深層学習モデルを用いた難易度調整可能な多枝選択式問題生成手法を開発するとともに，Direct Preference Optimization により難易度調整精度を最大化する訓練手法を提案する．
Q1-5,法令の改正に伴い，その訳文を修正する際には，改正箇所のみを差分的に翻訳し直す必要がある．改正前の訳文（旧訳文）の表現をコピーして訳文を生成できる 2 入力 NMT は，差分的な翻訳を可能とするが，2 入力 NMT の訓練には原文，旧訳文，訳文の三つ組が必要であり，言語資源の調達コストが大きい．そこで，本研究では，法令文の対訳コーパスから疑似的な三つ組を構築する．対訳コーパスの訳文に対してフレーズをランダムに削除又は置換した文を旧訳文とみなし，元の原文，訳文と合わせて三つ組とする．構築した三つ組コーパスを 2 入力 NMTの訓練に使用したところ，三つ組の生成元である対訳コーパスにより訓練した NMT の性能を上回った．
B9-4,現代語用の UniDic をベースとして関西方言を対象とした形態素解析用の辞書「関西弁 UniDic」の拡張を行い、方言特有の見出し語の追加、特に機能語の品詞や活用形の整備を行った。また、短単位データとして整備した関西方言用の学習用コーパスを大幅に充実させ、これらのデータを用いて MeCab 用の辞書を作成した。さらに、各種の学習用コーパスを組み合わせて解析精度の検証を行った。これにより従来より高い精度で、広域の関西方言の会話書き起こしテキストを解析することを可能にした。
P5-20,"本論文では,音声翻訳システムにおいて,音声基盤モデルである Whisper の分散表現を言語基盤モデルである LLaMA2 の分散表現と結合する ReShapeAttention (RSA)を提案する. RSA は, LLaMA2 のTransformer 層の内部に挿入され,音声とテキストの分散表現を,同じ特徴次元のサブベクトルに変形し, 2 つの分散表現間で Cross-Attention を実行する.RSA により, LLaMA2 と Whisper の勾配グラフは接続され,音声翻訳システム全体を入力音声に対して最適化できる. RSA は, Whisper と LLaMA2 を用いたCascade 音声翻訳システムと比較して, BLEU スコアを相対的に 8. 5%向上させた.さらに, RSA は正解の書き起こしが得られる場合において Cascade システムよりも音声翻訳精度を向上させる可能性があることが示された."
P2-15,多言語モデルの有用性は埋め込みによって支えられている。しかし、多言語で事前学習された言語モデルの埋め込みに内在すると考えられる単語の意味表現の分析は行われていない。本研究では、多言語翻訳モデルを対象に独立成分分析を用いて埋め込みを分析・可視化することによって、モデルの言語理解や層を横断した言語処理の流れについて調査した。分析の結果、入力に近い層では表層形によって軸が分離し、出力に近い層では意味によって分離する傾向がみられ、層を経るごとに文脈や意味情報を獲得することが示唆された。
C4-1,"ストレスや不安によるうつ病が世界的に増加しており,日本でも深刻な問題となっている.しかし,カウンセラーや精神科医の不足により早期発見が困難である.本研究では,我々の研究グループで構築しているカウンセリング面談時の言語・音声・動画・心拍及びアンケートデータから成るデータセットを用いて,最新の Mamba ベースのマルチモーダルうつ状態検出モデルの学習・評価を行った.その結果,既存の大規模データセットを用いた事前学習と本データセットでの微調整が,モデル性能の向上に効果的であることが分かった."
E7-2,本研究では，J-REIT の投資物件に関する表から情報を抽出するために，HTML 形式の表を JSON 形式の構造化データに変換する手法として，大規模言語モデルを用いた Few-Shot プロンプティングに基づく手法を提案する．実験の結果，既存の Zero-Shotプロンプティングに基づく手法よりも大幅に精度が向上することを示した．特に，同一の J-REIT の表をサンプルとした場合，変換精度は 98.70%に達し，実務への応用可能性を示唆する．
A2-2,近年の大規模言語モデルの研究において，様々なモデルの評価結果が一覧できるリーダーボードの重要性が増している．本研究では LLM-jp と HuggingFace の協力のもとにオープンソースで開発かつ運営される Open Japanese LLM Leaderboard を構築した．本リーダーボードでは大規模言語モデルの評価フレームワークである llm-jp-eval を用いて日本語大規模言語モデルの性能を評価し，その結果をリーダーボードとして公開している．本稿ではリーダーボードの詳細を紹介し，さらにこれまでに得られた評価結果を用いた統計分析を行い，日本語大規模言語モデルの評価結果に対する知見を報告する．
Q3-7,近年，大規模言語モデル（LLM: Large LanguageModel）を活用した物語の視覚的表現が注目されているが，物語のセリフや感情，キャラクターの行動といった本質的要素を取り入れる試みは十分に行われていない．本研究では，LLM を用いて Chain ofThought（CoT）Prompting により物語を解析・分割し，画像生成プロンプトを構築する新たな手法を提案する．本手法の特徴は，物語中のセリフを含めた可視化に焦点を当てる点にある．CLIP Score による評価実験では，提案手法が物語本文からそのまま画像生成する手法に比べ，セリフの有無に関わらず視覚的情報が画像に正確に反映されることを示す．
P7-25,ダイアグラムを理解できる AI モデルの実現は，学習支援や情報処理の効率化において重要である．しかし，画像理解タスクで顕著な成果を上げている大規模視覚言語モデル（LVLM）であっても，ダイアグラムのような抽象的かつ構造的な画像の理解には限界がある．本研究では，LVLM がダイアグラムのどのような視覚情報を認識しているか，またそれらの情報をどのように保持しているかを明らかにするため，画像エンコーダおよび LLM の隠れ状態を用いてプロービングを行った．その結果，ノードの色や形，エッジの色や有無の情報はどの層でも 10次元程度の低次元の線形部分空間に保持されていたが，エッジの向きの情報は 10 次元程度の低次元空間には保持されていなかった．また，パッチ単位のプロービングにより，ノードやエッジが描かれていない背景の隠れ状態に，複数のノードやエッジの情報がまとめて保持されていることが示唆された．
P7-19,法的に取得が制限される要配慮個人情報は，大規模言語モデル（LLM）の構築に必要な大規模な事前学習用コーパスに含まれる可能性があり，その検出とフィルタリングは重要な課題である．本研究では，文章内の要配慮個人情報を検出するために，要配慮個人情報データセットを構築し，機械学習モデルを学習させた．その結果，要配慮個人情報のジャンルと関係する情報を高速に検出する判定器を構築できた．
P8-4,インターネット上には様々なコンテンツが溢れていて、ユーザはライフサイクルに沿ってそれらを利用する。メディアは閲覧数に応じた収益を獲得するため、コンテンツとユーザの時間特性を把握し閲覧数を増大させることは重要なビジネステーマである。本研究では Wikipedia の記事内容と閲覧ログを用いて、内容とユーザの興味の時間特性を明らかにする手法を提案する。最初に内容が類似するWikipedia 記事は閲覧される時間帯が類似することを示す。次に独立成分分析を利用して異なるユーザグループの時間特性を抽出し、それらが直感的なライフサイクルと一致することを確認する。これまでの議論から記事内容と閲覧傾向に密接な関係があることが期待できるため、最後にニューラルネットを使って記事内容から閲覧傾向を直接予測できることを示す。本研究は Wikipedia の記事について注目しているがシンプルな手法ゆえ、閲覧ログが取得可能なあらゆるコンテンツで適応可能である。
P9-20,キャプショニングなどを用いた状況認識により，動画内のユーザ行動を自然言語で表現することが可能になった．しかし，このように認識されたユーザー行動を事前に定義された行動予定と比較して履行判断に用いようとする場合，テキストで表現される行動の粒度が問題となる．そこで，本研究では言い換えモデルを用いてテキストで認識した動画内のユーザー行動を言い換え，行動予定に対してアライメントを取るモデルを提案する．言い換えによって生成された行動とあらかじめ定義された予定行動を自動評価手法によって比較し，履行が判断できる閾値を設定することで予定の履行を適切に評価できることを確認した．
E1-4,遺跡の発掘調査後に作成される発掘調査報告書には、出土した遺物や遺構をはじめとする重要な考古学情報が含まれている。しかし、全国の発掘調査報告書を合算すると、その数は膨大であり、人手で全てを読み解くことは困難である。そこで本研究では、発掘調査報告書から自動的に考古学情報に関する記述（出土した遺物や遺構、それらの時代や数など）を抽出する手法を検討した。まず、奈良文化財研究所が公開している発掘調査報告書の PDF を対象に、考古学情報と判断される表現に対して人手でアノテーションを施し、評価データセットを構築した。構築したデータセットに対して、ChatGPT を利用して考古学表現の抽出し、その性能を評価した。精度(Precision)が 17 ％前後、再現率(Recall)が 30 ％程度という結果となり、まだ改善の余地が大きいことが明らかになった。
A4-4,社会的バイアスと文化的常識はどちらも社会に根付いた規範や価値観の理解に関するものであり，密接に関わる．これまで，大規模言語モデルの持つ社会的バイアスの抑制手法において，モデルの他の側面への影響は一般的な能力を測るタスクで評価されてきた．しかし，より関連が深い問題である文化的常識への影響については考慮されていない．本研究ではモデルが持つ社会的バイアスと文化的常識の両方を評価するデータセットを提案する．実験ではプロンプトによる社会的バイアス抑制手法が与える，文化的常識に基づく推論性能への影響を検証する．実験の結果，モデルの社会的バイアスの抑制と文化的常識理解タスクの性能低下には相関が見られた．注意:本論文には差別的な表現が一部含まれます．
Q10-5,本研究は，大規模言語モデルを用いて知識階層を自動構築し，視点の異なる複数の LLM による協調的な評価を通して上位下位関係の誤りを検出・訂正する手法を提案する．大規模言語モデルを用いて知識階層を自動構築すると階層関係の誤りが避けられないため，異なる視点が与えられて偏向した複数のLLM エージェントが協調的に誤りを検出することでその自動訂正を目指す．具体的には，LLM が生成した初期オントロジーに対して，複数の LLM がそれぞれ異なる視点から階層関係の正しさを評価する．これにより，単一の LLM では捉えきれない誤りを検出することが可能とする．交通教則文書からの概念階層構築に関する実験において，LLM の協調により階層誤り検出の F1 スコアを 5 ポイント向上させることができ，その有効性が示された．
Q5-1,"Generative linguistic steganog raphy aims at embeddinginformation into natural language texts for covert transmis-sion. However, in most tokenizer-based language modelapproaches, segmentation ambiguity during extraction canresult in errors or extraction failures. Despite several ex-isting countermeasures (or disambiguation) that have beenproposed, none address this issue from the perspective oftokenization consistency. Speciﬁcally, previous methodsexcessively modify candidate pools, compromising imper-ceptibility or embedding capacity. To address it, we pro-pose a stepwise tokenization-veriﬁcation method whichprecisely removes error tokens for each step, ensuring100% tokenization consistency in the ﬁnal output. Ex-perimental results demonstrate that our method surpassesbaseline approaches in text quality, imperceptibility, andanti-steganalysis capacity across various embedding rates."
Q9-19,含意関係認識は、ファクトチェック自動化において有望なアプローチの一つである。しかし、既存の含意関係認識手法をそのまま適用するだけでは、正確な検証が難しい場合がある。本研究では、前提文や仮定文を個別の事実に分解し、分解した要素に対して含意関係認識を行う手法を提案する。独自に構築したファクトチェック性能評価データセットにおいて、提案手法を導入することで LLM 単独よりもgpt-4o において 9.34、llmjp-3 において 20.67 ポイントの Accuracy 向上を達成し、その有効性を示した。
Q7-20,内閣府「研究開発と Society 5.0 との橋渡しプログラム（BRIDGE）」の農林水産省課題「AI 農業社会実装プロジェクト」では，国内農業知識を学習させた LLM の開発を進めている．これを実現するには，国内に散在する農業に関するデータを収集し，機械可読な形式へ変換する必要がある．本研究では，多くの都道府県から公開されている農業基準技術に関する文書を対象とし，そこに含まれている，人手で作成された経営類型や技術体系や作業別労働時間などの表から適切な形式でのデータの抽出を目的とする．本稿では，その基礎的な分析として，PDF 形式の表を CSV 形式に変換する際に生じる課題を明らかにした．
A6-6,本研究では，事前学習済み BERT に対する対照損失による追加学習が，下流タスクのファインチューニングに与える影響を実験的に調査する．実験では，事前学習済み BERT と，それを SimCSE で学習したモデルをファインチューニングするときの学習の安定性とモデルの可塑性の二つの観点で分析した．実験の結果，SimCSE で追加学習したモデルでは，(𝑖 )大きい学習率でのファインチューニングがより安定的になり，(𝑖𝑖) パラメータに関するフィッシャー情報行列の有効ランクが回復することで，モデルの可塑性が向上することがわかった．
E3-6,本研究では，BERT により形態素解析用の辞書の推定を行うことで，近代以前の日本語文書の形態素解析の精度を向上させる手法を提案する．形態素解析用の辞書作成時に用いたデータを用いて BERT をﬁne-tuning し，文書分類を行うシステムを作成した．形態素解析の対象文書を，作成した文書分類システムに入力し，出力された文書クラスの辞書を用いて形態素解析を行った．また，二つのベースラインとその文書の正解の辞書を用いた手法（Oracle 手法）と比較した．実験の結果，提案手法はベースラインを常に上回り，いくつかの文書では Oracle 手法を上回った．
P4-9,イメージスキーマとは認知言語学において、認知プロセスに繰り返し現れるパターンを表現する図である。しかしこのパターンは人間が同定する必要があるため、全てを網羅的に発見することは困難であった。本研究では英語の動詞を対象に、大規模言語モデル（LLM）と画像生成モデルを用いたイメージスキーマの生成を行った。評価の結果、画像生成モデルでは生成が困難であったが、LLM は LaTeX（TikZ）のコードとして、人間と LLM 双方にとって解釈性の高いイメージスキーマを生成できることが示された。これは LLM を用いたイメージスキーマの網羅的発見の可能性を示唆するものである。
Q7-3,自律型ロボットと人間が共生し，自動運転車が公道を走行する世の中では，それらの行動が，人間があらかじめ定めた法律や規則に沿ったものであるか説明できる高精度な規則適合判定が重要である．また，セキュリティの側面から，ローカル環境での規則適合判定技術の精度向上も重要である．本研究では，普通自動車免許学科試験問題を題材とし，現在比較的高精度とされる軽量 LLM を用い、判定理由も出力可能な規則適合判定をローカル環境で行い，規則適合判定の特徴などについて分析を行った．その結果，論理推論能力による出力の影響が大きいことや，「正」「誤」の判定能力に偏りがあることがわかった．
Q7-2,法律実務においては，法令や判例に加え，専門書籍やガイドラインなど，多様な情報源の関係性を総合的に把握することが不可欠である．しかし，これまでの研究は主に法令や判例間の関係性に焦点を当てており，書籍やガイドラインとの連携については十分に検討されていなかった．本研究では，これらすべての情報源を包括的に結びつける大規模な引用グラフを構築し，その実務的有用性を検証した．その結果，質問応答タスクにおいて，本引用グラフを活用することで，適切な法令・判例の選出が可能となっただけでなく，法的な正確性を保ちながら，人手で作成した回答よりも好ましい回答を生成できることが明らかとなった．
P10-1,"本研究は,法的自然言語処理タスクにおいて大規模言語モデルの推論性能を向上させる,新しい段階的推論手法を提案する.提案手法は法的三段論法に基づき,事例整理,条文整理,あてはめ,結論という 4つの手順に沿って条文と事例の整合性を論理的に評価することで,解答の精度と解釈可能性の向上を図る.我が国の司法試験（民法短答式問題）の自動解答性能を評価する COLIEE データセットを用いた実験で,提案手法のプロンプトを適用することで,GPT-4o, Llama3.1 および COLIEE 2024 の最高性能手法のいずれに対しても accuracy で 1.8 ポイント以上の性能向上を達成した.提案手法は LLM 非依存であると考えられるため,現時点の State-of-the-Art の性能を達成したといえる."
P4-8,"音が特定のイメージを喚起する現象を音象徴という.本研究では,機械学習を用いて音象徴の分析を行うことを目的とした.具体的には,日本語のポケモン名を材料に,モデルを作成し,進化前後の分類予測を行った.また,作成したモデルにおける各音韻に対する重要度を分析した.その結果,一定の性能で音象徴性を予測できることが確認された.さらに,音韻の重要度の分析により,従来から音象徴に影響を与えるとされる音韻がモデルに反映されていることが明らかになった一方で,既存研究では注目されていなかった音韻も何らかの影響を及ぼしている可能性が示唆された."
Q7-21,"新型コロナワクチン接種期間中の人々の考えや関心の変化を知るために，「ワクチン」を含む日本語の全ツイート(1.1 億件)を分析した．先行研究では大きな世論のダイナミクスを捉えることに成功したが，本研究ではツイートのより詳細な内容とその時間変化を明らかにすることを目的とした．まず LDAトピックモデルを用いて 15 の主要トピックを特定し，トピックの内容を人手で意味解釈して 4 つの主要なテーマに分類した．次に月毎の頻出単語分析と約15,000 件のツイート精読を組み合わせ，各トピックの話題変化に関する仮説を構築した．最後に，トピック内での単語の時間変化を調べ，仮説の妥当性を定量的に検証した．その結果，「怖い」という気持ちや強い意見をあらわすツイートは，接種の先行きが最も不明瞭だった時期に多く，その後減少したことや，ワクチン接種を受ける人物が医療従事者，高齢者から自分自身へと変化するのに対応して，ツイートで言及される対象も変化したことが示唆された．"
Q9-18,自然言語推論において、理論言語学に基づく解析手法では、推論の精度は統語解析の妥当性に依存する。統語解析の妥当性を保証するには、パーザの学習・評価に用いるデータが言語学的に妥当であることが重要であるが、統語構造を提供するツリーバンクの妥当性評価は十分に行われておらず、従来の手法では言語学的妥当性を適切に捉えることができない。そこで本研究では、理論言語学と型理論を基盤とする新たな評価手法を提案し、この評価手法を用いてツリーバンクの妥当性評価を行う。
Q10-4,生物医学分野における大規模言語モデルを用いた固有表現抽出を対象に，抽出モデルに合わせた用語情報の取得を行うために，一度，抽出した候補について用語情報を取得し，その用語情報を利用して再度抽出を行う 2 段階の抽出手法を提案する．また，取得した用語情報の種類及びその組み合わせが抽出性能に与える影響を調査する．統合医学用語システム UMLS を用語辞典として，BC5CDR データセットを対象に評価を行った結果，用語情報を利用することで，提案手法による抽出性能の向上を確認できた．特に用語の定義とカテゴリを，用語の定義がない場合に親概念の定義を利用しながら，組み合わせる方法が有効であることがわかった．
E1-5,歴史的テキストからの場所参照表現の抽出は，大規模な史料に対する人文学的分析を支援するための基礎技術として重要である．本研究では，近代・近世の日本語テキストを用いたデータセットを構築し，これら歴史的テキストに対する Transformer 言語モデルの抽出精度を調査した．実験から，現代語ラベル付きデータの活用の有効性を確認した一方で，歴史的テキストへの適応には，さらなるモデルの改善が必要であることも示された．
A4-5,本稿では、学習データ蒸留を逆向きに適用する学習データの逆蒸留を導入し、大規模言語モデルへの応用について議論する。学習データの逆蒸留では、ある学習データがもたらすモデルの変化と逆の変化をもたらす学習データを生成する。例えば有害な文章を含むコーパスを逆蒸留することで、モデルから有害な表現を忘却させる学習データが得られる。本稿では、一般的なコーパスに適用可能な、非常に軽量・単純な逆蒸留手法を導入し、モデルの有害性除去を例にその有効性を検証した。逆蒸留された文章が、有害性を除去するための学習データとして機能することを、様々なモデルを通じて示した。
P9-21,"The purpose of this study is to investigate the knowledgeof personality in a LLM using a psychometric methodol-ogy. In Experiment 1, a standard psychological question-naire is used to measure the personality proﬁle of the LLMand showed that the model has some knowledge aboutpersonality. Experiment 2 examined the scores of BigFive personality questions in the LLM when a wide rangeof personality descriptions were submitted as prompts tothe model. The results showed that the LLM has similarpersonality knowledge as humans. Implications for LLMresearch and psychological research are discussed."
P8-5,近年の RAG (Retrieval-Augmented Generation)や検索システムでは，文埋め込みを用いた検索手法が注目されている．従来はキーワード一致に基づくTF-IDF ベースの検索が主流であったが，大規模事前学習モデルの発達に伴い，文埋め込みを用いた検索が盛んに使用されるようになった．しかしながら，文埋め込みがキーワードベースの検索に対して，どのような利点や欠点を持つかはまだ十分に明らかになっていない．特に日本語検索においては，多様な表記ゆれが検索精度に影響を与える一因となる．そこで本研究では，単語レベルの表記ゆれをクエリに与えた際，どのように文埋め込みベースの検索精度が変化するのかを検証する．実験では，JMTEB ベンチマークのうち JAQKET および JaGovFaqs-22k を用いて，同義語辞書によるクエリ変換を実施し、変換前後のクエリを使用した場合の検索精度への影響を分析した．さらに，文埋め込みに同義語を拡張したクエリ手法も提案し，その有効性を検証する．
P7-18,悪意を持つユーザーにより大規模言語モデル(Large Language Model: LLM)が Jailbreak 手法により攻撃され，虚偽情報の生成に悪用されることでフェイクニュースの拡散につながる懸念が高まっている．LLM の安全性を高めるには様々な攻撃に対する頑健性の評価が不可欠だが，フェイクニュースにおいて Jailbreak 手法の脅威に関するデータセットや評価指標は確立されていない．本稿では，フェイクニュース生成の Jailbreak に関するベンチマークを構築し，LLM の頑健性や出力されたフェイクニュースの評価を実施した．その結果から，Jailbreak 攻撃の成功確率とフェイクニュースの評価指標では攻撃手法ごとに異なる傾向が見られ，Jailbreak 手法の評価において LLM が出力した内容まで精査する必要があることが明らかになった．
P7-24,ChatGPT の登場により，対話型生成 AI システムに対する期待が高まっている．一方で，LLM が組み込まれた AI システムの利用にはプライバシーリスクが伴う．LLM のプライバシー保護研究は，学習データやモデルに含まれる個人のプライバシーリスクに関する対策が主流であり，AI システム利用時のプライバシーリスクに関する検討は十分でない．本稿では，LLM の生成結果が利用者に出力される状況におけるプライバシーリスクとその低減の重要性を述べ，そのリスクに対するプライバシー保護の既存研究を示すとともに，今後研究すべき領域について提案する．
Q3-6,"This paper proposes automatic data augmentationfor Live Commentar y Generation using Large Vision-Language Models (LVLMs). This task aims to generatea set of timed subtitles commenting on the contents ofa given video, describing the actions and objects in thevideo, and including additional information. Collectingdata for live commentary generation can be an expensiveand time-consuming task. Therefore, we propose a lesslabor-intensive alternative by utilizing LVLMs to generateartiﬁcial live commentary data based on frames extractedfrom videos. Our results using a simple live commentarygeneration model reveal that training on a combination oforiginal and augmented data has the potential for perfor-mance improvement in this task in terms of BLEU score."
E7-3,株式会社のガバナンスの中核を担う取締役会の構成は、時代の変化に伴い透明性や多様性の確保が求められてきた。近年では、取締役会の機能強化を支える手段としてスキル・マトリックスが注目されている。しかし、その作成は各企業に委ねられ、客観性や標準化の欠如が課題となっている。そこで本研究では、取締役のスキル・マトリックス分類モデルの開発を行う。具体的には企業の公開している取締役推薦理由文からスキルを抽出・データセットを作成し、スキルを定義するとともに，スキル分類を多ラベル問題として定義する。その上で、ラベル不均衡に対応する学習フレームワークを提案し、その有効性を実証した。
A2-3,本研究では、日本語事前学習モデルの文章生成性能を評価するためのベンチマークである pfgen-benchを提案する。本ベンチマークは Fluency(流暢さ)、Truthfulness(真実性）、Helpfulness(有用性)の 3 つの評価軸から構成される。まず、日本の小中高の学習指導要領を参考に、13 科目 50 問からなる、日本語圏特有の常識問題集を作成した。さらに、複数のLLM とルールベースのフィルタリング手法を用いて、高品質な参照回答群を構築した。その上で、さまざまなモデルの回答と参照回答群の近さをはかる3つの評価軸を設計し、生成結果の評価が可能なベンチマークを構築した。このベンチマークを使用した評価結果に基づくと、事前学習モデル間の性能差を明確に示し、LLM による従来の評価とも一致する点が確認された。構築したベンチマークは公開し、一般に使用可能である。
P2-14,"ニューラル言語モデルは,大量のテキストを用いた事前学習と指示チューニングによって,多様な知識と推論能力を獲得しているとされる.本研究では,言語モデルが有する時間に関する事実知識,特に過去の出来事の日付に関する知識について調査する.具体的には,過去の出来事が発生した年月日を回答するタスクのデータセットを構築し,言語モデルが出力する日付と実際の正解との間の誤差を分析する.実験の結果,言語モデルは年号に関する知識については,月日と比較してより正確に保持していることがわかった.また,年号を正確に認識できていない言語モデルは,実際の年よりも後の年代として推論しやすい傾向があることが示唆された."
E10-1,近年，言語による刺激とそれに誘起された脳活動との対応関係を捉えた事前学習済みマルチモーダル言語モデルである BrainLM が提案された．本研究では、このモデルをさらに発展させ、英語だけであった言語刺激をフランス語および中国語へと拡張し多言語からなる BrainLM の開発を行った．言語刺激の拡張には，転移学習を利用することで多言語タスクでのモデルによる脳内状態予測能力を向上させた.特に、英仏間の整合性判別のための二値分類タスクにおいて多言語対応した BrainLM は 51.75%という最高精度を達成した.また，脳内状態予測タスクにおいて，転移学習の前後で相関係数が約 3%から15%向上した.さらに、大脳皮質全体の脳内状態予測タスクにおいて，他のモデルと比べて BrainLM が最も高い相関を示した．本研究は、BrainLM の応用範囲を広げるだけでなく，さまざまな言語における大規模言語モデルとヒト脳機能との関係性についての理解を深めるものである.
B9-5,国立国語研究所共同研究プロジェクト「多世代会話コーパスに基づく話し言葉の総合的研究」では、子どもを中心とする多様な場面における多様な相手との会話を対象とする『子ども版日本語日常会話コーパス』（CEJC-Child）の構築を 2022 年度から進めている。これは、2022 年 3 月に公開した『日本語日常会話コーパス』で不足する子どものデータを補充するために計画したものである。収録対象は 8 世帯 12 名の子どもであり、100 時間規模のコーパスを構築するが、このうち 50 時間のデータを 2025 年 3月にモニター公開する。本稿では CEJC-Child モニター版の特徴について報告する。
P5-21,人間は二重分節構造を持つ連続音声信号を明確な境界点やラベルなしに音素や単語に分割し，単語の遷移規則を文法として学習することが可能である．音声信号の二重分節構造を学習するモデルを構築することは，人間の言語獲得過程を構成論的に解明するために重要である．そこで本稿では，Gaussian Process Hidden Semi Markov Model(GP-HSMM)と Hidden Semi Markov Model (HSMM)を階層的に接続し，連続音声信号から音素，単語と文法を学習することが可能な新しい確率的生成モデルを提案する．提案手法では，各統計モデルのパラメータを相互に更新している．そのため，音素と単語と文法が相互に影響し合った学習を可能とする．実験では，文法学習を含む提案手法が，文法学習をしない従来手法よりも高い精度で連続音声信号を音素と単語に分割・分類できることを示した．また，文法学習が文中の単語数の正確な推定に大きく寄与することを示した．
Q1-4,話者の説得力、および、聴者の納得度を自動で推定することが可能となれば、自学自習による練習機会が増え、営業スキルやコミュニケーションスキルの向上につながる。本研究では、オンライン会議において話者の説得力や聴者の納得度をラベル付けしたデータセットを構築した。話者と聴者が明示的に交代するディベート形式を採用し、肯定側 1 人・否定側 1 人・判定者 1 の合計 3 人での会議を 115 セッション収録した。第三者から見た説得力や論理性、聴者の納得度などのアノテーションを実施した。ラベルの分析からは、説得力と論理性には相関係数0. 796 の強い正の相関が、説得力と判定者の納得度については相関係数 0.554 の正の相関が、それぞれ見られた。
E5-1,企業が公開する決算短信には，事業の結果について述べる文のほかに，将来の業績や事業計画などを見通す文が含まれる．事業の見通しとその結果を比較できれば，企業ごとに見通しの傾向を知ることができる．それにより，投資家は企業について，より正確に予測できる．しかし，投資初心者が決算短信を分析することは容易でない．本研究では，投資初心者の支援のために，時系列に並んだ決算短信の間で，それらに出現する見通し文と結果文をアラインメントする．具体的には，文の類似度や大規模言語モデル(LLM)を単独で用いる手法に加えて，それらを併用する手法を検証する．その結果，LLM を用いる手法が最も有効であることを明らかにした．
C6-2,近年，小論文自動採点タスクの一つとして問題横断型自動採点が注目されている．しかし従来の問題横断型自動採点では様々な問題に対する採点済み小論文データを全て訓練に利用するため，目的の問題の自動採点に悪影響を与えうるデータまで訓練に利用される可能性がある．この問題を解決するために本研究では，訓練データの価値を評価し，モデル学習に悪影響を及ぼす可能性のあるデータを除外することでその採点精度を向上させる手法を提案する．
Q2-11,本論文は、プログラムのソースコード用の言語モデルの性能を適切に評価する際に重要となる、モデルの事前学習における評価データの混入の問題について論じる。まず、コード用のモデル向けのベンチマークを網羅的に調査し、一部の評価データの内容が本質的に GitHub 由来の学習データ重複しうるという実態を示す。また、混入除去の妥当な方策として、評価データと学習データの間の文字列の一致の検出に加えて、由来となるレポジトリの情報を用いる手法を提案する。
Q5-18,大規模言語モデル（LLM）の出現により、機械による文生成の能力は大きく向上した．それに伴い、LLM の出現以前に利用されていた文生成能力を測るタスクは現在の LLM の能力を測る指標としては適切なものでなくなってしまったものが多い．その一つに常識推論能力を測る CommonGen がある．本研究では、文生成タスクの CommonGen における入力単語を特定の分野に絞った専門用語にすることで、さらに高い文生成能力を求められるタスクにする試みを行った．更に試験的に作成したデータセットを用いて、LLM による生成文の評価と人手評価を行い、LLM の文生成能力と自動評価の可能性について調査した．
D10-4,対話要約は，対話を事後に確認して内容を把握するだけでなく，進行中の対話に途中から参加する対話の引継ぎにも有用と考えられる．しかし，対話要約には，文章形式，対話形式，キーワード形式などの種別があり，これらの中でどれが最も対話の引継ぎに有用であるかは明らかでない．そこで，本研究では，対話要約の種別が対話の引継ぎに及ぼす影響の定量的な評価を目的とし，これらの種別について要約を作成した上で，対話を引継ぐ際の負荷と，要約を基に作成した次発話の適切さを評価した．結果として，対話の引継ぎには対話形式の抽象型要約が有用であることが確認できた．また，対話の引継ぎにおける，要約の各種別の特性を明確化できた．
D8-4,高度な言語理解能力に加えて人間的な感性をも備えつつある高性能大規模言語モデルを、人手評価の代替手段として活用することに関する議論が近年広がりを見せている。しかし、大規模言語モデルによる人手評価の代替については、いまだ現行技術の限界や致命的な課題など未解明の側面も多く、言語やタスク横断的に広く知見を収集することが重要な段階にある。本研究は、日本語を対象として、対話データの品質評価における大規模言語モデルの活用について経験的な知見を提供するものである。評価軸や回答形式が異なる複数の評価設定において、モデルの評価性能や動作傾向がどのように変動するかを定性的および定量的に調査し、結果を報告する。
D8-6,人間同士の対話における発話のオーバーラップや相槌など，同時双方向的な特徴をモデル化できるfull-duplex 音声対話システムは，近年注目を集めている．しかし日本語においては，full-duplex 音声対話システムはほとんど見られず，full-duplex 音声対話システムの開発に関する知見は不足している．本研究では，英語における主要な full-duplex 音声対話システムである Moshi をベースとすることで，日本語で利用可能な最初の full-duplex 音声対話システムを試作し，公開する．1）
D10-6,近年の対話システムの飛躍的な発展にもかかわらず，3 人以上のマルチパーティ対話に対応した対話システムは少ない．そこで，我々は，そのような対話システムを実現するための対話リソースとして，マルチパーティ対話コーパス Multi-RelationalMulti-Party Chat Corpus (MRMP)を構築した．本コーパスは初対面の話者のみからなる初対面対話と家族関係の話者と初対面の話者からなる家族入り対話の2 種類の対話を含む．本稿では，構築したコーパスを用いた分析により，話者間の関係性が対話に与える影響を明らかにする．
Q2-13,LLM が起こす幻覚には様々な種類がある。例えば、存在しそうで存在しない「架空語」の意味を尋ねた際、LLM は「知らない」と答えるのが望ましいが、誤った説明や別の語の意味を返すことがある。本論文では LLM が幻覚を引き起こさずに適切に未知を示す能力を評価する方法を提案する。架空語を自動生成し、架空語について問う質問に対する LLMの応答を分類することでこの能力を評価する。
E5-3,金融分野へのサービス提供時等において，深層学習モデルのドメイン適合実施時において，「計算コスト」や「更新されたパラメータのブラックボックス性」が課題になることがある．特に金融分野では単語レベルでのポジネガが時代やドメインが変わると変化することも多く，本課題は当該分野では重要な課題である．そこでなニューラルネットワークモデル SINN を活用した単語極性変換手法 Word-level Polarity Adaptation framework based onSINN (WPAS)を提案する．景気センチメントに関するデータセットを利用した検証の結果，提案手法WPAS により（１）少ないパラメータ数の更新、かつ（２）更新されたパラメータが解釈可能な形で高性能なドメイン適合ができることを実証した．
Q1-6,"Large language models (LLMs) demonstrate strong per-formance in text simpliﬁcation, yet current metrics lack theinformativeness of more detailed schemes that annotate in-dividual errors. Clearly stating these limitations is essentialto understand the simpliﬁcation quality of LLMs. Buildingon our previous work [1], which introduced an error-basedhuman annotation framework to assess GPT-4’s simpliﬁca-tion capabilities, this study expands the scope by includingtwo additional LLMs, Qwen2.5-72B and Llama-3.2-3B,along with more datasets. Our human-annotated corpuscomprises ﬁne-grained error analyses for 4, 500 complex-simple sentence pairs and Likert-scale ratings for 10, 471pairs, one of the largest scales to date. Results show thatLLMs generally generate fewer erroneous simpliﬁcationoutputs than the previous state-of-the-art (SOTA). How-ever, LLMs have their limitations, as seen in larger LLMsstruggle with lexical paraphrasing."
P5-23,本研究では，大規模言語モデル（LLM）の情報抽出時の評価手法である Needle in a Haystack LLM テストをより実践的に拡張した LLM 偽針混入テストを提案する．従来手法は LLM の抽出精度を Recallのみで評価するため，現実の情報抽出で頻出する誤抽出の問題を考慮していない．提案手法では，Precision を評価指標に加えて誤抽出を定量化するとともに，抽出対象と文脈のドメインを一致させ，さらに偽正解情報を混入することで実践により近い誤抽出を評価可能とする．実験の結果，提案手法による現実的な設定下で LLM による誤抽出が増加し，誤抽出を網羅的に評価する必要性が示された．
E10-3,本研究では，大規模ニューラル言語モデルの中間層から得られる次単語予測確率が人間の読み活動・脳波データをうまく説明できることを報告する．これは，大きな言語モデルの計算する確率ほど人間の振る舞いから逸脱してしまうという既存の報告を覆すものであり，大規模言語モデルの認知的妥当性が過小評価されていたことを示唆する．さらに，人間の比較的速い反応（最初の視線停留など）は浅い層で，遅い反応（脳波 N400 など）は深い層で再現される傾向が見られ，言語モデル内部でのレイヤ方向の漸進的処理と，人間の異なるタイムスケールの反応との対応をとる新たな方向性を提示する．
P2-16,本研究では，事前学習言語モデル（PLM）における専門ドメインに特化したニューロンの内部挙動を分析する．具体的には，金融ドメインと一般ドメインのテキストに対する，日本語の Encoder または Decoder のアーキテクチャをもつ複数の PLM のニューロンの挙動を比較し，ドメイン特有のニューロンを検出した．分析の結果，Encoder と Decoderの両アーキテクチャに共通して，ドメイン特有のニューロンは初期層に多く存在することがわかった．次に，Decoder モデルの MLP にはドメイン特有の性質が複数の層に分散して存在することが示唆された．また，金融ドメインで追加事前学習したモデルでは，中間層でドメイン特有の表現を獲得していることがわかった．
A2-1,規定の文字数やフォーマットを守った文章生成や数千にも及ぶ条文からなる法律を遵守するなど，大規模言語モデルの更なる応用のため複数の指示追従性能は重要な側面である．複数の指示を同時に追従する性能の正確な推定ができると，未見の指示の組み合わせリスクのシミュレーションが可能となる．更に，その組み合わせの種類が膨大になるほどシミュレーションによるリスクの把握が重要性を増す．我々は複数の指示追従性能調査のためのベンチマーク ManyIFEval と StyleMBPP を作成し，同時に複数の指示追従する成功率は個々の指示の追従成功率の積で推定できるという経験則を得た．経験則により指示の未知の組み合わせに対して指示追従性能を推定できることを示した．また組み合わせる指示数が多くなればなるほど，同時に追従成功する可能性は劇的に低くなることを確認した．
E7-1,本研究では，決算短信における業績要因文を対象として，文生成にいわゆる大規模言語モデル的手法を使わず，指定の文集合のみを参照して単語・文節の極性を学習し，明示された基準を用いて同義の文や対義の文（意味反転文）を出力する手法を提案した．具体的には，少数の極性提示表現例をもとに，文章中の全文節の極性を自動で算出する．その後，入力文の置換箇所を極性によって定め，置換先の組み合わせ表現を極性や機能語の接続頻度を元に決定し，同義文や対義文の出力を行った．
C4-2,"In recent years, MultiModal Large Language Models(MM-LLMs) have undergone substantial advancements,augmenting oﬀ-the-shelf LLMs to suppor t MM inputs oroutputs via cost-eﬀective training strategies. In this paper,we provide a survey aimed at facilitating further researchon MM-LLMs. We outline general design formulationsfor model architecture. Furthermore, we review the perfor-mance of selected MM-LLMs on mainstream benchmarksand explore future directions. More latest developments inthis ﬁeld are provided in a real-time tracking website.1）Wehope that this survey contributes to the ongoing advance-ment of the MM-LLMs domain."
Q3-4,本稿では，視覚言語モデル(VLM)の識別性能を評価するための新たな評価用ベンチマーク DiscriBenchを構築し，既存の VLM の識別性能を調査する．DiscriBench は，提示される情報の中から必要な情報を識別し質問に回答するという，人間が日常生活において行なっているプロセスに焦点を当てたベンチマークである．全 100 問からなる選択肢形式のVQA であり，大学入試難易度を想定して作成している．GPT-4o を含む既存の VLM を DiscriBench で評価した結果，人間の正解率は 89.2%だったのに対し，VLM はそれより 18.2 - 63.2 ポイント低く，識別性能において大きな差が認められた．
P8-7,本研究では，文対モデリングタスクの性能改善のために，事前学習済みマスク言語モデルに対する追加事前学習の手法を提案する．マスク言語モデリングによる事前学習は，意味的に近い文の埋め込み同士を埋め込み空間上で必ずしも近づけるようには設計されていない．そこで提案手法では，事前学習済みマスク言語モデルに対して，言い換え文対の文埋め込みを近づける対照学習を適用し，文対モデリングの性能改善を目指す．対照学習の先行研究で標準的に使用される自然言語推論コーパスは，英語以外の言語では大規模に利用できない課題があるが，本手法では生コーパスと言い換え辞書から低コストに対照学習のための学習データを構築できる．4 種類の文対モデリングタスクにおける実験の結果，英日の両言語において提案手法の有効性を確認できた．
P9-23,対話における発話の感情認識が，ソーシャルメディアの感情分析を目的として注目を集めている．対話の感情認識では，同じ発話であっても，先行文脈に応じて異なる感情を示すことがある．従来手法として DialogueCRN [1]は，識別対象の発話とその先行文脈（対話）を利用し，高い識別性能を示した．本研究は，モデル外部のデータベースを活用して，従来の識別モデルを補強する方法を提案する．具体的には，まず識別対象の発話とその先行文脈の内容をクエリーとして，意味的に近い発話を訓練データから k 近傍法を用いて検索する．検索した発話（近傍事例）に付与された感情ラベルと，識別対象の発話との距離を基に感情ラベルの確率分布を作成し，従来の識別モデルの確率分布と重み付け線形和によって組み合わせる．本研究は，定数による重み付き線形和で 2 つの確率分布を組み合わせるだけでなく，重み係数を導出するニューラルネットワークを構築して，識別対象の発話ごとに動的に重み係数を変更する．さらに，適切な重み係数を学習するために，図 1 に示す係数損失を導入する．従来の識別モデル（または近傍事例）による確率分布が適切な場合，従来の識別モデル（または近傍事例）側の重み係数が高くなることが望まれるため，従来の識別モデルによる確率分布と近傍事例による確率分布のそれぞれが示す感情ラベルが，教師ラベルと一致する場合に重み係数を高め，そうでない場合に重み係数を低くする損失関数を設計する．ベンチマークデータ IEMOCAP [2]を用いた評価実験の結果を表 1 に示す．動的に重み係数を変更すCE lossBCE losssadsadsadhappy
C2-4,"本研究は,大規模言語モデルを用いて,ビジネス文書中の読み手にストレスを与える文章を検出する手法を提案する. BERT(Bidirectional  EncoderRepresentations  from  Transformers)[1]を用いた多クラス分類モデルにより,過剰な丁寧さ,命令的な表現,情報の過不足,責任回避的な表現を検出し,文章改善の指針を提供する.独自のデータセットを作成し,分類タスクに適した学習を行うことで,従来手法では検出が困難だった微妙な文体の違いを捉えることを目指す.実験により,定義したラベルは文章の内容に関わらず,ストレスの要因となる表現を検出可能であることを示す."
Q5-2,本研究では，離散拡散モデルを用いたテキスト生成において生じる訓練時と推論時の不一致に注目し，この問題を解消するため，訓練時の損失計算においてモデルが予測した系列を次ステップの入力として使用する 2 ステップ損失計算アプローチと，その確率的スケジューリングを提案する．提案手法を広く使用されている 4 つのテキスト生成ベンチマークデータセットにおいて学習・評価した結果，2 ステップ損失計算による離散拡散モデルの性能向上を確認した．
Q10-6,本研究は，⽇本の刑法を対象とした法律相談システムの構築を⽬指して「罪名」「量刑」「量刑根拠」の 3 つの予測に取り組んだ.弁護⼠へのヒアリングを基に構築した罪名データベースを参照するように設計した罪名予測モジュールは，正解割合の平均が70%となり⽬標の 80%には達しなかった.弁護⼠へのヒアリングを基に構築した量刑根拠データベースを参照するように設計した量刑根拠予測モジュールは，正解割合の平均が 89%となり，⽬標の 80%に達した.過去の量刑事例集を参照させるように設計した量刑予測モジュールは，正解割合の平均が 43%となり，⽬標の 80%を⼤きく下回った.
P6-8,"In real-world scenarios, text classiﬁcation often facesthe challenge of limited labeled data, especially for rare oremerging classes. Traditional methods struggle in thesesituations, requiring new approaches that can generalizeto unseen or sparsely annotated classes. This challenge isparticularly common in the biomedical ﬁeld, where datais expensive to annotate, and new diseases and treatmentsfrequently emerge. This paper proposes an entailment-based framework for zero and few-shot text classiﬁcationby reframing the task as a natural language inference (NLI)problem. Leveraging pre-trained language models, the ap-proach infers labels for unseen classes without additionalﬁne-tuning. For few-shot scenarios, minimal task-speciﬁcﬁne-tuning signiﬁcantly enhances performance. Our ﬁnd-ings highlight the potential of entailment-based learning asa versatile and eﬀective paradigm for text classiﬁcation inlow-resource environments."
E3-5,地理的位置属性を持つ言及に対するエンティティ・リンキング課題において、地名が持つ住所階層性を活用したエンティティ曖昧性解消手法を提案する。提案手法では、入力文章中に地理的位置属性を持つ言及が複数現れる場合に、それらをトリガにして入力文章を編集することで地名間の住所階層関係をモデルに伝える。評価実験を通して、提案手法は従来手法を上回るエンティティ曖昧性解消の精度を達成し、同名の地名間の混同やカテゴリの異なるエンティティとの混同を効果的に削減できることを確認した。
A6-5,Transformer ベース言語モデルの内部表現には統語構造が表現されていることが示唆されているが，入力が各層を伝播する中で統語構造が構築される過程は依然として不明確である．本研究では，Transformer ベース言語モデルにおける，統語構造の構築過程を定量的に分析するための新しい手法として Derivational Probing（派生的プロービング）を提案する．これにより，文の局所的な構造と大域的な構造が，単語表現が各層を伝播する過程でどのように構築されるかを検証することが可能となる．BERT と GPT-2 を用いた実験では，BERT は局所的な構造を構築してから大域的な構造を構築するボトムアップな方法をとるのに対し，GPT-2 は局所的な構造と大域的な構造をよりパラレルに構築する傾向があることが示された．また，主述の一致タスクのケーススタディでは，BERT モデルが最終的に正しい統語構造を導出する場合でも，大域的な構造の構築が行われる層の位置が，タスクのパフォーマンスに影響を与えることが示され，大域的な構造を構築する最適な層の範囲が存在することを示唆した．
P10-3,RLAIF を対話システム学習に適応する上では、シングルターンの対話だけでなく、対話文脈全体の一貫性、個性、共感性などの対話印象を向上させる必要がある。本研究では、対話印象評価のための報酬モデルの比較、及びその報酬をフィードバックとしたシステムの対話印象の改善を行った。自動評価と人手評価の結果、個々の対話印象の向上だけでなく、応答の自然さも向上することが示された。
Q7-1,大規模言語モデル（LLM）のハルシネーション（事実と矛盾する情報生成の課題）に対し，構造化・非構造化知識源を用いた Retrieval-AugmentedGeneration（RAG）の比較分析を行う．マルチホップ QA データセットを用いて，構造化知識ベース，文書ベースの RAG および LLM のみによる回答を段階的に組み合わせる手法により，各知識源の特性を活かした回答生成の有効性を実証する．
P10-2,"Decision-making is an essential part of our daily lives,especially in dialogue. It involves group decision-making,where we strive to reach a consensus with others, or in-dividual decision-making primarily based on our indepen-dent thinking. Collecting decision-making data helps usanalyze our daily behaviors and engage in self-reﬂection.In this study, aiming to detect individual decision-makingdialogues in conversation automatically, we annotate thedecision-seeking (e.g.,“Would you like to form a bandwith me?”) and decision-making utterances in a dialoguedataset. We then investigate the LLMs’ ability to detectindividual decision-making and conduct an error analysisto analyze the mistakes in the detection processes."
E3-4,大規模言語モデルの発展に伴い，記号接地問題が脚光を浴びるようになってきている．しかしながら，記号接地は大規模言語モデルにとっては問題ではなく，言語獲得においてもそれほど重要な課題ではない．問題は，記号創発による平衡状態としての言語体系にある．本稿では，理論言語学，とりわけ生成文法と呼ばれる理論から，記号接地問題について批判的に考察する．
A6-4,大規模言語モデル(LLM)は long-tail の知識に対して精度が低く，過去には事前学習データに含まれる知識に関する頻度が高いと精度も高くなる関係を示した例がある．一方，実用上はより複雑なタスクを解くことがあり，単純な頻度よりもいかに文脈を捉えるかが重要となる可能性もある．そのための基礎的な分析として，本研究では次の二つを実施した．1)事前学習データに含まれる単語やトークンの頻度を算出し，精度の関係を分析した．2)各層の埋め込み表現を用いて定性的な分析を行った．その結果，今回対象としたタスクでは頻度と精度の関係は確認できなかったものの，LLM は文章全体で文脈を捉えずに特定のトークンに着目している可能性を示した．
Q7-22,本研究では，PDF 文書から表データを正確に抽出することを目的とし，主に農業分野で利用される技術文書を対象に主要企業の表抽出ツールを評価する．既存研究が指摘する固定レイアウト構造の課題を考慮し，複雑な表レイアウトや多言語への対応を踏まえて，表構造認識ベンチマーク TOITA を用いて性能を比較することで，その有用性を明らかにする．
P6-9,企業情報の分析のために，各企業の各事業に適切な業種を割り当てることは重要である．このとき，既存の業種体系に合致しない事業内容があるため，業種体系を適宜拡張して使う必要がある．本研究では，LLM を用いて既存の業種体系にない業種名称を生成し，業種体系を拡張する．ただし，生成された業種には不要な名称が含まれる．不要な名称を削減する手法として，LLM への生成制約，既存業種にある名称のフィルタリング，生成業種間で類似した名称のクラスタリングを提案し，効果を検証する．
Q10-7,近年，オープンサイエンスが世界規模で推進され，データセットやコードなどの研究成果の公開促進に加えて，そのアクセス性が重要視されている．アクセス性を高めるための要素の 1 つとして，研究成果間で関連付けることが挙げられる．そこで本論文では，研究成果の一種であるデータセットを対象に，それらの間の関連性を推定することの実現性を検証する．データセットに付与されたメタデータを用いて BERT ベースのモデルによって関連性を推定する手法を実装し，実験により推定性能を評価した．
Q5-3,"Existing studies investigate stereotypical biases in largelanguage models (LLMs) through the diﬀerence betweenreal-world and counterfactual data. In this case, real-worlddata typically exhibit pro-stereotypical bias, while counter-factual data rewritten by humans exhibit anti-stereotypicalbias. Due to the subjective nature of stereotypical biasjudgment, it is crucial to explain the judgment. In thisstudy, we aim to use LLMs to judge whether a sentenceis pro- or anti-stereotypical and explain the reason for thejudgment. We construct a stereotypical bias explanationdataset for this goal. The experimental results show thatLLMs outperform humans in distinguishing pro- and anti-stereotypical biases. Moreover, our constructed dataset ishighly eﬀective in training smaller language models to gen-erate high-quality explanations. Finally, we ﬁnd that LLMsdiﬀer from human annotations on counterfactual data thanon real-world data."
A4-6,外国人被告人が公正な裁判を受ける権利を保障するためには法廷通訳人の存在が必要不可欠であるが、その人数は年々減少傾向にあり、また、国家資格が存在しないため通訳の質の保証の問題も抱えている。本研究では、大規模言語モデルを用いた法廷通訳並びにチェック・インタープリターの実現可能性を検証する。法廷通訳能力の検証のためのデータセットの作成および評価基準の策定を行い、3 種類の機械翻訳システムの検証を行った。実験の結果、特に GPT-4o による訳文は法的等価性を高い水準で維持できる一方で、法律用語や疑問文の訳出エラー、日本の司法制度に関する知識の不足といった課題もあることが分かった。
E1-6,"本稿では，コプト語説教文書「On Christian Be-haviour」(OCB)の著者帰属を，スタイロメトリ（文体統計学）を用いて再検討する．OCB は写本題辞で修道院長シェヌーテ（Shenoute,紀元後 4〜5 世紀）の名を冠するが，実際にはシェヌーテの特徴である修道士向けの規律に関する厳しい忠告や厳しい断罪が乏しく，早くから「偽シェヌーテ文書」と疑われてきた．本研究では，OCB の K. H. Kuhn の校訂版テキストと，白修道院文学（シェヌーテ,ベーサ,ヨハンネス）および新約聖書，コプト語聖人伝，新学書，説教などを対象に，R 言語の stylo パッケージを用いて文体比較を行った．結果として，OCB がシェヌーテの著作群よりも新約聖書の書簡のクラスタに近いという従来の示唆を定量的に裏付け，OCB を「偽シェヌーテ文書」の範疇に位置づける客観的根拠を提供した．"
C2-5,LLM による自動プロンプト最適化は活発に研究されている分野であり，主に人の主観によらず一意に正解が定まるタスクに対する有効性が報告されてきた．しかし，主観的評価によって定められたラベルの予測タスクに対するこれらの手法の効果は検証されていない．本研究では，テキストへの個人的選好の予測タスクに既存の複数の自動プロンプト最適化手法を適用し，精度向上の程度を検証する．検証の結果，(1)個人的選好の予測タスクについては既存手法による精度の向上が見られないこと，(2)プロンプト書き換えの反復が精度向上に与える効果が小さいこと，(3) LLM が生成した誤りの情報が最適化の過程でうまく参照されていないことを確認した．
P9-22,関連研究節生成のためには，引用する論文を決定した上で，どのような段落構成や順序で論文を引用するかという論文配置を考える必要がある．しかし，関連研究節自動生成に関する既存研究では，引用すべき論文を推薦する引用推薦や，引用論文と引用順が与えれらた場合に関連研究節を自動生成する研究は多く行われているものの，引用論文の最適配置には着目されてこなかった．本研究では，関連研究節の自動生成に向けた引用論文の最適配置に取り組む．具体的には，引用論文を段落ごとにまとめるクラスタリング，段落順の決定，段落内の引用順決定という 3 タスクに分解し，各タスクを解くことで引用論文の最適配置を実現する．
P8-6,本論文では，LLM を活用し，疎検索を用いた検索拡張生成（RAG）を最適化する，反復的キーワード生成手法 IterKey を提案する．IterKey は，キーワード生成，回答生成，回答検証の 3 つの構成から成り，すべて LLM によって実行し，RAG の処理全体の最適化を目指す．この手法により，質問応答タスクにおいて，検索なしの手法や BM25 を用いたRAG と比較して精度が 5 ％から 20 ％向上し，密検索モデルを用いた RAG や先行研究と同等の性能を達成した．IterKey は，価値あるキーワードを生成しながら，解釈可能性を維持し，LLM による反復的なキーワード洗練と自己検証を通じて RAG 全体を最適化する可能性を示す新たな疎検索手法である．
Q3-5,大規模言語モデル（LLM）の発展として，画像など他のモダリティも扱う大規模マルチモーダルモデルの研究が進んでいる．本研究で注目する Vision &Language モデル（VLM）は，画像とテキストを同時に入力可能なモデルである．しかしながら，データが潤沢な英語モデルに比べ，データの不足する日本語モデルの開発は十分とはいえない．本研究では，日本語能力に特化した VLM の開発のため，大規模な日本語テキスト・画像ペアの合成データセットを新たに構築した．なお，データセットの構築時に，ライセンスによってデータ利用が制限される LLMは用いていない．構築したデータセットを用いて日本語 VLM を訓練し，その性能を評価した．
C4-3,視覚言語モデル（VLM）の進歩に伴い，画像品質評価において VLMを用いることが注目されている．また，製造業では製品の外観検査において異常画像の数が少ないため精度の高い異常検知モデルの開発が難しく，異常画像を生成できるドメイン特化画像生成 AI の需要が高い．そこで本研究では VLM を用いてドメイン特化生成画像の定量評価を行い，その妥当性を検証した．VLM により生成画像を定量評価し，既存評価値や官能評価値との相関を分析した結果，特に形状，色，テクスチャの観点で VLM によるドメイン特化生成画像の定量評価の可能性を示した．また，参照画像や生成画像同士の相対評価を行うことで，精度の高い評価が可能となることを示唆した．
P2-17,Attention は，文章生成時のメモリ消費量が入力トークン数に比例して増加するため，長文の処理や高速な文章生成を困難にする．この課題を解決するため，推論時のメモリサイズが入力長によらず一定である状態空間モデル(SSM)に基づいた言語モデルが提案されている．本研究は，SSM に基づく言語モデルがどのようにして入力文中の情報を記憶しているのかを分析する．分析では，記憶と想起を必要とする質問応答タスクにおいて，正答に必要不可欠なSSM をもつ層を特定して，その SSM が本文中のどの文脈を参照しているかを観察する．記憶と想起のメカニズムの実現のために SSM のパラメータが満たすべき条件を示すことは今後の課題とする．
P5-22,本研究ではイベント知識グラフからの実況テキスト生成に取り組む．タスク設定はシナリオの進行に合わせて実況を生成できるようマルチターン形式で定義する．グラフ情報はテキスト形式へ変形し，大規模言語モデルを用いて few-shot プロンプトによる生成を行う．また，我々は既存のイベント知識グラフを備えた動画データセットに対して，日本語の実況音声とテキストを新たに付与することで 4 種のデータ形式を備える動画実況データセットを構成し実験に利用した．結果として，詳細なグラフ情報の利用により BLEU スコアの向上を確認したものの，言語モデルの最大系列長制限のため正解実況で言及されることのある情報の一部は入力中に含められなかった．データセットは一般公開されている．1）
E10-2,計算心理言語学では、人間の文理解において、どのような表象がどのように構築されているのかが探究されてきた。この問いに取り組むのに、Combinatory Categorial Grammar (CCG)が有望な文法理論であることが、日本語や英語の読み時間や脳血流のデータを用いた先行研究で示唆されている。そこで本研究では、日本語を対象とした新たな脳波データセットを構築した上で、CCG による指標が脳波の予測に寄与するのか検証する。統語操作の適用数および作業記憶の負荷に関する指標が、それぞれ事象関連電位を予測することを示す。
B9-6,看護留学生への支援に活用できる語彙リストを作成するためのコーパス構築のパイロットスタディについて発表する.まず，全 70 巻の『系統看護学講座』シリーズのうち３巻を文字化し，語彙の多様性や，品詞・語種の観点から留学生が直面しうる困難について検討した.その結果，名詞が多いこと，漢語や外来語が多いことなどから，母語や背景によっては難しく感じることが示唆された.その後，本パイロットスタディを踏まえ，コーパス構築を前提とした整形作業において考慮すべきことについて検討した.教科書という特性上，コラムや練習問題などが入り組んでおり，学習の必要性や語彙の特徴の過大評価の可能性などを踏まえ，今後の整形の方針を述べた.
Q1-7,小説理解において，登場人物の認識とセリフの話者推定は，最初の重要なステップである．本論文では，登場人物認識とセリフの話者推定を統合した処理を，登場人物アノテーションと名づけ，これを実現するシステムを提示する．さらに，そのシステムを用いて完全自動の登場人物アノテーションを実行し，セリフの話者推定において，主要登場人物リストを与える先行研究と同程度の精度を達成した．
C6-1,"This paper investigates whether continually pre-trainingLarge Language Models on domain-speciﬁc reference textscan improve performance in Japanese Automated EssayScoring tasks. We use a dataset covering multiple es-say prompts related to four thematic areas― Globaliza-tion, Natural Science, Critical Thinking, and East AsianEconomics. Each essay is scored on a ﬁve-point scalefor Comprehensiveness. Models undergo two conﬁgura-tions:(1) direct ﬁne-tuning on the scored essays, and (2)an additional continual pre-training phase using domain-speciﬁc texts prior to ﬁne-tuning. Our ﬁndings indicatethat most models beneﬁt from this extra training, as ev-idenced by improvements in evaluation metrics such asthe F1 Score, Quadratic Weighted Kappa, Accuracy, andRoot Mean Squared Error. These results underscore theimportance of domain adaptation for more accurate essayscoring."
E5-2,"This study leverages advanced natural languageprocessing techniques and large language models(LLMs)—including ChatGPT, Claude, and Gemini—to extract sentiment from Japanese 10-K reports and predict stock returns. Using a dataset of 11,135 firm-years from Tokyo Stock Exchange-listed companies(2014–2023), we compare LLMs with dictionary-basedmethods and a DeBERTaV2 model. While traditionalapproaches show no significant sentiment-returnrelationship, LLM-derived sentiment reveals asignificant negative correlation with future stockperformance, challenging the efficient markethypothesis. These findings underscore thetransformative potential of LLMs in financial analysis,offering predictive insights undetected by traditionalmethods."
Q2-12,近年，大規模言語モデル（LLM）を用いた回答分布予測が注目されているが，割合に関する数値的予測に合理性があるかは明らかではない．本研究では，実際のアンケートデータの分布割合を入れ替えた「常識的には不自然な擬似分布」を用いて，LLMがその説明を受けても合理的な分布推定を行えるかを検証した．その結果，説明に単に追従する能力と，常識に基づいて割合を予測する能力が異なることが明らかとなった．また，分布の性質を十分に理解していない予測における不合理性も確認された．この結果は，LLM の分布予測能力を評価する際に，常識的な推論能力だけでなく，与えられた指示への追従性能も考慮すべきであることを示唆している．
Q8-9,本稿では翻訳能力を向上させるデータを用いて継続事前学習を行ったモデルを対象に，モデルマージを用いて破滅的忘却を抑制する方法について検討する．継続事前学習前後のモデルをマージすることにより，一般的タスク能力の忘却を抑えつつ，翻訳能力をベースモデルよりも向上させられることを示す．さらに，モデルマージの手法間の比較や，各マージ手法のパラメータ設定による結果の変化についても調査を行い，今後の研究の方向性を示す．
P6-14,固有表現抽出における過抽出やラベルの認識誤りは，典型的な性能低下の要因であり，大規模言語モデルにおいても頻出する課題である．本稿では，固有表現抽出を学習する過程で，抽出エラーを自己修正(Self-Correction)するための指示学習を提案する．本研究における自己修正の学習は，固有表現抽出の教師データのみ参照し，抽出エラーの検証や修正に関する追加アノテーションを必要としない．化学分野の特許を対象とした固有表現抽出において，自己修正に基づく指示学習を導入することで，固有表現の抽出エラーを大幅に抑制できることを示した．
P8-11,本研究では，E コマースにおけるクエリ意図分類の精度向上を目的とする．提案手法では，クリックログを利用して大規模なデータセットを構築し，それを人手ラベルデータで補完する方法を採用した．さらに，これらのデータを統合的に活用することで，モデルを段階的に学習させる新しいアプローチを提案する．実験の結果，クリックログによる大規模データセットを信頼性の高い小規模な人手データで補完することで，従来手法を上回る分類性能を示した．
P1-21,大規模言語モデル(LLM)の技術進歩は著しく，様々な分野でその活用が進んでいる．しかし、特許翻訳の分野では依然として Transformer ベースの翻訳が主流であり，LLM を活用した翻訳能力については十分に検討されていない．そこで本研究では、近藤ら[6]の手法を参考に，対訳データを用いた継続事前訓練と SFT(Supervised Fine-Tuning)を行ったLLM を用いて特許請求項の翻訳を行い，Transformerベースの翻訳と比較した．その結果，BLEU およびCOMET のスコアがいずれも上回り，訳抜けや繰り返しといった課題が改善されたことを確認した．一方で、従来モデルでは発生しなかったハルシネーションが一部の例で確認され，その影響で翻訳精度が低下したケースも観測された．本研究は，LLM が特許翻訳分野において有望な技術である一方で，課題も存在することを示している．
Q6-6,我が国の農業においては、農林水産省が国の政策の策定と実施を担う一方、実務的な管理・指導は都道府県と農業協同組合（農協）が中心となって実施している。各組織は、栽培技術、病害虫防除方法、農業者の経営形態に関する情報など、地域特性に応じた情報を集約し、ウェブサイト等を通じて公開している。本研究では、各組織と交渉して公開・非公開を問わずデータの収集を進めている。収集したデータは、各提供元のオープン・クローズ戦略に準拠しつつ、組織内で有効活用できるような AI モデルを構築するための知識源として使用している。本稿では、これらの収集されたデータのうち、公開データの収集状況について報告する。
A7-3,ニューラルモデルの構成的汎化能力は，人間のような言語能力の実現に向けた重要な課題の一つである．既存研究は，モデルの出力に着目して構成的汎化能力を評価しており，モデルの構成的汎化における内部機序は明らかでない．そこで本研究では，構成的汎化に寄与するサブネットワークの探索とモデルの統語的特徴の活用に関する因果分析を行い，Transformer の内部機序を分析する．実験結果からTransformer は構成的汎化において統語的特徴に一定程度依存することが示された．一方で，モデル全体よりも優れた汎化性能を持つサブネットワークは，統語的特徴を用いた構成的な解法に加え，非構成的な解法にも依存することも示された．
E2-3,本研究は，人文学の系譜に位置付く社会学理論の実証の文脈において，いかに自然言語処理が応用可能かを示すべく，言語処理の研究者集団を対象にブルデュー流の「界」の分析を行い，その分化の構造を明らかにする．ACL  Anthology と researchmap を用いて構築した有力な言語処理研究者 578 名のデータセットを用いて，多重対応分析により「界」の空間を構築したところ，資本総量の差は見られたものの，解釈可能な資本構成の交差配列構造は認められなかった．BERTopic により析出した研究分野との関連もそれほど明確とは言えず，理工系の分野においてはブルデュー理論が有効とは言えないことが示唆された．
Q6-11,本研究では，日本語自然言語処理に関連する 484件の GitHub リポジトリを対象とし，合計 1537 件の研究分野マルチラベルを付与したデータセットを構築した．本データセットは，README ファイル，PDF ドキュメント，スクリーンショット画像など，複数形式のマルチモーダルデータを入力とすることでラベルを予測できるように設計されている．実験の結果，本データセットが日本語言語資源の効率的な検索に寄与することを示す．
Q1-18,人は他者とコミュニケーションを行う際，使用語彙や話す速さ，表情やボディランゲージなどを相手に応じて使い分けている．しかし，現在の対話システムがユーザに応じて話し方や対話戦略を変更することはほとんどない．対話システムがより効率的にタスクを達成したり，ユーザの満足度をより高めるためには，ユーザに応じて対話戦略などを変更できることが望ましい．そこで我々は話し方の変化に大きく影響を与える要素として話者の年齢に着目し，幅広い年齢層の話者によるマルチモーダル対話コーパス Tabidachi を構築した．本コーパスは国立情報学研究所情報学研究データリポジトリ（IDR）1）にて公開している．
P9-1,SNS やオンラインニュースのコメント欄では，誹謗中傷など知りたくない情報に触れることが多く，精神的な負担を感じる人が増えている．NG ワード設定によるフィルタリングの手法もあるが，攻撃的なコメントを完全に防ぐことは難しい．また，既存のコメント表示アルゴリズムは古いコメントを優位に扱う仕様であるため，新しく投稿された有益なコメントが埋もれてしまい，得たい情報を得ることができないという問題もある．これらの課題を解決するために，誹謗中傷表現を含まない建設的なコメントを抽出し，建設的度合いを閲覧者が調節できるシステムを提案した．本研究では，コメントのアスペクト情報を基に建設的度合いを推定する推定器を作成し，GPT4 と比較した実験で提案手法の有効性を確認した．
Q8-14,生成 AI 技術の著しい進歩により、これを活用した製品やサービスが数多く登場している。本研究では、生成 AI の一種である LLM を用いて日本語学習者を支援するため、架空の日本での生活をシミュレーションするゲームを開発している。このゲームでは、動的な対話を可能にする LLM を登場人物として活用し、学習者に現実に近い会話練習を提供する。さらに、LLM の特性を活かして、学習者ごとにパーソナライズされた会話体験を実現し、日本語学習の効率と効果を高めることを目指している。
Q4-4,本研究では，日本語の医療分野に特化した小規模言語モデルの開発を行った．日本語に焦点を絞ったテキストクリーニングと形態素解析，教科書相当の品質に分類されたテキストデータ，疾病・薬剤に関する話題についての合成テキストデータを使用し，軽量化に重きをおいた 1B の言語モデルの事前学習を実施した．このモデルをベースモデルとして指示ファインチューニングしたモデルを IgakuQA とJMED-LLM を用いて評価を行った．ファインチューニングモデルにおいて，JMED-LLM の 8 つの評価指標のうち，6 つのタスクで既存の大規模言語モデルより高いスコアを示した．この結果から，ネットワークや計算資源が限られた環境において，特定の分野に特化した小規模言語モデルの運用が選択肢の１つになり得る可能性が示唆された．
A5-1,ニューラル言語モデルを一度学習し，後からその層を繋ぎ直すことで，モデルの軽量化や複数のモデルの統合が可能になるという不思議な現象が知られている．本稿では，最も単純な層の繋ぎ変えである隣接層同士の交換の成否が，「層の冗長性」と「層同士の独立性」というふたつの直感的な指標によって特徴づけられることを示す．理論的には，これらの量が十分小さいことが，層同士を交換できることの必要条件になっていることを示した．経験的には，提案指標が学習済みの GPT-2 の層同士の交換しやすさが提案尺度でよく予測できることを確認した．
C3-2,"近年，大規模言語モデルの発展に伴い，マルチモーダル LLM(Large Language Model)の活用が進んでいる．特に画像分類においては,画像内の状況や意味を理解することで，従来の物体検出モデルでは検出困難だった画像全体を考慮した判別や新規の物体を特定する可能性が注目されている．しかしながら，マルチモーダル AI の性能は，画像とテキストのペアデータセットの収集難易度や，学習データの影響により画像分類性能に課題がある．そこで，本研究ではこの課題を克服するために物体検出モデルとマルチモーダル LLM を組み合わせたハイブリッド画像分類手法 OConfVQAC(Objectdetection Confidence-guided VQA Classifier)の提案を行う．具体的には，物体検出モデルによって算出された信頼度を VQA モデルにプロンプトとして与え物体検出モデルの検出漏れを補完し，VQAモデルを用いた画像分類の性能向上を目指す．また，この提案手法の有効性を検証するために，テーマパークに関する SNS の投稿画像にぬいぐるみが映っているか否かの 2 値分類タスクに適用した．本研究では，VQA モデルの画像分類性能の向上の可能性を検証した．"
Q4-14,本研究では、LLM が与えられた問題を適切に解けるかを推定するタスクにおいて、推定モデルの学習に含まれない新規の LLM や問題に対しても高精度に推定する手法を提案する。提案手法では、従来の行列分解に基づくアプローチに加えて、問題文の埋め込みやモデルの来歴などの補助情報から得られる類似度を考慮した類似度制約項を損失関数に導入する。その結果、提案手法では学習時に利用した既知の LLM による新規問題の平均的な解決性能の推定において 20.2%、新規 LLM の既知の問題に対する平均的な性能の推定において 15.6%の誤差軽減を達成した。
B8-1,本研究では、認知症高齢者の「帰宅願望」や「不安」といった注意すべき発話を特定するシステムの構築を目的とした。介護施設で収集した対話データを基に、実データの収集が困難な環境下でも活用可能なデータ拡張手法を活用し、日本語 BERT を基盤とした発話意図推定モデルを構築した。特に、ChatGPT(GPT-4o)を用いた疑似データ生成により、少数データクラスのデータ不足を補完し、分類精度の向上を実現した。評価の結果、疑似データ生成がデータ不足を補う有効な手法である一方、施設特有の文脈や固有表現への完全な対応には最低限の実データが不可欠であることが判明した。本研究は、疑似データ生成を活用したコーパス構築の有効性を示すとともに、施設ごとに適応可能なモデル設計の方向性を示す一助となるものである。
Q3-21,本研究では，テキストの答案データと同時に画像の答案データを入力として利用した場合の自動採点システムの効果について議論する．テキスト特徴量と画像特徴量を直接分類層に入力するモデルとLLaVA モデルの二つのモデルを作成し，BERT のみを利用したモデルとの比較実験を行った．その結果，文法能力について評価を行っている文書力については画像を取り込むことで一部の課題において評価精度が向上した．また画像データによるモデルの性能向上の原因として答案の長さの影響が示唆される実験結果を得た．
Q2-2,LLM の安全性の評価のために，先行研究における人手評価の結果を分析し，評価の課題を洗い出すことにより評価基準を整備した．この評価基準を用い12 の LLM による 183 の質問に対する回答の安全性を人手により評価した．そしてこの人手評価結果の分析を通して評価における課題を整理した．評価結果は現行の LLM の安全性における能力の評価に加え，LLM の安全性を評価する基準となるデータとして，また自動評価手法の構築のために貢献し得る．
P1-8,"Adapting Unsupervised Neural Machine Translation(UNMT) for domain-speciﬁc tasks often encounters Do-main Mismatch (DM), where one language lacks suﬃcientin-domain monolingual data. We observe that while in-domain monolingual corpora enhance translation qualityfor the language they belong to, this improvement doesnot extend to the paired language. To address DM, wepropose Domain-Aware Adaptation (DAA). DAA selectsin-domain texts according to assigns higher weights to in-domain texts from open-domain corpora. Experimentalresults on Japanese-English translation tasks across the IT,Koran, Medical, and TED2020 domains demonstrate thatDAA successfully mitigates the quality disparities in trans-lation caused by DM, enhancing overall domain-speciﬁctranslation performance."
C5-4,"時系列行動セグメンテーションは、映像内の一連の行動を時間軸に沿って認識し、一連の行動を構成する個別行動区間を検出するタスクであり、行動理解・評価や技術習得支援等への応用が期待されている。既存手法では、全体的な時系列の流れを捉えておらず、ラベルの予測精度が課題となっている。本手法では、多種多様なドメインに対する膨大な一般的知識を持つ大規模言語モデルを汎用的な状態遷移モデルとして活用することで、常識的・論理的な行動手順を考慮し、行動認識の精度を向上させる。提案手法の性能をいくつかのビデオデータセット（50Salads, Breakfast）で評価したところ、既存手法を上回る性能を達成した。"
P3-18,本研究では、講義を受けた学生が質問に回答する形式で講義内容について記述したテキストである「振り返りテキスト」を用いた学生の成績推定に取り組む。具体的には、2 人の学生の初回講義の振り返りテキストから、最終的にどちらがより高い成績を収めるかを予測する成績上下予測を、Meta-Llama-3.1-8B、Llama3.1-Swallow-8B-v0.2、Llama-3-ELYZA-JP-8B、Ruri-large の 4 つの言語モデルを利用して行う。九州大学の 3 つの講義における振り返りテキスト及び成績データを使用した実験の結果、複数のモデルの出力を多数決によって集約することで、およそ 60%の精度で成績の上下を判別することができた。
P4-11,ASD の小児の言語や事物の認識を理解することは，彼らに対する支援の適切性の評価に重要である．当事者やその家族を対象とした研究や生物学的研究のほかに，工学的観点からヒトの模倣可能性が注目されている LLM を活用した研究がある．我々はこれらを組み合わせて ASD の小児における言語認知メカニズムの解明を目指す．そのために，LLMに対して ASD の小児のペルソナを与え，LLM にASD 様の振る舞いを再現させることを目指す．本稿では，LLM に ASD の小児と定型発達の小児のストーリーを識別する能力があるかを調査した結果を報告する．ASD の小児が作ったストーリーを回答するという 5 択の QA タスクにより，現状の LLMによる識別精度は 22%であることを明らかにした．
C7-6,複数のモジュールでの処理を順次通過するようなタスクでの一般的な実装として，カスケードモデルと End-to-End モデルが存在する．カスケードモデルは汎用性が高く，学習データも豊富に存在する一方で，中間出力において情報が一部欠損してしまう．End-to-End モデルは入力から最終出力まで一貫して計算を行うため中間出力における情報欠損が少ないが，既存の訓練データが少なく，学習コストが高い．本研究では両者の課題にアプローチするため，量子計算の性質に着目した．量子計算を用いた量子機械学習モデルをそれぞれ独立に訓練し，推論時のみ回路を結合させることで，量子状態の観測を行わずに中間出力の受け渡しを行う．古典コンピュータに比べて豊富な表現力を持つ量子ビットを中間出力に用いることで，モデル間の情報欠損を抑制する．本研究では対話状態追跡タスクを用いて提案法の検証を行い，今後の課題について考察を示した．
A1-5,"検索拡張生成(RAG)は,外部情報を活用することで,大規模言語モデル(LLM)の知識を補完し,質問に対する応答の精度を改善させる.この手法は,最新の情報を活用できる利点を活かし,多様な分野で広く応用されている.先行研究の多くは性能改善に注力する一方, RAG を利用した際の出力の信頼度に関する特性については十分に研究されていない.金融,医療,医学などの出力への信頼性が強く要求される分野で,出力の信頼度を分析することは重要な課題である.本研究では,医療分野における多様な課題および推論モデルを対象に, RAG が信頼度に与える影響を調査する.具体的には, LLM の予測確率を出力として扱い,期待較正誤差と適応較正誤差を出力確率に基づいて計算することで信頼度を評価する.さらに,プロンプト内の取得文書の順序が信頼度に影響するかについても分析を行う.結果として,モデル,取得する書類数や埋め込み数などの設定,および入力プロンプトの形式に応じて,信頼度と精度に大きな変動が見られることが明らかとなった.これらの結果は,特定のモデルおよび条件に基づいて RAG で用いる構成を最適化する必要性を強調している.1）"
A1-4,大規模言語モデルによる自己説明は，ブラックボックスなモデルの挙動を解釈可能な表現に変換することが期待できる．しかし近年，自己説明が必ずしもモデルの挙動を忠実に反映しておらず、自己説明と実際の挙動が矛盾しうることが明らかになっている．本研究では，入力文中で予測に最も影響を与える語を特定し，これを教師信号として継続学習することによって，自己説明の忠実性が改善するかを検証する．実験により，複数の分類タスクおよび説明様式の条件下で継続学習の有効性を検証し，とくに未学習の分類タスクおよび説明様式においても忠実性が改善することを確認した．
E4-4,エイゼンシュテイン（1898 - 1948）がモンタージュについて述べているものの中に、「同じ」「類似」という要素が入っているかどうかを個別に判定した.調査は「モンタージュ」(1937)、「モンタージュ１９３８年」（1938）、「垂直のモンタージュ」（1936-40）を範囲とした.エイゼンシュテインの考察には、小説に現れているモンタージュを述べているものが幾箇所かある.それらの個所は、小説と映画の双方が同じ一つのモデルを共有し得ることの確度に資するものとなるように思われる.
D9-1,"大規模言語モデル(LLM)の能力を網羅的に評価するのは大変に難しい課題である。LLM のベンチマークの一つに、マルチターンの対話的タスク遂行能力を評価する MT-bench があり、日本文化に合うように改編された Japanese MT-bench も構築されている。しかし、これらのデータセットは 80 問と小規模であることと、2 ターン目の質問が 1 ターン目の回答に依存していないという問題がある。我々はクラウドソーシングを用いることにより、5,000 問程度にまで大規模化し、より広範に評価を行えるベンチマークを構築する。1ターン目の質問はワーカー、回答はワーカーと LLM によって作成することにより、多様な回答を得る。2 ターン目の質問を作成する際は 1 ターン目の各回答に対して作成し、より自然な対話設定となるようにする。"
P3-19,医師によって作成される初診時記録や経過記録などの診療記録の利活用に向け，機械学習とルールベースに基づく診療データベースの構築，そして診療データベースを用いたカルテスクリーニング(臨床試験の選択基準に適合する患者の選定作業)について検討を行う．開発した機械学習モデルは固有表現抽出が Micro-F1 で 0.884，関係抽出が 0.768 と一定の精度で診療記録からの情報抽出が可能であった．また診療データベースを用いたカルテスクリーニングの精度は，診療記録を直接用いた際の精度よりも最大で 4.2 倍改善することが明らかとなった．本研究で構築した診療データベースはカルテスクリーニングに有用である可能性が示唆された．
P4-10,自閉スペクトラム症（ASD）は、定型発達の人とは異なるコミュニケーションの取り方や行動パターンで特徴付けられる発達障害であり、文処理に困難が伴うことが多い。本研究では、ASD の文処理を理解し支援するために、ASD の人の文処理データを用いて言語モデルをファインチューニングするアプローチを提案する。このアプローチにより、ASD の人々の文処理の特徴を反映したモデルの構築が行われ、ASD の統語論処理能力に関する理解の深化や、ASD の人々の読解ニーズに応じた支援ツールの実現に向けた可能性が示唆された。
E6-6,株価変動に関する記事は，変動の要因を分析する点で有用であるが，人手で作成するには手間と時間がかかるため，十分な量が存在していない.本研究では，大規模言語モデル(LLM)を用いて記事を自動生成する手法を提案する．日々の株価変動率ランキングに基づく日本語データセット“JFinSR”を構築し，記事と株価変動要因に関する情報を収集した．このデータセットを用いた few-shot 学習により，株価変動要因から高品質な記事を生成する手法を実現し，zero-shot より優れた性能を達成した。
A3-6,スマホ依存（Problematic Smartphone Use; PSU）患者に対する診療支援では、行動パターンの詳細な把握と、それに基づく専門的な情報提供が求められる。近年、スマホのログデータなどを分析することで患者の行動パターンを詳細に把握できるようになったが、アンケートデータや診療録などの複数の情報と組み合わせてそれらを総合的に解釈し、専門的な情報を提供することは容易ではない。そこでLLM を活用し、自動要約や情報提示による支援が期待されるが、プライバシー保護の観点から、患者個人の詳細な情報をパブリックな LLM に入力することが困難である。本研究では、ローカル LLM とRetrieval-Augmented Generation（RAG）を組み合わせたプライバシーに配慮した対話システムを提案する。具体的には、患者個別の利用履歴データ、診断経過、関連するドメイン知識を言語モデルでベクトル化し、知識ベースに格納する。プロンプトに基づき類似度検索で情報を抽出し、ローカル LLM の回答生成を支援するシステムを構築した。これにより、プライバシー保護とドメイン知識の活用を両立し、PSU 診療における意思決定を効果的に支援できることをケーススタディを通じて示す。
C5-5,本研究は，村田[1]による ChatGPT を用いた教育的小説の生成や，宮本ら[2]による ChatGPT によるノベルゲーム自動生成システムを参考にして，教育的ノベルゲームを作成した．ChatGPT を用いたノベルゲームには DeepGame[3]があるが，DeepGame はユーザ入力による逐次生成であるため，物語の全体像が見えにくい．そのため，初めに物語の全体像をフローチャート形式で生成してから細かい生成を行う．生成の際は，被験者が興味を持つ内容になるように，海外旅行や料理などの物語のテーマを設定する．ノベルゲームの面白さや教育的効果についてアンケートと事前，事後の小テストを用いて被験者実験を行った結果，筆頭著者による被験者実験では興味や一貫性などについて概ね良いという評価になったが，小テストの結果はほぼ変わらなかった．また，物語のテーマによって評価が異なり，海外旅行や料理をテーマにしたものよりも，SF をテーマとしたもののほうが評価が高かった．著者以外の被験者による被験者実験では，被験者によって評価が大きく異なり，特に評価の低かった被験者 A は小テストの点数も低かった．被験者 A は短時間で物語の途中にあるバッドエンドに辿り着いており，内容を十分に理解できなかったからではないかと考えられる．読むのにかかった時間やシーンの選択で評価が変化すると考えられる．
P1-9,"我々はクラウドソーシングを使って、日中対訳web サイトのトップページ URL の対を約 1 万件収集し、約 460 万文対の日中対訳コーパスを作成した。まずトップページ URL を起点としてそのドメインをクロールし、次に 16 万語対の日中対訳辞書を用いて文書対応と文対応を行い、最後に別途用意した120 万文対の高品質な日中対訳文対から作成した対訳コーパスフィルタを用いてフィルタリングを行った。我々の日中対訳コーパス 460 万文対は、既存の日中対訳コーパス CCMatrix(1,240 万文対)[1]に比べ、大きさはの約 3 分の 1 であるが、翻訳精度は同等であり、クラウドソーシングの有効性を示せた。"
Q2-3,日本語 LLM の出力の安全性・適切性向上のためのデータセット AnswerCarefully を紹介する。このデータセットは、回答に注意が必要な質問とその参考回答からなっており、先行の英語による類似データセットを参考に設定した広範な有害カテゴリを踏まえ、人手により作成されている。このデータを使用して日本語 LLM をファインチューニングしたところ、一般の回答の有用性を損なうことなく、出力の安全性が向上することが確認できた。また、このデータをベンチマークとして 12 の日本語 LLM を評価した結果についても報告する。
Q3-20,"We present a framework that streamlines the preparationof human evaluation process for text or audio automaticallygenerated from video. In such evaluation tasks evaluatorsoften assess the generated text or audio while watching avideo. Consequently, preparing for these evaluations canbe highly resource-intensive because the process typicallyinvolves several steps cutting a video and audio segments,synthesizing speech with text-to-speech tools, merging au-dio and video, and developing a user interface for crowd-sourcing annotation collection. Our framework automatesthese steps, reducing the researchers’ workload."
Q4-15,本研究では、真面目さという性格を LLM に付与した場合のタスク正解率への影響を検証する。手法としては、真面目さ、不真面目さを付与する複数種類のプロンプトを用いる。実験では、日本語の 3 種類のタスクを使用して各プロンプトを検証する。実験の結果、真面目さを付与した場合はプロンプトによって正解率が向上することもあれば低下することもあること、不真面目さを付与した場合は基本的に正解率が低下することがわかった。また、正解率に大きな変化を与える言語表現が存在することも判明した。
C3-3,本研究では，非構造ドキュメント画像の情報抽出に取り組む．光学文字認識（OCR）の結果に対して大規模言語モデルを適用することで高精度な情報抽出が行えることが報告されているが，文書画像は一般に文字だけでなく，図形や文字の色などを含んだレイアウトも用いて情報を表現している．そのためOCR によって文字情報に劣化させる方法に比べ，画像を直接扱う Large Vision-Language Model の方がより高精度に抽出できる可能性がある．そこで，非構造ドキュメントとしてメニュー画像を対象とし，この方法で情報抽出を行い従来手法と比較した．
Q4-5,"本稿では、疎なパラメータを用いて大規模言語モデルの部分的更新を行なうことで効率よく Fine-Tuneする手法を提案する。大規模なコーパスで学習された事前学習済みの言語モデルを特定のタスクやドメインに対して Fine-Tune するには、事前学習済みモデルのパラメータを固定し、少量の追加パラメータのみを学習する手法(Parameter-Eﬃcient Fine-Tuning,PEFT)が主流である。しかし、通常の PEFT は学習時の計算リソースを抑える一方でパラメータをすべて更新するため、知識保持および編集が重要なタスクやドメインの性能が劣化したりモデル解釈性が失われたりする問題がある。そこで本稿では、疎なパラメータを用いることで計算リソースを抑えつつ、新たにモデル解釈性も備えた新しい PEFT を提案する。事前学習済みモデルとして RoBERTa とLlama3-8B に適用することで、言語理解と算術推論ベンチマークで性能が向上すること、およびモデル解釈が可能であることを示す。"
Q8-15,"Recent advancements in Sparse Autoencoders (SAEs)have uncovered insightful features in large language models(LLMs). In this study, we identify language-speciﬁc SAEfeatures, which are predominantly found in the later layersof the LLM. Using these features, we steer the output lan-guage of an LLM. In an experiment based on a translationtask, our method achieves a 49% accuracy in generating thedesired target language, outperforming a previous methodusing individual language neurons for steering. This workdemonstrates the potential for SAE features for languagesteering."
Q6-10,言語モデルが否定を理解する能力を評価するための様々な英語データセットが構築されているが，日本語においては，そのようなデータセットを構築する取り組みは限られている．本研究では，否定理解能力を評価するための日本語言語推論データセットJNLI-Neg を構築する．さらに JNLI-Neg を用いて既存の言語モデルを評価し，それらの否定理解能力の現状と課題を明らかにする．
Q1-19,人間は視覚的な情報と言語的な情報を受け取ると，それに関連する事前知識を用いて物事の“見えない部分”を想像するすることができる．物体の見えない部分を予測するタスクはコンピュータビジョンの分野では精力的に研究されているが，多くは対象物の一部が隠れた物体を対象とした物体認識であり，裏側や側面など見えない部分には焦点は当てられていない．そこで本研究では，物体の裏側や側面の認識能力を評価するためのタスクを提案し，線画と写実画像を用いてデータセットを構築した．実験では，提案タスクを用いて人間と代表的な大規模画像言語モデルの性能を比較した．その結果，人間にとって簡単なタスクであるにもかかわらず，最先端の商用モデルでも人間の性能には及ばないことを確認した．
C1-1,"This paper introduces a novel system for the automaticidentification of argument structures in German sentenc-es. Our approach addresses the complexities of Germansyntax, including flexible word order, rich morphologicalinflection, and diverse clause types. We leveragespaCy’s German language models, which provide com-prehensive pipelines for tagging, morphological analysis,parsing, and lemmatization. By combining the  modeloutputs with linguistic rules, we have  implemented arule-based approach for argument structure identifica-tion.To evaluate our system, we created a gold-standarddataset through a systematic annotation process in whichannotators validated  and refined initial parser outputs.Beyond argument extraction, our parser identifies themain verb of each (sub-)clause, classifies the genus verbi(active/passive), and determines clause types (e.g., mainclauses, various subordinate clauses). This work lays afoundation for large-scale corpus-based investigations ofargument structures in German, enabling more compre-hensive linguistic analyses."
A7-2,"単語埋め込みは単語を多次元の実数ベクトルとして表現し，データとして解析しやすくする一方で，その数値の解釈が難しい．独立成分分析（Independent Component Analysis, ICA）を用い，埋め込みから独立した主要な特徴を抽出することで，より明確な意味軸を生成し，言語間で普遍的な意味軸が存在する可能性がある．しかし，言語内および言語間における独立成分の一貫性は，これまで十分に検証されてこなかった．そこで，本研究では，一つの言語内と複数言語間の両面から，意味軸の一貫性を調査した．まず，言語内の一貫性を調べるために，ICA アルゴリズムを複数回実行して得られた結果をクラスタリングし，意味軸の再現性に着目した．次に，統計検定を用いてこれらの軸の対応関係を検証することで，言語間の一貫性を統計的に評価した．この研究は統計的手法を適用し，意味軸の信頼性と普遍性を担保するための手法を確立した．"
Q6-7,ツール拡張言語モデルを用いた対話管理エージェントは流行しているが、既存ベンチマークデータは実際のビジネスタスクと乖離があり、商用チャットボットに使えない。本研究で提案するデータ作成手法ではデータ作成者が与えた必要最小限の情報に基づいて、要望に沿った大量で高品質なデータを自動的に生成してオーダーメイド対話管理を実現した。作成されたデータは学習データとして対話管理エージェントの学習や改良に使える。
P1-20,低資源言語の機械翻訳モデル構築における課題として，十分な量の対訳データの確保が挙げられる．さらに，対象ドメインが限定されている文の翻訳などの場合，対訳データだけでなく原言語側の単言語データを確保することさえも困難な場合がある．本研究では，対象ドメインの原言語側の単言語データが少量しかない状況下で，学習データ量不足の課題を解決するための大規模言語モデル（LLM）を活用した多様で高品質な合成データ生成手法を提案する．提案手法の効果を確認するために，タイ語から日本語へのニュース翻訳の実験を行った．提案手法で合成したデータを用いてLLMをファインチューニングしたニュース機械翻訳器は，タイ語から日本語へのニュース翻訳タスクにおいて従来手法を上回る性能を達成し，BLEU値を19.9ポイント改善した．
P8-10,本論文では，多様な地方議会会議録を統一的に扱うデータスキーマを提案し，それを活用することで自治体を横断して議会会議録を検索・視覚化するシステム「ぎ〜みる v2」の概要について述べる．本システムは従来システムと比較して Embedding に基づく発言検索，任意の区域を対象とした視覚化の機能が追加され，さらにシステム運用の簡便化を図ったことで，異なる自治体セットを対象とした複数のシステムを 1 つのサーバで容易に運用可能とした．
P6-15,Wikipedia の情報に基づいて、構造化した知識を抽出する研究は多く行われているが、基本的には、Wikipedia の記事が一つのエンティティについて述べていることを前提としている。しかし、実際のWikipedia の記事には、小説を原作としたような映画のように、元の創作物からの派生的なエンティティがまとめて記載されることが多い。本研究では、そのような複数エンティティが記述されている可能性を考慮した中で、Wikipedia 記事のクラス分類を行う方法を提案するとともに、森羅のデータを用いて本手法の性質について議論する。
Q8-8,比較法学研究を推進するために日本法と外国法の類似条項を対応付ける研究が行われている．その手法の一つに汎用言語モデルである BERT が使われている[1]．これにより，事前学習と fine-tuning の組み合わせで End-to-end 学習を可能とする．法令分野の事前学習モデルは既にいくつかある[2，7]が，判例など法令以外の文書もコーパスに含まれており，法令のみをコーパスとした BERT モデルは存在せず，高精度な法令解析を行うには，法令のみをコーパスとした BERT モデルが必要となる．したがって，本研究の目的は，日本の法令文解析に適した事前学習モデルを構築することである．法令のみをコーパスとした事前学習モデルを二通り作成し，各モデルの言語理解能力，外国法対応付け能力をテストした．結果として，F1 値で東北大学が発表した，日本語汎用事前学習モデル（以降，東北大 BERTi）を上回る性能を示した．
P6-17,情報欲求に起因して自然発生する質問（自然な質問）のマイニングには様々な応用がある．しかし，素朴なマイニング源として考えられる検索クエリログは一般利用可能でない場合が多い．本研究では，検索クエリログの代わりにテキスト生成モデルを用いた自然な質問のマイニング手法を提案する．具体的にはまず，情報欲求の対象を指定し，これに関する質問の観点をテキスト生成モデルに予測させる．次に，大規模言語モデルを用いて情報欲求の対象と予測された質問の観点を表す 2 つのキーワードから自然言語の質問文を生成する．実験の結果，検索クエリログを用いない自然な質問のマイニングができる可能性を示唆した．
P1-22,"This paper introduces a Japanese-English parallel cor-pus composed of literary works, constructed mainly us-ing bilingual texts from Aozora Bunko and Project Guten-berg. Existing Japanese-English parallel datasets, suchas JParaCrawl, JaParaPat, and ASPEC [1, 2, 3], oﬀer ingcoverage of common, patent, and academic domains, theylack resources speciﬁcally designed to address discourse-level phenomena and context-aware translation challengeswhich are existed in literary translation task. To bridgethis gap, we build upon the ""English-Japanese TranslationAlignment Data""1）developed over a decade ago, updatingand expanding it to better support research in discourse-level literary translation and document-level context mod-eling. Baseline experiments with transformer models onthe constructed dataset demonstrate limited performance,highlighting the inherent challenges of literary translationand underscoring the need for more advanced methodolo-gies and resources to enhance translation quality for literarytexts."
P8-12,本論文では，株式会社カカクコムが運営する求人ボックスを題材として，大規模で更新頻度が高い検索サービスにおける高性能なレコメンドシステムの設計方針を提示する．文ベクトルを生成するのに適した深層学習モデル Sentence-BERT を用いて，閲覧履歴からユーザーを表現するベクトルを作成することで，パーソナライズされた推薦を可能にする．さらに Item2vec の思想を応用したファインチューニングを行うことで，文章の意味のみならずユーザーの意図をベクトル表現に反映することが可能になる．
Q6-5,"The Japanese Natural Language Inference (JNLI) datasetis a valuable resource for NLI research. However, we foundit contains inconsistencies and lacks structural diversity.This paper presents a two-pronged approach to addressthese limitations: A rigorous correction of errors and thecreation of a new, expanded dataset with diverse sentencestructures. We detail our iterative correction methodology,leveraging Large Language Model (LLM) predictions andmanual review. The new dataset introduces variations insentence type (noun, verb, adjective/quantiﬁer), enrichingthe data. Furthermore, we evaluate the performance ofour internally created LLM model Takane on the original,corrected, and newly created JNLI datasets, demonstratingsuperior performance compared to existing state-of-the-artmodels."
C1-3,本稿では，The KIT Speaking Test Corpus（以下，KISTEC と表記）の設計と仕様について報告する．KISTEC は日本の大学生英語学習者が受験したスピーキングテストの解答音声を基に構築した約 30万語規模の話し言葉コーパスであり，書き起こしテキストとアノテーションから構成される．各種タグだけでなく，学習者の属性や，全体およびタスクごとのスコアを参照できるため，個人差やタスク特性を考慮した発話の分析を可能とする．KISTEC は L2話者の非流暢性現象を自動検出する BERT モデルの性能評価にも使われており[1]，NLP 研究への応用も十分に可能である．
P9-2,"Web からクロールされた事前学習コーパス内の有害性を含む文章がLLM の有害な出力を引き出すことは知られているが、事前学習コーパス内の有害性が時とともにどのように変化するかは十分に調査されていない。特に、紛争の勃発や移民問題などの社会問題を通じて2,3 年単位で世論に起きた急激な変化がどのようにコーパスに影響を与えるかは未だ調査されていない。本研究では近年その取り巻く環境が大きく変わった民族に対する言及がどのように変化しているかを、事前学習に用いられることの多いCommonCrawl の日本語データを対象として調査する。結果として CommonCrawl では紛争などの事象が発生した時期を境として、特定の属性に対する有害な文脈を伴う言及が増加することが確認された。"
Q6-12,本研究では，小論文にルーブリックに基づいたアノテーションを行い，そのデータを用いて小論文自動採点を行う方法を提案する．ルーブリックの評価部分に対応した小論文の文書内構造の情報を，小論文にタグをつけるという形でアノテーションを行った．そうして得られるタグを小論文と同時にトークン化し，採点モデルにスコアを予測させ，小論文のみでの自動採点と比較することで，提案手法の有効性を明らかにした．
Q10-25,ニュース記事と、記事に登場する企業名の法人番号を紐付けたい。しかし、同名企業が存在する場合、一意に特定できないことがある。既存手法では、ニュース記事と、企業情報のベクトルの類似度が最も大きい法人番号を出力しているが、企業データベースが持つ他のテキスト情報を有効活用できる手法ではない。そこで、GPT による QuestionAnswering を利用し、他のテキスト情報を適切に活用可能な Entity Linking を提案する。提案手法により、既存手法に対し 65%ポイントの性能改善を確認した。さらに、Web 検索結果のテキストを追加で与えることで、5%ポイントの性能改善を確認した。
Q8-17,"文脈内学習(In-Context Learning; ICL)において,デモンストレーション(デモ)の選択はタスク性能に大きな影響を与える.既存研究ではデモの選択手順については研究されているが,選択基準であるデモの性質は十分に調べられていない.本研究では,デモの「親和性」と「多様性」という 2 つの性質を新たに提案し,その内の親和性が性質が複数のモデルおよびデータセットにおいてデモ選択に望ましい性質であることを示した.さらに,既存手法で選ばれたデモが, 2 つの性質のタスク性能を向上させる方向へ集約していることを示し,デモ選択とタスク性能のメカニズム解明への示唆を得た."
P10-19,本研究は、日本語で学習された大規模言語モデル（LLM）を観光対話システムに適応させるため、効率的なデータ作成とチューニング手法を検証することを目的とする。疑似対話データを用いた SupervisedFine-Tuning（SFT）および少量の Preference データを用いたチューニングを実施し、観光案内タスクにおける対話の自然性、一貫性、満足度、信頼性への寄与を評価した。実験では、汎用指示チューニングのみのモデル、SFT モデル、Preference モデルを比較した結果、SFT モデルは対話の自然性と満足度を大幅に向上させる効果が確認された。一方、Preferenceモデルでは Hallucination の抑制が可能であったが、満足度の向上には課題が残った。
Q10-19,生物医学イベント抽出は階層的な構造のイベントが多く現れるため，イベント間の関係も考慮した抽出が必要となる．従来研究ではエンコーダモデルを利用した手法が多く提案されているが，モデルサイズなどの制約から，複雑な関係を捉える言語能力に限界があった．そこで，本研究では生物医学分野におけるデコーダモデルを用いた階層的な構造を持ったイベント抽出の実現を目指し，質問応答を繰り返して，階層的なイベントを抽出できるようにデコーダモデルをファインチューニングする手法を提案する．実験ではベースモデルに LLaMA-3.2，データセットに GENIA2011 を用いて，性能を評価する．
Q4-7,近年，言語モデルの巨大化により，計算コストが大きく増加したため，性能を保ちつつモデルのパラメータ数を削減する手法が求められている．その一つに知識蒸留があり，中間層蒸留はその一種である．モデルの中間層出力も損失関数の計算に用いる中間層蒸留は有効とされてきたが，線形写像を推論時に用いないため，学習の効果が保証されない問題があった．本研究では，中間層蒸留の線形写像を LoRA のアダプターで代替し，推論時に除かれない線形写像を実現した LoRAILD を提案し，実験を行った．その結果，中間層蒸留の効果に対する否定的な結果を得た．
C3-1,本稿では画像とテキストを入力として文生成が可能なタイプの日本語向け大規模マルチモーダルモデル(LMM)開発について報告する。今回採用した開発手順は初めに LMM の構成要素であるモデルパーツの付け変えを行った後に追加で訓練を行う形態をとっている。この開発過程で行ったモデルの新しい付け替え(結合)方法やその手順、そこからさらに日本語向けにデータを用意し、追加訓練を行った内容について説明する。作成した LMM に対して日本語向けベンチマークで評価し、モデル精度とその変化についても公開する。
A5-2,近年の大規模言語モデル(large language model;LLM)は，人間らしく言語を扱う能力を示しつつある一方で，理論言語学が明らかにしてきた人間の言語機能の普遍的性質を持っているかは明らかでない．本研究は「代名詞の束縛変項照応」という現象に対する構造的な制約に注目し，LLM がこの制約に従うか否かを調査した．実験にあたっては，人間の場合でも判断に揺れや個人差があることを考慮し，統語構造とは関係のない要因を除去する「言語機能科学」の方法論を採用した．実験の結果，非構造的要因がないと考えられる状況においても，LLM は束縛変項照応の構造的制約に従わない判断をする場合があり，人間の言語機能との差異が示唆された．
Q4-17,大規模言語モデル(LLM)のファインチューニングにおける入力系列の作成時には，1 つのサンプルに[PAD]トークンを最大系列長まで連結する Padding戦略が広く採用される．しかしファインチューニング時には，最大系列長に収まるように複数サンプルを連結し入力系列を作成する Packing 戦略を採用する選択肢も考えられる．この Packing 戦略は，複数のサンプルを連結して入力するので，Padding 戦略と比較して学習効率が高い利点がある．しかし，Packing 戦略が，Padding 戦略を採用した時と同様の学習効果が得られるかどうかは明らかになっていない．本研究では，LLM のファインチューニング段階における，Packing 戦略の学習効果を検証し，特定の学習データに対しては，Padding 戦略で学習した場合と同等の学習効果が得られることを示す．
B8-2,主体性とは「行為を引き起こしているのは自分だ」という行為主体としての自己の感覚を指す．主体性は well-being やうつ病などと密接に関連しており，文章を通じて主体性をモニタリングすることは非常に重要である．しかし，ある行為の記述に対してどの程度の主体性を認めるかという判定は人によって異なる．本研究ではアノテーションのばらつきを考慮したコーパスを構築し，主体性の多寡を推定するタスクと解釈のばらつきを推定するタスクを実施し予備的分析を行なった．前者のタスクでは高い精度を示したものの，後者のタスクでは課題が残った．主体性という心理学的概念に対して自然言語処理によるアプローチの可能性が示唆された．
Q3-22,学術ポスターは文章と図表を組み合わせて研究内容をまとめたポスターであり，論文の概要を短時間で理解するのに効果的なフォーマットである．従来の学術ポスターの自動生成に関する研究は主にレイアウトの生成を目的としており，コンテンツも含めた生成は行っていない．そこで本研究では，学術ポスターに含まれる文章や図表，レイアウトを LLMを用いて段階的に予測することで，学術ポスター全体を生成する Paper2Poster システムを構築した．定量的および定性的な評価結果より，構築したシステムは整列されたオーバーラップのない，視覚性に優れたポスターを生成可能であることがわかった．
Q2-1,今後社会に，AI が浸透するにつれ，人と AI の協働が新たなチームワークとして注目されるはずである．近年においては，大規模言語モデル(LargeLanguage Model; LLM)の発展により，人間と LLMの協働が様々な分野で検討されている．従来の研究では LLM の性能向上や人間と効果的に協働するための方法に焦点が当てられてきたが，対人スキルなどのユーザ固有の能力が LLM との協働に与える影響は明らかにされていない．本研究は人間と AIの協働パフォーマンスを評価する JHACE (JapaneseHuman-AI Collaborative Evaluation)を提案し，実験によって対人スキルが AI との協働に与える影響を調査する．結果として，対人スキルは AI の回答への批判的対応に影響する可能性が示された．
A3-4,学術分野の PDF 文書解析のデファクトスタンダードである GROBID は主に英語で訓練されており，日本語論文の解析は困難であった．そこで，本研究では日本語論文を手動でアノテーションし，新たに GROBID モデルを訓練した．実験の結果，我々のモデルは既存モデルに比べて日本語論文に対する識別性能が向上し，特に非レイアウト関連の要素で優れた性能を示した．さらに，解析対象の論文 PDFと同一の収録誌を訓練データに含めることの有用性を明らかにした．また，収録誌ごとに識別性能を算出し，性能差が生じる原因を定性的に分析した．
E6-4,本研究では，テキストデータを用いた株価のリターン予測タスクにおいて，独立成分分析(ICA)を適用することで解釈性の向上を目指す．近年，リターン（株価の変化率）の新たな予測変数として，テキストデータから得られる埋め込み表現が注目されている．ただし，テキストの埋め込み表現の各次元を変数として用いる手法では，個別の埋め込み次元を解釈することは困難である．そこで，本研究では，埋め込み表現に対して ICA を適用することで，株価の変動の解釈可能性を向上させることを目的とする．実験の結果，意味的に解釈可能な複数のトピックが抽出され，これらのトピックは株価変動と関連性を示すことが確認された．
P4-12,"「""それ""であると認められることをもって、""それ""の定義を満たす」とする社会的承認という方法で定義された「心がある AI」の実現を目指す．そして人と AI 自身が「心がある」ことを認める AI のつくりかたを考える．本論文では，社会的承認による定義やこの場合の評価方法の実現性，作成する人工物の有効性を議論する端緒を形成することを目的に，簡単な発話応答に対する評価を実施した．実験ではダニエルデネットの提唱する「設計スタンス」「意図スタンス」の考え方に基づく，設計発話/応答と意図発話/応答の組み合わせを作成し印象を調べた．"
D9-3,本研究では、松下幸之助の思想や発言を忠実に再現する「松下幸之助」再現 AI システムを開発した。音声認識、返答生成、音声合成、動画生成の 4 つのAI モデルを統合し、ユーザとの自然な対話を可能にした。本システムは、膨大な著作物や音声データを学習対象とし、データクレンジングやリアルタイム処理の最適化、さらにドメイン知識の活用により、精度と自然さを大幅に向上させている。実験結果では、提案手法が返答生成の正確性、松下幸之助らしさ、応答の適切な長さなどの評価項目で高い性能を示し、史実に基づく自然な応答生成を実現した。これにより、企業理念の継承や文化的遺産の保存など、多様な領域での生成 AI 技術の新たな応用可能性が示唆された。
P3-9,文法誤り訂正における自動評価尺度の目的の一つは，人手評価を模倣するような訂正システムの順位づけである．しかし，現状の自動評価は人手評価と乖離した評価手順に基づいており，このことは人手評価を模倣する目的と矛盾している．具体的には，人手評価は文単位の相対的な評価結果をレーティングアルゴリズムで順位に変換するが，自動評価では文単位の絶対的な評価結果を平均するなどしてコーパス単位評価に集約し，ソートすることで順位とする．本研究では，この乖離を埋めるために既存の自動評価尺度を人手評価の方法と一致するように用いることを提案し，実際に多くの尺度で人手評価との一致度が向上することを示す．
A1-6,"昨今,大規模言語モデルは世界中で広く使われるようになったが,安全性への懸念が叫ばれている.本研究では,手動設計の敵対的プロンプトに対し,既存のデータセットを調査することで,多種多様な敵対的プロンプト手法を把握し,それらを体系的に分類することを目指した.既存データセットを人手で調査し,最終的には,敵対的プロンプトを大小 49 個のカテゴリに分類した.また,データセット内で用いられた手法を数え上げることで,手法の偏りを明らかにした.最後に,本分類の各カテゴリに対して敵対的プロンプト例を作成し, Github 上に公開した. https://github.com/Tasuku-Sasaki-lab/Adversarial-Prompt-Classification 本研究を通じて,手動設計の敵対的プロンプトの手法の実態が明らかとなった.これらの成果は, LLM に対する RedTeaming テストや,敵対的プロンプト防御手法の開発を通じて, LLM のサイバーセキュリティ向上に貢献するだろう."
C7-5,声調言語や高低アクセント言語を持つ地域を中心に，音楽の旋律と言語の韻律の変化を一致させる傾向が指摘されている．日本においては，とりわけ日本民謡の旋律と言語の韻律の関連が示唆されているものの，具体的な関連を明らかにすることはできておらず，体系的な実証研究が不足していた．本研究では，日本民謡における旋律と方言アクセントとの一致関係を明らかにすることを目的とし，東京，京都，鹿児島の計 382 曲を対象に旋律の音程変化とアクセントの高低変化を比較し，一致関係を検証した．その結果，日本民謡の旋律とアクセントの間に地域差を含む一致関係が存在することを明らかにした．
C7-4,本研究では，自己教師あり学習音声モデル（SSLモデル）の第二言語（L2）獲得過程を，Critical Period（CP）仮説の観点から分析する．L2 獲得におけるCP 仮説とは，人間は L2 への接触開始時期が遅いほど，その習得が困難になるとするものである．CPに注目することは，SSL モデルの学習メカニズムや効率的な L2 学習手法に加え，人間の脳の言語学習の仕組みに関する新たな示唆をも与える可能性がある．実験の結果，SSL モデルでは L2 の音韻獲得における CP 仮説は成り立たなかったが，早期に L2 の学習を開始したモデルは L1 モノリンガルモデルや初めから 2 言語で学習したモデルとは異なる埋め込みを獲得していることが示唆された．
P3-8,LLM と  Docker 環境を統合した対話型言語処理教育プラットフォームを提案する．本システムは，Electron ベースのデスクトップアプリケーションとして複数のOS 環境で動作し，Docker コンテナ上に構築された再現可能な言語処理環境を提供する．ユーザは独自の Web UI や Jupyter Notebook を介して LLM と対話しながら，様々な言語処理ツールを活用した実践的な学習が可能となる．また Rubyを用いた DSL による記述で独自のアプリを作成できるため，多様な教育ニーズに対応した柔軟なカスタマイズが可能である．本プラットフォームは，LLMを用いた新たな教育手法の探求を促進し，言語処理教育の質的向上に貢献すると期待される．
D9-2,"Creating training data for supervised learning mod-els has traditionally been time-consuming and costly.However, recent advancements in large language models(LLMs) have enabled many studies to leverage these mod-els for synthesizing training data. In this paper, we exploredata synthesis strategies for conversational semantic frameanalysis, a complex task involving the extraction of enti-ties and relations from dialogue contexts. We propose twonovel methods tailored for this purpose: Forward Synthesisand Reverse Synthesis. Our results demonstrate that For-ward Synthesis can achieve performance levels comparableto its creator LLM. Additionally, we provide an in-depthanalysis of Reverse Synthesis, highlighting the challengesin this approach."
P4-13,本研究では，埋め込みベクトルと頻度情報を基に移動動詞の粒度を定量化し、それと着点との共起傾向を検証する。これまでの研究では，移動事象における着点志向性が認知的に優位であり，言語にも反映されることが示されてきた。しかし，着点と共起しやすい動詞については主観的な議論にとどまっていた。本研究では，英語の移動動詞を対象に，COCA から抽出した用例を基に埋め込みベクトルを生成し、その分散の平均値と頻度から粒度を算出する手法を提案する。
C5-6,本研究は，批判的思考力育成の有効手段とされるディベートにおいて，人的リソースの負担が大きいエキスパートジャッジの役割を，LLM エージェントで代替可能とするシステムを提案する．ディベートエキスパートらと共にマルチ LLM エージェントシステム用のディベート評価指標(ジャッジ指標)を新たに設計し，それを元に肯定側へフィードバックを提供するジャッジシステムを構築した．さらに，システムが出力したフィードバックと，エキスパートが作成した模範フィードバックを比較評価する実験を行った．その結果，論点の整理などといった観点では LLM によるフィードバックが人間エキスパート以上の品質を示した．
A3-5,"LLM は大規模な自己教師あり学習によって汎用的な言語知識を獲得するが,主に Web データから構成される事前学習データは不適切な社会的バイアスを含んでおり, LLM はこれらを強く継承してしまう問題が知られている.本研究では,事前学習データ内の多様な保護属性(人種・性別・宗教など)を正確に検出し,その属性に対する表現の感情極性(Regard)を分類することによってバイアスを分析・軽減する手法を提案する.また,代表的な事前学習データとして Common Crawl を用いた実験により,提案手法の効果を定性的・定量的に検証する.注意：本論文には不快な表現が一部含まれます."
E6-5,内閣府の景気動向調査である景気ウォッチャー調査では，さまざまな職業の人々による現在および将来の経済状況に関する評価が判断根拠テキストとともに公表されている．本研究では，この景気ウォッチャー調査データをテキスト埋め込みの手法で数値データに変換し，景気判断に影響を及ぼす要因を定量的に分析する．テキスト埋め込みは解釈が難しいことで知られているが，本研究では独立成分分析とFisher の線形判別分析を組み合わせることで，高次元のテキスト埋め込みデータを解釈可能な低次元データに変換することで，人々の景気判断に寄与しているテキストの要素について調査する．
Q3-23,視覚言語モデル（VLM）の研究は急速に進展しているが，日本語の視覚言語（V&L）タスクにおける評価環境は未だ十分に整備されていない．その結果，日本語評価データセットは散逸し，網羅的な性能評価をすることは困難な状態にあった．本研究では，日本語性能に関する複数のマルチモーダル課題を統一した環境で評価するためのツールキットllm-jp-eval-mm を提案する．本ツールキットは既存の 6 つの日本語マルチモーダル課題を統合し，モデル出力を複数の指標で一貫して評価するベンチマーク基盤である．本稿は llm-jp-eval-mm の構築と継続的な開発のための設計概要を述べ，公開されている13 種類の日本語・多言語 VLM を評価した結果を報告し，既存研究の知見に照らして議論する．
B8-3,"本研究では,単言語コーパスをもとに日本語文平易化コーパスを疑似的に構築する手法を提案する.日本語文平易化タスクにおいては,大規模なコーパスの不足が課題である.本研究では,単言語コーパスから類似度が高く,かつ難易度が異なる 2 文を抽出することにより,約 6 万ペアを含む疑似日本語文平易化コーパスを構築した.また,構築したコーパスを用いて平易化モデルを構築することにより,コーパスの品質を評価した.その結果,提案手法の有効性を明らかにした."
Q4-16,いくつかの意味論的なタスクをとりあげ，BERT型モデルに対して対照学習規範を用いた学習の効果を検証する．対照学習規範を BERT に適用した先行研究は，基となる BERT の埋込層に追加されたPooling 層のみを対照学習規範で学習するものが多いのに対して，この報告では，BERT の埋込層も含めた学習を行う．実験によると，対照学習規範は，単一事例規範と併用することによって，性能改善が達成できることがわかった．
A5-3,"Acquiring factual knowledge for language models (LMs)in low-resource languages poses a serious challenge, thusresorting to cross-lingual transfer in multilingual LMs(ML-LMs). In this study, we ask how ML-LMs acquireand represent factual knowledge by conducting multilin-gual factual knowledge probing and a neuron-level investi-gation of ML-LMs. Additionally, we trace the roots of factsback to their source (Wikipedia) to understand how ML-LMs acquire speciﬁc facts. We identiﬁed three patternsin how ML-LMs acquire and represent facts: language-independent, cross-lingual shared, and transferred."
Q4-6,LLM の効率的な段階的事前学習法を提案する．提案法では，事前に適切な埋め込み層と出力層のパラメータを獲得し，それを初期値として再利用した上で固定して事前学習をする．この手順を取ることで，標準的な事前学習より計算量およびメモリ要求量を削減可能であることを示す．また，事前に獲得した埋め込み層と出力層の単語ベクトルとしての性能が標準的な事前学習で得られる表現よりも優れており，それが LLM の最終的な性能向上に寄与する可能性があることを示す．
Q10-18,本研究では Sentence BERT を用いて、源氏物語における古今和歌集の序文や和歌からの引用の検出を行った。コーパスから、源氏物語の一文と古今和歌集の一文あるいは一句のペアを作り、この二文をモデルへの入力とした。このとき、源氏物語の一文に古今和歌集の一文あるいは一句が引用されていれば正例、引用されていなければ負例として、二値分類を行った。負例の数は、正例の数との比で設定した。実験の結果、正例と負例の比を 1:58 にしたシステムにおいて、69.6%の F 値で古今和歌集からの引用を検出した。また、実験によってシステムが、表記の異なる言葉や作中に何度も登場する語句による引用の検出を苦手としていることが分かった。
Q8-16,Vision-Language Model の学習に必要な Visual In-struction Tuning データセットは、コストの観点から主に人手ではなくデータ合成によって作成される。合成データの利用における課題は、合成時に発生する不適切な合成データを取り除く上での正確性と、時間的効率性である。本稿では、CLIP および VLMas a judge を用いたフィルタリングの正確性と効率性について検証する。実験の結果、VLM as a judge は正確性が17.3%高いがCLIPの方が62倍高速に動作すること、これら手法の併用により VLM as a judge単体に比べ正確性を損なうことなく 36%高速にフィルタリング可能なことがわかった。
P10-18,本研究では，対話相手に適応した応答生成を目指し，序盤の対話から，その話者との終盤の対話を予測するための埋め込みモデルを構築する．具体的には，対照学習を利用し，話し方に基づいて序盤と終盤とを紐づける埋め込みモデルを学習する．さらに，最近傍探索ライブラリである Faiss を用いて序盤の対話から，類似した話し方を持つユーザの終盤の対話を獲得する仕組みを構築する．本手法の評価では，旅行代理店タスク対話コーパス（Tabidachi）および RealPersonaChat（RPC）コーパスを使用し，提案モデルが序盤の対話から終盤の対話を予測するための埋め込み表現の獲得に有効であることを確認した．
Q10-24,キーフレーズ抽出は情報検索や要約に活用できる技術である．本稿の目的は埋め込みモデルを用いた教師なしキーフレーズ抽出における長文に対する抽出精度の改善である．埋め込みモデルベースの手法では，文章全体とフレーズとの類似度を直接算出するため，長文においてテキスト長の大きな差が原因で精度が低下しやすい．提案手法では文単位の埋め込みを用いて重要な文を絞り込むことで，既存手法に比べ長文へのキーフレーズ抽出精度が改善した．開発したキーフレーズ抽出ツールおよび日本語の評価データセットは https://github.com/flatton/keyphrase extraction tools にて公開予定である．
Q6-13,"近年の自然言語処理の成功を受け、神経科学の分野でも自然言語処理との融合的アプローチが急速に発展している。このアプローチにおいては、言語モデルの評価に応用可能な「自然な刺激文に基づく脳活動データセット」が必要不可欠であるが、2025年現在、日本語を対象としたものは存在していない。本研究では、日本語を対象とした新たな脳磁図(Magnetoencephalography, MEG)データセットであるBCCWJ-MEG を構築する。BCCWJ-MEG は、41 名の日本語母語話者が、新聞記事 20 件（229 文・1642 文節）を読んでいる際の MEG データを含む。さらに、我々は、ケーススタディとして、アーキテクチャの異なる複数の言語モデルを BCCWJ-MEG を用いて評価し、(i)自己注意あり言語モデルが自己注意なし言語モデルよりも脳活動をよりよく説明すること、および(ii)脳活動をよりよく説明するモデルが工学的性能が高いとは限らないということを確かめた。"
P9-3,"As the digital news consumption continues to grow,sentiment analysis has become essential for understand-ing public opinion and the impact of media. TraditionalNLP methods often fail to capture the in-depth emotions innews content, especially when taken from various mediasources. This work identiﬁes gaps in the use of ﬁne-tuneddeep learning models and large language models (LLMs)without ﬁne-tuning in the sentiment analysis of news arti-cles, oﬀering enhanced insights across various model fam-ilies. In our work, we collect news from BBC, and annotateBBC dataset using the proprietary OpenAI GPT-3.5-turbomodel, and ﬁne-tune models such as DistilBERT, BERT,and RoBERTa-large. We also compare ﬁne-tuned modelswith LLM variants including Llama-3 and Qwen-2 modelswithout any model ﬁne-tuning through crafted prompts.Our results show that RoBERTa-large achieved the highestperformance, delivering an accuracy of 86%."
P10-24,近年，カウンセリングに特化した Large LanguageModel(LLM)の開発が盛んに行われ，様々な観点からの評価が必要となっている．我々は，相手の話を理解していることを示す能力である Active ListeningSkill(ALS)に着目する．カウンセラーの ALS は患者の自己開示を促すなど，カウンセリングにとって重要である．本研究では，カウンセリング対話でﬁne-tuning した LLM を基にカウンセリングチャットボットを作成し，ALS に関連するいくつかの評価項目によって当該ボットを評価した．評価の結果，一般的な LLM と比べて，我々が作成したモデルは言い換えや要約による ALS によって，自己開示をユーザに促すことができることを示した．
E2-1,所属集団との結びつきについての感覚を表す集団的アイデンティティは，人々の認知や行動に影響を与えることが知られている．近年，オンラインコミュニティの集団的アイデンティティを推定する重要性が高まっている．既存の辞書を使った指標では，辞書メンテナンスのコストや，低頻度語が考慮できないなどの課題がある．そのため本稿では，語のイノベーティブな使用（Linguistic Innovation）の頻度が，集団的アイデンティティの指標になるという仮説を検証する．データは YouTube 上の動画へのコメントを用いた．結果は，対象とした 4 カテゴリのうち 3 つのみで仮説を支持し，指標としての機能にはコミュニティの性質による条件が示唆された．
A7-1,"In this study, we investigate whether large language mod-els (LLMs) trained with substantial Japanese data exhibithigher probabilities for Japanese in their intermediate lay-ers when projected onto the vocabulary space (a.k.a la-tent languages). Focusing on Llama2 (English-centric),Swallow (continued in Japanese), and LLM-jp (balancedEnglish-Japanese), we ﬁnd Llama2 relies mainly on En-glish, while Swallow and LLM-jp use both Japanese andEnglish as latent languages. Moreover, input and target lan-guages both inﬂuence the probability distribution betweenlatent languages."
C1-2,大規模言語モデル（LLM）の創造性を評価するために，Japanese Creativity Questions (JCQ)，DivergentAssociation Task (DAT)，そして Story Alteration Task(SAT)という 3 つのベンチマークを構築する. JCQでは，LLM を用いて創造性を包括的に評価する.一方，DAT と SAT では，埋め込みを用いて，創造的能力の一面を測定する.さらに，JCQ と DAT，およびJCQ と SAT の間の相関を分析する. JCQ は網羅的な評価ができるが，比較的時間とコストがかかる.一方，DAT と SAT は網羅性が低いが，迅速に評価できる.
Q6-4,我々は，先行研究において，人間同士が対話しながらキャッチコピーを共同で作成する対話システムの構築を目的としてキャッチコピー共同作成対話コーパスを構築してきた．しかし，作成されたキャッチコピーについて，第三者による評価が行われておらず，共同作業の内容と作成された成果物の質の関係が不明確であった．そこで，本研究ではコーパスに含まれるキャッチコピーに対して第三者評価を付与し，共同作業の内容と作成された成果物の質の関係を明らかにし，それを踏まえ，キャッチコピーを共同で作成する対話システムが持つべき指針について考察する．
P8-13,ベクトル検索において，検索対象のテキスト同士の特徴が異なる状況で同じ埋め込みモデルを用いると，埋め込み空間上で離れた位置に写像されてしまうために正しく検索できなくなる問題がある．本研究ではこの問題に対し，構造面でのテキスト間の相違を事前に緩和することで検索精度を改善できる，という仮説の下，検索対象のテキストに対して事前に指定したフォーマットに基づいた構造化を行う．実験的分析の結果，提案手法を適用しない場合と比べて，検索精度が改善することを確認した．加えて，構造化によってテキストに含まれる特徴量を解釈可能な情報として抽出し，検索に有用な特徴量を特定できるという異なる利点についても分析した．
P1-23,大規模言語モデルの急速な発展は、機械翻訳分野にも影響を及ぼしているが、長く複雑な文の翻訳においては、原文構造の喪失、訳抜けといった課題が依然として存在する。本研究では、大規模言語モデルの特長を活かしつつ、これらの課題に対処するため、原文の修辞構造を利用した分割統治型機械翻訳法を提案する。提案手法では、原語文を修辞構造に則って分割した後、モデルによる翻訳と原文の並列構造を考慮した統治を行って、翻訳文を得る。特許請求項の日英翻訳タスクを通して評価を行った結果、翻訳精度、訳抜け抑制、文構造保持の点で、提案手法が大規模言語モデルでの直接翻訳より優れていることが確認された。
P6-16,"昨今の大規模言語モデルの発達の恩恵により,大量の文章から自動でトリプルを抽出することにより知識グラフを構築する方法が現実的になっている.しかし,これまでの大規模言語モデルによるトリプル抽出の評価は一般ドメインのデータに注目するものが多く,企業内部でのユースケースにおいても同程度の性能が発揮できるかは未知数であった.そこで本稿では,企業内での活用が想定される文献から作成したトリプル抽出タスクの評価用データセットによって, 5 種類の大規模言語モデルの zero-shot トリプル抽出の性能を評価した.結果,抽出性能は F1スコアが最高で約 0.16 であり,LLM によるトリプル自動抽出の企業内活用には精度面に課題があることが確認された.また誤答ケースの分析の結果,性能向上のためには,学習データの構築や知識グラフスキーマ・オントロジーを活用した手法が必要であることが示唆された."
P8-17,"検索クエリの意図をよく反映した埋め込み表現は,検索エンジンの様々なクエリ理解(Query Under-standing, QU)タスクに活用できる.しかし,検索クエリは短く表層形の変化が生じやすいため,既存手法では意図を十分に捉えられない.本研究ではユーザ行動ログから抽出した,検索意図が類似するクエリペアを正例とする対照学習手法を提案する.このペアは表層形の類似性に依らず意図が類似するため,表層形の差異に頑健でクエリに内在する意図を的確に捉える埋め込みモデルを実現できる.提案モデルは複数の QU タスク評価で Ruri や SimCSE などの最先端テキスト埋め込みモデルを大幅に上回った."
P6-12,文献から有機合成手順を自動抽出するために、ルールベースの手法や生成系大規模言語モデル（GLLM）を用いた方法が提案されている。しかし、自動抽出の結果が正しいとは限らないため、再現性や安全性の観点から、専門家による結果の確認と修正作業は必要不可欠である。本稿では、我々が提案した、専門家による確認と修正作業を支援するための枠組みについて紹介する。本枠組みでは、意味役割を用いた有機合成手順のアノテーションを行うことで視覚的に確認作業を支援し、ルールベースとGLLM ベースの 2 種類の性質の異なるシステムの出力を候補として提示することで修正作業を支援する。
C1-6,本研究では，日本経済新聞記事オープンコーパス，日本語話し言葉コーパスを対象とし，読みと意味の対応表作成のための情報付与を行い，データ整備を行う．日本経済新聞記事オープンコーパスには，語義情報が付与されているものの，読み情報が付与されていなかったため，専門家による読みのアノテーションを行った．日本語話し言葉コーパスは，話し言葉の書き起こしであるため，読み情報は正確であったが，語義情報はついていないため，語義曖昧性解消システムを利用して語義データを付与した．以上のデータから，読みと意味の対応表を作成し，関係性について調査する．
A7-5,LM の西洋の人物の内部表象に時系列的な方向が存在することが観察されている．では，和暦という独自の暦法体系を持つ日本の人物の内部表象はどのような構造を持つだろうか．本研究では江戸から平成までの LM 内部での時代表現を別々に取り出し，時代間の方向と位置を比較することで日本の時系列構造を調べた．実験の結果，LM 内部では，日本の時代間の方向はバラバラに表現されるが，時代間の位置は江戸から平成まで単調な順番に配置されることが示された．また，本研究で提案する時系列構造を同一平面で可視化する方法を用いて，日本の時系列構造を簡単な図に示すことができた．
E2-5,本論文では，国立国語研究所でかつて刊行された『方言文法全国地図』[1]の原データを用いて，新しい構想で言語地図を作成した．もとの地図における語形の標識はすべて人手で作成されていたが，本研究では方言の各語形をベクトル化し，そのベクトルのクラスタによって地図のアイコンの色を割り当てた．この際に色の割り当て方についても，カーネル整列法[2]を用いて，色の類似度と語形ベクトルの類似度が最大になるような配色を行った．さらに元の地図の人手による語形分類データと，自動化された語形分類との一致度を調査することで，提案方法の妥当性を検証した．こうした統計的な手法により，非常に困難だとされてきた方言文法の言語地図を非常に見やすく，研究に使いやすい形にすることができた．
Q8-12,"Mixture-of-Experts はそのパラメタ数に対して計算コストが小さく,大規模言語モデルの実用に向けて重要な技術である.しかし,エキスパートを選択するルーティングでは選択が偏り,効率的なパラメタの利用が難しいという問題がある.それに対して,エキスパート選択を均一にする追加損失が使われるが言語モデル性能に干渉することがわかっている.本研究では, TF-IDF を教師信号とした教師あり学習でMixture-of-Experts のルーティングを訓練することを提案する.ケーススタディとして法律へのドメイン特化を扱い,追加損失なしの提案手法は追加損失を使用するベースラインに比肩する結果を得た."
Q1-22,言語モデルを評価するための英語言語理解ベンチマークが，否定理解能力の評価に有効であるかの分析が行われている．一方，日本語においては，ベンチマークをそのような観点から分析する取り組みはない．本研究では，日本語言語理解ベンチマークJGLUE を否定の観点から評価する．JGLUE に含まれる否定について現状と課題を明らかにする．
P10-20,本研究は，思考発話を付与した対話データを用いてファインチューニングを行うことで，個人の発話及び性格特性を再現する手法を提案する．具体的には，LLM を用いて既存の対話データセットに対して対象人物の思考発話を付与する．そして，そのデータを用いてモデルを訓練することで，対象人物の話し方や感情，思考を再現する．著名人・著名キャラクターの再現に焦点を当てた先行研究に比べて，本研究は多様な特性を持つ個人の発話と性格特性を再現できる可能性を示した．
P9-7,"ソーシャルメディアの普及により，個人が意見を発信し，他者の意見を取り入れることが容易になった．本研究では，対象ユーザの投稿文履歴，リポストした投稿文履歴，これら履歴のいいね数やリポスト数から,直後に意見が変化するかの予測を試みた．結果, 80%前後の予測性能を達成し,リポスト投稿文が顕著に予測に貢献すること,要因として投稿文内容からの直接の予測よりもユーザ属性からの間接的な予測が大きいと思われることが分かった."
Q6-17,"The use of promotional language (’hype’) in biomedicalresearch is increasing. Examples include adjectives such asgroundbreaking, unparalleled, novel and innovative. Suchlanguage can undermine objective evaluation of evidence,impede development of research and erode trust in science.In this pilot study, we show that (1) formalizing annotationguidelines may help humans reliably annotate such adjec-tives as ’hype’ or ’not hype’, and (2) that using an annotateddataset following the guidelines to train machine learningmodels yields promising results for automatic detection ofpromotional language."
Q10-20,日常対話を目的とした非タスク指向型対話システムは，ユーザと長期的な信頼関係を構築するために，深く対話を継続する必要がある．システムの実現には，人間同士のコミュニケーションのように共生や共感といった視点が重要であり，ユーザの個々の情報を把握・活用する必要がある．本研究では，ユーザの情報として人間関係に着目する．また，小説の台詞から登場人物の人間関係を抽出できれば，日常対話におけるユーザの人間関係も抽出できるという仮説のもと，日常対話の代替として小説の台詞を活用する．本稿では，台詞に出現する登場人物とその人物に紐づく人間関係語を抽出するモデルを検討する．実験の結果，0.6618 の F 値で人間関係語を抽出できることを確認した．
C3-4,視覚言語モデル（Vision-Language Model; VLM）は与えられた画像と指示文に基づいて文を生成できる能力を持つ。しかし、VLM の出力文を評価する既存手法は、文の総合的な品質を測定することのみに注力しているため、結果の解釈性が乏しいことに加え、必要な評価項目を網羅できていない可能性がある。本研究では、文の評価項目ごとの質を網羅的にスコア付けし、それらのスコアを元に総合スコアを決定する自動評価手法 HarmonicEval を提案する。構築した人手評価データセット MMHE における実験により、HarmonicEval の人手評価との相関は既存手法を上回ることを示す1）。
Q4-2,医療分野は国ごとの制度や慣習の違いが大きく、事前学習済み大規模言語モデルに対してドメイン固有の知識を効率的に習得させる学習戦略が重要となる。本研究では、英日医学翻訳を対象タスクとして設定し、英語の医学用語から適切な日本語の医学用語を想起する能力を、当該タスクにおけるドメイン知識として定義した。これに基づき、医学専門用語の変換精度を定量的に評価するための知識プロービング・ベンチマークを構築した。続いて、Qwen-2.5ファミリーのベースモデルに対して、英日医学対訳コーパスを用いた継続事前学習と教師ありファインチューニングを異なる比率で実施し、ドメイン知識獲得の観点から最適な学習戦略を検証した。
P7-8,大規模言語モデル（LLM）を評価者として用いる“LLM-as-a-judge”は，機械翻訳品質推定（MTQE）をはじめとする，多くの評価タスクで効果を示している．しかし，指示チューニングや強化学習によってアライメントされた LLM では，特定の評価スコアを頻繁に生成する数値バイアスが確認されている．この現象は，アライメントにより出力の多様性が減少するという既存の知見と一致しており，多様性の欠如は評価スコアの偏りを引き起こす可能性がある．その結果，入力の微細な変化に対する評価の頑健性が損なわれる懸念がある．本研究では，LLMのアライメントが数値バイアスおよびタスク性能に与える影響を調査する．
Q4-12,"多言語 LLM や低資源言語 LLM の開発において，言語間での事前学習データの不均衡は大きな技術課題である．現状は，英語中心の事前学習データが圧倒的に多い一方、低資源言語のデータ収集や作成は容易ではない．言語間転移は英語で学習した知識を活用して低資源言語の性能を高めることが期待されるが，その発生条件や原理は未解明な部分が多い．本研究では，指示調整を通じて言語間転移を促進させることを目指し，指示文を二言語の対訳構造にした対訳指示調整(Parallel Instruction Fine-Tuning, PIFT)を提案する．PIFT の効果を日本語からのコード生成タスクで調査した結果，単言語の指示文を用いた指示調整と比較して性能が向上することを確認した．"
E6-1,大規模言語モデル(LLM)の発展に伴い、様々な分野において性能を評価する取り組みが必要となってきている。本研究では、金融分野において LLMの生成の良さ測るための日本語生成ベンチマーク pfmt-bench-ﬁn-ja を提案した。pfmt-bench-ﬁn-ja は、MT-bench に対応するような金融分野に特化した複数ターンの日本語生成ベンチマークであり、12 カテゴリー、360 問のベンチマークを新たに構築した。評価にあたっては、GPT-4o-mini を LLM-as-a-judgeとして用いて、10 段階評価でスコア計測をすることとした。実験として、複数の LLM に対してベンチマークを計測し、その結果を比較検討した。その結果、pfmt-bench-ﬁn-ja が一定レベルで LLM の性能評価を行うことができることが示された。構築したベンチマークは Github より利用可能である。
A3-1,特定の文章が機械学習モデルの学習に漏洩しているかを推論する手法として，メンバーシップ推論攻撃（MIA）がある．大規模言語モデル（LLM）に対する MIA では，文字の並びなどの表層情報を利用するが，LLM はテキストをそのまま記憶しているとは限らない．本稿では，テキストの忘却と質問応答タスクの学習を同時に行うことで，LLM にテキストの文字の並びを忘却させながら，その知識を保持できることを報告する．すなわち，MIA の成功率を低減しながら，関連知識についての質問応答の性能を維持できる．この知見は，たとえテキストが MIAで推論されなくても，その知識を LLM が隠蔽できている可能性があると警鐘を鳴らすものである．
C5-2,拡散モデルは，ランダムノイズに対して「ノイズ除去」を繰り返し行うことで徐々に良いサンプルを出力する，生成モデルの一種である．テキスト生成に応用する際の課題として，生成の過程において，ある回数以降のノイズ除去でサンプルの改善に失敗し，生成結果を崩壊させていく現象がある．本研究は，この現象に関して，これまで注目の薄かった時刻の埋め込みに焦点を当て，その影響を調査した．結果として，時刻の埋め込みがこの「崩壊問題」の一因であることを示し，崩壊を抑制する正則化を提案する．
P3-20,大阪大学では、科学技術分野に関心のある高校生を「SEEDS プログラム」という枠組みの中で 2015 年から受け入れてきた。本プログラムの受講生が提出したレポートの「科学的にダメな点」を調査、分析することにより、中等教育段階の生徒にとって習得が困難なアカデミック・ライティングに求められる項目を明らかにした。その結果、SEEDS プログラム受講生のレポートの「ダメな点」は、「定量性に欠ける表現」「思い込みなどが原因の客観性に欠ける表現」「書き手の価値観が入っている表現」など、大きく分けて 6 種類に特徴を分類できることが判明した。今後は、これらの項目の習得を意識した、中等教育段階の生徒向けのライティング教材の開発が期待される。
Q1-24,本研究では，テキスト平易化のための日本語パラレルコーパスを構築し，公開した．本タスクにおける既存の日本語コーパスとしては，非専門家によって構築されたものが訓練に使用されており，専門家によって構築された高品質かつ大規模なものは存在しない．我々は，専門家により平易化された記事に対して人手で文アライメントを行うことで，大規模な文単位のパラレルコーパスを構築した．人手評価の結果，専門家によって平易化されたパラレルコーパスは，非専門家が平易化したものに比べて多様な平易化操作を含んでいることが明らかになった．また，我々の構築したパラレルコーパスは，流暢かつ意味を保持した平易化が行われていることを確認した．
P6-24,固有表現抽出は，自然言語処理において基本的で重要なタスクである．しかし，大量の教師データを必要とする従来の固有表現抽出は，ユーザーに応じた多様な粒度のカテゴリを抽出するという実社会の需要に柔軟に対応できていない．既知語が出現する文脈を擬似教師データとして利用する弱教師あり固有表現抽出は，大規模なシソーラスと組み合わせることでこの多様なカテゴリの需要に対応できる．弱教師あり固有表現抽出の先行研究は，擬似教師データの誤りに頑健な学習法を提案してきたが，これらの学習法の結果作られたモデルには，関心のあるカテゴリと無関心なカテゴリの境界を超えて予測してしまうという副作用があった．この副作用に対し本研究では，ユーザーの関心のあるカテゴリを含むシソーラスの全カテゴリを擬似教師データ作成に活用する手法を提案し，実験を通じてシソーラスに含まれる総体的な知識の有用性を明らかにした．
B5-6,本研究は，高知県を対象に ChatGPT を活用した観光支援システムを構築し，観光資源の効果的な発信を目指した．土佐弁を活用した対話インターフェースやユーザー条件に基づく観光案内，地域特化型データを活用したリアルタイム情報提供を試みた．その結果，観光案内の有用性が示される一方，情報の正確性や視覚的要素，音声対話機能の課題が明らかになった．本研究は，AI 技術による観光業の可能性と地域振興の新たな方向性を提案するものである．
Q2-4,近年，大規模言語モデル(LLM)による応答の自動評価を LLM により行う手法，LLM-as-a-Judge が広く使用されている．日本語でも複数の LLM-as-a-Judgeベンチマークが開発されている．本論文では，LLMの多面的な分析を容易にするため LLM-as-a-Judge 評価を統一的に扱うことができるツール“llm-jp-judge”を提案する．現時点では，独自のプロンプトを用いた生成品質評価，MT-Bench によるマルチターン対話評価，応答の安全性評価に対応している．また，提案ツールによる評価の妥当性を検証するためのメタ評価を行い，評価結果の信頼性や有用性について議論する．本ツールはオープンソース1）として公開しており，誰でも利用可能である2）．
P3-22,既存のタイピングゲームは、固定的な文章や単純なレベル分けが中心であり、学習者が慣れていくことにより、学習者のモチベーション維持やスキル向上に限界がある。個人の嗜好に合わせてタイピング文章を毎回自動生成することができれば、学習者のモチベーション維持や向上に繋がることが期待される。本研究では、AI が自動生成した日本語文章を活用したタイピングゲームを開発した。評価実験によって、開発したタイピングゲームにはモチベーション向上効果があることが示唆された。その一方で、セリフ自動生成の精度が低いネガティブな性格語に対して、プロンプトの改良や別の大規模言語モデルの利用を検討する必要があることも明らかになった。
P9-15,テキストと付随する絵文字の表す感情は一致することが普通であるが、そうでないものも存在する。テキストと絵文字の感情の組み合わせには様々な類型があり、それらがどのような感情の機微を示しているのかを自動的に読み取るのは現状困難である。本論文は、絵文字付きテキストのテキストと絵文字の感情を同一平面上で可視化するマッピングを行うことで、その分布からレトリカル絵文字を定量的に検出し、それらの持つ感情の機微の分析を行った。この結果を用いることにより、絵文字付きテキストの感情分析をより詳細に行えるようになることが期待できる。
Q8-25,"Multi-label text classification, which assigns multiple labels to a single text, is a key task in natural language processing. In this task, a model is often trained on an imbalanced dataset whose label frequencies follow a long-tail distribution. Low-frequency labels that rarely appear in training data have an extremely small number of positive samples, so most of the input samples are negative. Therefore, the model learns low-frequency labels with the loss value dominated by the negative samples. In this research, we propose a method called weighted asymmetric loss that combines the appearance frequency weight of labels, the weight that suppresses the loss value derived from negative samples, and a label smoothing method in accordance with the co-occurrences of each label. Experimental results demonstrate that the proposed method improves the accuracy compared to existing methods, especially on imbalanced datasets."
E2-2,数千件を超えるような、大規模な先行文献すべてを対象にレビューすることは困難を伴う。このようなとき、タイトルや抄録に対するトピックモデルの適用が有効である。今日では、従来の古典的なトピックモデルである潜在ディリクレ配分法 (LDA) 等ではなく、論文情報に紐づいたメタ情報をモデリング過程で有効活用できる構造トピックモデル (STM) の有用性が示唆されつつあるが、心理学を含む人文学における文献レビューでは STM はほとんど用いられていない。こうした研究動向を踏まえ、本研究では、「自分への思いやり」をさすセルフ・コンパッションという心理学的概念を題材とし、STM を用いたレビューを行った。結果、解釈可能な 38 のトピックが、トピック割合の時間的推移と共に抽出され、先行研究における主要なテーマを得ることができた。
Q7-23,質問応答は，自然言語処理における重要な研究テーマの一つである．近年の深層学習技術の発達と言語資源の充実により，質問応答技術は飛躍的な発展を遂げている．しかし，これらの研究は英語を対象としたものがほとんどであり，現状，日本語での質問応答に関する研究はあまり活発には行われていない．この背景を受けて，我々は日本語での質問応答研究を促進するため，日本語のクイズを題材とした質問応答のコンペティション「AI 王」を企画し，これまでに計 3 回実施してきた．本論文では，日本語の質問応答技術における現在の到達点と課題を明らかにすることを目標として，使用したクイズ問題と提出された質問応答システム，さらに比較対象として大規模言語モデルを用いた分析を行い，その結果を報告する．
Q9-24,研究者や実務者にとって事前学習済みモデルの利活用が一般的になる中，実運用上の大きな課題として時系列性能劣化の監査が挙げられる．特に事前学習済み言語モデルは事前学習や推論にかかる時間と費用が大きいため，効率的な監査と再学習の仕組みの検討は重要である．本研究では学習コーパス内の単語の通時的な意味変化を計算することで，事前学習済み言語モデルや単語分散表現の時系列性能劣化を監査する枠組みを提案し，モデルの再学習に関する意思決定を支援する．最初に 2011～2021 年の日本語・英語のニュース記事を用いて，学習コーパスの期間が異なる RoBERTa や word2vec のモデルを構築し，時系列性能劣化を観測した．実験では，学習コーパス内の単語の通時的な意味変化から計算できる指標「Semantic Shift Stability」が小さくなる際，事前学習済みモデルの性能が時系列で大きく劣化しており，監査の用途での有用性を確認できた．提案する枠組みには意味が大きく変化した単語から原因を推察できる利点もあり，2016 年の米大統領選や 2020 年の新型コロナウイルス感染症の影響が示唆された．指標を計算するソースコードはhttps://github.com/Nikkei/semantic-shift-stability で公開した．
Q5-25,"Pre-trained sequence-to-sequence (seq2seq) models have achieved state-of-the-art results in the grammatical error correction tasks. However, these models are plagued by prediction bias owing to their unidirectional decoding. Thus, this study proposed a bidirectional transformer reranker (BTR) that re-estimates the probability of each candidate sentence generated by the pre-trained seq2seq model. The BTR preserves the seq2seq-style transformer architecture but utilizes a BERT-style self-attention mechanism in the decoder to compute the probability of each target token using masked language modeling to capture bidirectional representations from the target context. To guide the reranking process, the BTR adopted negative sampling in the objective function to minimize the unlikelihood. During inference, the BTR yielded the final results after comparing the reranked top-1 results with the original ones using an acceptance threshold λ. Experimental results showed that, when reranking candidates from a pre-trained seq2seq model, the T5-base, the BTR on top of T5-base yielded scores of 65.47 and 71.27 F0.5 on the CoNLL-14 and building educational applications 2019 (BEA) test sets, respectively, and yielded 59.52 GLEU score on the JFLEG corpus, with improvements of 0.36, 0.76, and 0.48 points compared with the original T5-base. Furthermore, when reranking candidates from T5-large, the BTR on top of T5-base improved the original T5-large by 0.26 on the BEA test set."
Q5-24,本稿では，日本語ニュース記事の要約支援を目的とする，ドメイン特化事前学習済みモデルを用いた編集支援システムについて報告する．具体的には実社会のシステム要件を整理し，既存技術を組み合わせて開発した編集支援システムを，有用性を評価するための検証項目と共に提示する．第一に，特有の文体を再現する目的で「日経電子版」のニュース記事を用いて T5 の事前学習とファインチューニングを行い，学習コーパスのサイズが小さいにもかかわらず，見出しと 3 行要約の生成タスクで一般的なモデルを上回る性能を確認した．次に，発生し得る幻覚の特徴を明らかにするために，構築したドメイン特化 T5 の出力を定量的・定性的に分析した．最後に，クリック率を予測するドメイン特化 BERT も含め，編集システム全体の有用性を議論した．
P4-17,"人間中心主義的に展開されてきた言語の哲学は、ChatGPT（OpenAI）、Claude（Anthropic）といった人間に比肩する言語的能力を持つとされる大規模言語モデル（Large Language Models, LLMs）の出現によって、脱人間中心主義化を迫られている。従来はその基礎的意味論として分布意味論があてがわれてきた LLM であるが、現在では、LLM の基礎的意味論として分布意味論以外の基礎的意味論を探る研究が続けられている。本発表は、言語の表象性という観点から、言語モデルに最適な基礎的意味論としてロバート・ブランダムの推論的意味論を提案し、推論的意味論の反表象主義性や論理的表出主義性が、LLM の性質や振る舞いを解釈する上で有用であることを示す。"
A1-3,大規模言語モデル(LLM)の普及に伴い，安全性の高い LLM への要望が高まっている．本稿では LLMの安全性の 1 要素である LLM が有害コンテンツを出力しないことに着目し，有害コンテンツを軽量かつ効果的に回避する手法を提案する．提案手法ではトークン列生成を行う生成 LLM と，トークン列の有害性を評価する評価 LLM を用いて，適宜トークン列の有害性を評価しつつ推論を行うことで，有害コンテンツを含まないトークン列の生成を目指す．
Q7-24,"This paper describes the development of a large-scale English-Japanese simultaneous interpretation corpus named NAIST-SIC and presents analyses of it. We collected the recordings of simultaneous interpreting sentences (SIsent). To understand the characteristics of simultaneous interpreting by human simultaneous interpreters (SIers), we analyzed a subset of this corpus. Samples of speech were interpreted by three SIers having different levels of experience and can be used to compare SIsent attributes in terms of the SIers’ experience. Using this corpus subset, we analyzed the differences in latency, quality, and word order. The results show that (1) SIers with more experience tended to generate a higher quality of SIsent, and (2) they better controlled the latency and quality. We also observed that (3) a large latency degraded the SIsent quality."
Q1-23,デジタルプラットフォーム上の誹謗中傷に対する社会的関心が高まっており，その性質の理解と対策に向けたデータセットや自動検出の研究が進められている．既存のデータセットでは，誹謗中傷の主観的な性質とクラウドソーシングなど非専門家によるアノテーションを実現するために，タスクを単純化や主観的な判断に依存することで，実際問題との乖離や社会・文化的文脈の考慮不足といった課題があり，社会科学の専門知識を活用しながら，誹謗中傷問題を個々の社会に合わせて調整するアプローチが必要である．そこで本論文では，日本の裁判例を基に誹謗中傷検出に向けた日本語データセットを提案する．我々のデータセットは，オンライン上の発言に対して，名誉権や名誉感情といった法的権利と，その権利に対する裁判所の判断を誹謗中傷のラベルとして利用している．さらに，自動検出手法の検証によって，実際上の問題とのギャップを明らかにし，課題点に対する検討を行っている．この研究は，誹謗中傷の問題に実際の社会問題に即したデータセットの構築により，配慮されたコンテンツモデレーションの実践を目指すとともに，他のドメインからの専門知識の活用に関する議論の基盤を提供することを目指している．
P6-25,事前学習済み言語モデル (Pre-trained Language Models; PLM) は事前学習時に獲得した言語理解能力や知識によって，既知の事象に対して推論を行うことができる一方，未知の事象に対しては PLM の推論能力のみで解を導き出す必要がある．しかし言語モデルの推論能力のみを評価するには，PLM が事前学習時に記憶した知識と獲得した推論能力を完全に切り分けた分析が必要となり，既存のデータセットで測定するのは，事前学習時の記憶が作用してしまうため困難である．本研究では PLM の推論能力の分析に，知識グラフ上の既知の関係から欠損している未知の関係を予測するタスクである知識グラフ補完 (Knowledge Graph Completion; KGC) を対象とする．KGC において埋め込みに基づく従来手法は推論のみから欠損箇所を予測する一方，近年利用されているPLM を用いた手法では事前学習時に記憶したエンティティに関する知識も利用している．そのため KGC は記憶した知識の利用と推論による解決との両側面を有することから，PLM が記憶する知識の影響を測るのに適したタスクである．我々は KGC に対し知識と推論による性能向上を切り分けて測定するための評価方法及びそのためのデータ構築手法を提案する．本研究では PLM が事前学習時にエンティティに関する知識の記憶により推論を行っている箇所を明らかにし，PLM に備わっている未知の事象に対する推論能力も同時に学習していることを示唆する結果が得られた．
Q9-23,"This study clarifies how the domain adaptation of bidirectional encoder representations from transformers (BERT) contributes to the syntactic analysis of mathematical texts and their limitations. Experimental results show that the domain adaptation of BERT is highly effective, even with a relatively small amount of raw in-domain data. This improves the accuracy of the syntactic dependency analysis by up to four points without any annotated in-domain data. By analyzing the improvement, we found that numerous errors involving the mathematical expressions have been corrected. Errors related to structures that are not frequent in the out-domain fine-tuning data were difficult to improve by only the domain adaptation of BERT. This study also revealed that the effectiveness of BERT depends on the representation of the mathematical expressions in the input. Among several different representations of mathematical expressions, the highest dependency accuracy was achieved using a simple method where an entire mathematical expression is replaced with a dedicated special token."
E4-3,本研究では，明治期に編纂された百科史料事典である「古事類苑」を知識グラフ化した．さらに，記載された事物やことがら，引用・参照される史料との関係性を元に，古事類苑の言語リソース，およびその基盤として活用方法を提案する．古事類苑は，類書の構造をもとに編纂されており，日本の和歌集や物語といった史料群を体系的に知ることのできる書物を目指して作成された．そこで，古事類苑を知識グラフ化し，さまざまな引用書と語の関係や，現代語との接続を行うことで，明治期に設定された語の分類，および古代から江戸時代までの書物との関連性を扱うことで，言語リソースとして古事類苑を利用可能とする．
C7-1,"本研究は,音声認識出力を可読性の高い形式へと変換する「整文」手法を提案する.日本速記協会の「発言記録作成標準」を参考に,語断片の除去や文法,流暢性の向上,簡潔化までの 4 つのステップを定義した.これにより大規模言語モデル（LLM）を用いた整文処理が可能となり,発言に忠実な書き起こしから,要点のみをコンパクトにまとめた要約形式まで,多様な用途に合わせた出力結果が得られる.これにより,音声認識出力の利活用の可能性を広げることを目指す."
A1-2,"This study proposes a novel framework for evaluatingLarge Language Models (LLMs) by uncovering their ideo-logical biases through a quantitative analysis of 436 binary-choice questions. Applying the framework to ChatGPT andGemini, we found that while both models show consistentopinions, their ideologies diﬀer between models and lan-guages. Both models also exhibited problematic biases,with some responses potentially having negative societalimpacts. These ﬁndings highlight the need to address ide-ological and ethical considerations in LLM evaluation, andthe proposed framework oﬀers a ﬂexible method for assess-ing LLM behavior and developing more socially alignedAI systems."
E4-2,文章構造は，読者の注意喚起や興味喚起，理解・記憶の効率など，文章を評価する要素に大きな影響を与えるにもかかわらず，文章構造と評価との関係は明らかでない．本稿では，小説，Wikipedia 記事，学術論文，映画字幕といった多様な媒体を対象に，文章構造と評価の関係を定量的に分析した．具体的には，意味依存度の低い特徴量を抽出し，文章中の構造を捉え，評価に与える影響を検証した．その結果，評価が高い文章には特定の構造が顕著に見られることが明らかとなり，情報提示の順序や関係性が読者の評価に与える影響が確認された．これにより，効果的な文章作成や情報提示の設計において，媒体ごとの構造や転換タイミングを考慮する重要性を示すことができた．
P4-16,SNS 投稿には他の投稿や外部サイトの情報に対して言及するものがあるが，言及先の情報が必ずしも投稿内に忠実に記述されるとは限らない．このような情報の変容は偽・誤情報の蔓延に繋がるため，投稿に含まれる事実表現が言及先に忠実であることを自動的に確認する手法の開発が大きな課題となっている．本研究では，SNS 上の情報伝播時における事実表現の累積的な改変の解明に向けて，フレーム意味論に基づいた自動要約システムのアノテーション枠組みを応用し，SNS 投稿内に含まれる事実表現に関する誤りの種類の分類を行う．データセットとしてニュース記事に言及する日本語 X 投稿を人手でアノテーションし，分析を行う．結果として，全体の約 1/3 に事実忠実度の観点での誤りが認められた．
P3-23,将棋などの完全情報ゲームのプログラムは任意の盤面から最善と考えられる指し手とその評価値（形勢判断）を正確に提示できるが、その理由まで説明することは難しく解釈性が課題となっている。本研究では解説文に出現する手順を予測する部分ゲーム木（解説木）をゲームエンジンを用いて生成する手法を提案する。Policy-Value Network を用いた Monte-Carlo 木探索(PV-MCTS)によって得られたゲーム木を再帰的に枝刈りして解説木を生成する。この手法により、解説文のコーパスに依存しない解説木の予測が可能となる。また、PV-MCTS を制御する PUCT アルゴリズムを調整することによる予測精度の変化についても調査した。
Q2-5,本稿では，大規模言語モデル（Large LanguageModel，LLM）の生成テキストを人の倫理観や価値観に沿うものにするアライメントに取り組む．本稿のアプローチでは，アライメントの対象となる LLM内部のパラメータを更新するのではなく，テキスト生成過程におけるトークンの確率分布に介入する．トークンの確率分布への介入は外付けの“制御フィルタ”によって行われる．この手法では，アライメントが外部の機構によって行われるが故に，高い柔軟性と透明性を提供するものである．実験では，Llama 3 8b に対するアライメントを行い，提案手法の有効性を示している．
C5-3,企業における大規模言語モデルの活用が進む中、社内固有の知識を大規模言語モデルと結び付けるRetrieval Augmented Generation（RAG）は重要な技術である。多くの企業で RAG の改善が試みられているが、製造業で RAG を活用する場合、使用されるドキュメント群の特殊性から、一般的なデータセットで検証された RAG 改善手法が常に効果を発揮するとは限らない。本研究では、RAG の性能を改善するとされる要素（①テキストの正規化、②ハイブリッド検索、③リランキング、④検索ワードの拡張）について、製造業の設計現場で扱われるドキュメント群に対して、どの要素が効果的であるかを調査した。その結果、テキスト正規化、ハイブリッド検索、リランキングが検索性能向上に寄与した一方、検索ワードの拡張は検索性能向上に寄与しなかった。
Q4-13,代数統計は代数幾何と統計の融合領域であり，構造を備えた確率モデルを高次元空間における多様体として捉える新たな視点を提供する．本研究では，言語の確率モデルを文を構成する単語の同時確率分布として定式化し，その確率ベクトルが言語の構造を反映した多様体をなすことを示す．これにより，代数幾何のツールである多項式イデアルを用いて，単語の同時確率を制約する多様体構造から言語の構造を抽出するための新たな手法を検討する．
B8-6,スケッチ画像を理解してベクター形式のダイアグラムを生成するためのベンチマークデータセット SkeTikZ を提案する1）．SkeTikZ は，人手で作成したスケッチ画像と TikZ 形式のダイアグラムがペアになった初めてのデータセットである．さらに，画像を理解して TikZ 形式のダイアグラムを生成可能なマルチモーダルモデル ImgTikZ を提案する．ImgTikZ は，コード生成に特化した大規模言語モデルと画像エンコーダを活用したモデルであり，実験によって 7B 規模のモデルサイズながら GPT-4o に匹敵するダイアグラム生成能力を有することを確認した．また，スケッチ作成のツールによって画像認識の難易度が大きく変わることを確認した．
P7-9,計算機によるユーモアの研究は，対話システムなどの自然言語処理ツールの高度化に不可欠とされている一方で，大規模言語モデル(Large LanguageModel; LLM)のユーモア生成や評価に関してはまだ十分に検討されていない．本研究では，図 1 のように大喜利を題材として新たに高品質な日本語の大喜利データセットを構築し，LLM の大喜利生成能力と大喜利評価能力を検証した．
Q4-3,近年，英語や多言語の汎用的なテキスト埋め込みモデルの開発が盛んに行われている．しかし，日本語でのモデル開発の取り組みは限定的であり，その理由としてはデータセットの不足やモデル開発のための知見が少ないことが挙げられる．本稿では，日本語汎用テキスト埋め込みモデル Ruri を開発し，その過程について述べる．具体的には，訓練データの不足を補うための大規模言語モデルによる合成データセット構築，対照事前学習によるベースモデルの訓練，そして高品質データを用いた微調整について説明する．構築したテキスト埋め込みモデル Ruriは，日本語テキスト埋め込みのベンチマークにおいて既存のモデルを上回る性能を達成した．
A5-6,言語モデルの大規模化が進むにつれ，再学習無しで知識更新が可能な知識編集の需要が高まっている．しかし知識編集は事前学習で獲得したトークン予測確率を事後学習で変化させるため，トークン予測確率と実際の精度が乖離する可能性がある．本研究ではこの問題が実際に起きているか検証するために，知識編集前後でのトークン予測確率と実際の精度の一致度を conﬁdence calibration の観点から計算し比較した．その結果，知識編集によりモデルのconﬁdence calibration が変化すること，特に意味理解が必要なタスクでは精度と比べトークン予測確率を相対的に低下させる傾向があることが分かった．
C3-5,本研究では、マルチモーダル大規模言語モデル(MLLM)がジェスチャーの意味をどの程度理解できているのか調査する。特に、MLLM は外界への参照性・依存性が高い「指標的ジェスチャー」の理解を、イメージを描写する「図像的ジェスチャー」や常識によって定められる「象徴的ジェスチャー」の理解よりも苦手とするのではないかという仮説を検証する。未来館 SC コーパスの 925 件のジェスチャーに対して人手でタイプラベルを付与し、GPT-4o を含む MLLM によるジェスチャー説明文の生成と評価を行った。その結果、MLLM は一貫して指標的ジェスチャーの理解に困難があることを明らかにした。
Q10-21,新聞社では，分析の目的や対象文書のドメインに応じた固有表現抽出（NER）が求められる．従来どおり，特定のドメインごとに NER モデルをファインチューニングするには，教師データの作成などに高いコストがかかる．一方，大規模言語モデル（LLM）を用いた Few-shot 推論なども検討できるが，精度は十分とはいえない．そこで本研究では，LLMに対する NER プロンプトのフォーマットと，NERタスクそのものの形式を学習させるファインチューニング手法を提案する．このモデルで Few-shot 推論を行い，少量のデータのみで特定のドメイン・ラベルへ適用させた NER を行う．
Q6-16,本研究では論文の内容を根拠としてレビューを生成可能なモデルを構築することを目指す．この目的を達成する一つの方法として，学習データのレビューが論文のどの部分に基づいているかという情報を活用することが考えられるが，こうした情報を含むデータセットを人手で作成することはコストがかかる．そこで本論文では，レビューと論文の結びつきや論文の内容を正確に反映したレビュー文をLLM を用いて自動でアノテーションすることを検討した．評価結果より，現在の LLM はレビューと論文の結びつきをある程度の精度で予測することができ，論文の内容を正確に反映したレビュー文を高い精度で選択できることがわかった．
P10-21,ユーザが対話破綻に対して破綻と判断する度合い（以降，破綻度合いと呼ぶ）には個人差があることが報告されている．そのため，対話を円滑に進めるために必要な対話修復の戦略を考える際，破綻に対して修復すべきかどうか，あるいはどのように修復すべきかといった判断をするときに，破綻度合いの個人差は無視できない．そこで本研究では，そのような個人差が生じる要因が性格や年代，性別などの個人特性と関係していると考え，個人特性を考慮した破綻度合いの推定手法を提案する．加えて，破綻度合いはこれまでの対話履歴にも依存するため，対話履歴と個人特性に関する情報を併用して破綻度合いを推定する．システムの発話に対する破綻度合いとユーザの個人特性のデータを収集し，個人特性が破綻度合いに与える影響について調査を行った結果，勤勉性や神経症傾向などの 7 種類の個人特性によって破綻度合いに差が生じることが明らかとなった．また分析の結果に基づき破綻度合い推定器を構築した結果，8 割以上の精度（accuracy）を得ることができ，対話修復への活用が期待できる．
P9-6,本論文では，LLM を利用した Zero Shot の評判分析における性能調査について報告する．実験では，評判分析のデータとして Webis-CLS-10 データセットを使用し，LLM として GPT-3.5-turbo，GPT-4o，Llama 3.1-Swallow-8B を用いた．結果として，極性判定では，LLM を利用した場合，Zero Shot でも高い精度が得られることが確認された．一方で，livedoor記事のカテゴリ分類を行う場合には，Zero Shot の精度が低いという結果となった．また，Zero Shot で日本語の Amazon レビューの評判分析を実施する際，LLM にその判定根拠を提示させると精度が低下することが確認された．
Q8-13,大規模言語モデル(LLM)は急速な発展により、幅広い知識を保有し、多種多様な応答が可能になっている。LLM の知識や言語能力の評価には GLUEや MMLU などのデータセットが存在し、JGLUE などの日本語データセットも構築されている。LLMの生成評価の観点は、これら以外に、人間の指示に対して追従しているかという点がある。しかし、指示追従性を評価する為の日本語データセットは存在するものの、カバーする範囲が狭い。本研究では、日本語の包括的な指示追従性データセットを構築する。さらに、構築したデータセットを評価ベンチマークとして、既存の LLM の指示追従性を評価する実験を行う。構築したデータセットはichikara-instruction2 データに含まれる形で提供予定である。
Q6-1,日常生活における行動の理解は，社会学，経済学や疫学などで重要な課題である．ソーシャルメディアの普及に伴い，人々の日々の行動に関わるテキストデータが蓄積されるようになり，行動分析のための材料として注目されている．本研究では，総務省統計局の社会生活基本調査で用いられている 20 種類の行動を基に日常生活における行動を定義した．これらの行動を「LIFE STORY」データセットにアノテーションし，公開可能なコーパスを構築した．このコーパスを用いて分類モデルを構築し，分類性能を評価した．さらに，構築したモデルを用いてCovid-19 前後のエピソードから抽出した行動を定量的に分析し，コーパスの有用性を検証した．
A7-4,In-context Learning (ICL)は，言語モデルにおける新たな少数ショット学習パラダイムとして注目されているが，その内在的メカニズムは十分に解明されていない.本研究では，ICL の推論ダイナミクスを3 つの基本操作に分解し，それらを基盤として推論回路を構築した上で精密な測定を行い，従来の研究で観察されてきた現象を統一的に説明することを試みた.さらに，提案した回路を無効化するアブレーション分析の結果，ICL の性能が顕著に低下することが確認され，提案した推論回路がICLの主要なメカニズムであることが示唆された1）.
E2-4,本研究は，サンスクリット辞書の意味記述を横断的に探索する新たなアプローチを提示する．Cologne Digital Sanskrit Dictionaries が公開する 21 種類のサンスクリット辞書を用い，大規模言語モデルに追加学習を行うことで，個々の辞書の限界を超えた柔軟な意味解釈を可能にするモデルを構築した．提案モデルは，既存辞書の記述を統合しつつ，辞書に記載されていない単語についても意味記述を生成する能力を示した．また，妥当性がありながら，いずれの辞書でもなされていない意味記述を生成することも可能であることを示した．
P6-13,"近年,顧客とのエンゲージメントを生む施策としてコミュニティの重要性や価値が増しており,コミューン株式会社が提供する“Commune”のようにクライアントごとに個別のコミュニティを提供するサービスが注目されている.このようなコミュニティ提供は顧客体験の向上に寄与する一方で,例としてハッシュタグ推薦タスクにおいては,各コミュニティが異なるハッシュタグ空間を持つため新たな課題をもたらす.本研究では,単一のモデルで複数のコミュニティに対するハッシュタグ推薦を可能にするべくマルチラベル分類モデルを用いた二段階推薦を提案する.提案手法は実験の結果, NDCG@10 で0.52 を達成し、推論速度の観点からも実運用に適した有効性を確認した."
P8-16,本研究は，芸能人のファンが，芸能人に関連する事柄についての情報探索を行いやすくすることを目的とする．X から特定の芸能人に関するポストを収集し，大規模言語モデル(LLM)である ChatGPT を活用して，芸能人の評価対象とそれに関連する感想のペアを抽出する．これらをキーワードとして使用し，上位 30 件のウェブページから感想の背景にある理由を探る．この理由の収集・集約では，ChatGPTに検索拡張生成(RAG)の枠組みを適用し，収集したウェブページの内容を参照情報として活用する．人手で作成した評価対象と感想のペア，および理由のデータを参照として評価を行った結果，提案手法が高い精度を達成することが明らかになった．
P8-14,本研究では，日本語検索拡張生成（RAG）システムの性能評価と改善を目的とした企業法務向け評価データセットを構築する．構築した評価データセットを用いて既存モデルの性能検証とエラー分析を行う．一般ドメインの評価データセットでの性能評価結果と異なることを示し，特定のドメインに特化した評価データセットを作成することの重要性を明らかにする．さらに，より信頼性の高い評価データセットの確立のため，評価データの収集方法の違いがモデルの性能評価結果に与える影響について追加検証を実施する．
P1-24,"Using the Universal Dependency Database (UDD), theword order of subject (S), object (O), oblique (X), and verb (V) is  investigated. The  order  of  three  dependent elements (S, O, X) and head verb  are examined in the database and the frequency of each word order patterns are counted. Although previous studies investigated the order of S, O, and V or O, X, and V, no studies have investigated the order of S, O, X, and V to the author's knowledge. The  study  results  show  the  following:(1) Frequent  word  orders  are  SVOX, SXOV, SOVX, and SOXV.(2) Frequent verb positions are 2nd, 4th, 3rd, and 1st.(3) In the case of verb position is 2nd, 3rd, or 4th, the most frequent element of the 1st position is S.(4) In the case  of  verb  position  is  2nd  or 3rd, the  most  frequent element of 4th position is X.(5) In the order of S, O, and X ignoring verb position, SOX, SXO, and XSO are most frequent.(6) O is often adjacent to V."
P1-18,"Sign language translation (SLT) has traditionally de-pended on gloss annotations, which are costly and time-consuming to produce. This work presents a gloss-free SLTframework that integrates raw RGB video input with facialkeypoint features, enabling richer visual representations.We leverage a two-stage approach:ﬁrst aligning visualand textual features with a frozen multilingual mBARTencoder, then reﬁning translation through the mBART de-coder. Evaluations on the PHOENIX-2014T dataset showperformance gains over baselines, yielding a +0.64 BLEUimprovement. These results conﬁrm that incorporating fa-cial keypoints strategy can signiﬁcantly improve gloss-freesign language translation."
P6-11,本研究では，複数のデータセットにおけるラベル付けの違いを効果的にモデル化し，複数データセットで学習を行うために，条件付き変分オートエンコーダ（Conditional Variational Autoencoder;CVAE）をスパンベースの固有表現抽出（NamedEntity Recognition; NER）モデルに統合する先行研究からエンコーダの変更と条件ベクトルの学習を行う．実験では，複数の生物医学データセットを用いた学習を行い，BioRED データセットでの評価で提案手法の有効性を示し，性能向上を確認した．
A7-6,"大規模言語モデルが特定のペルソナ（人格）として振る舞うとき,モデルはどの程度“本心から”ペルソナという仮面を被っているのだろうか.本研究では,表層的には指示されたペルソナとして振る舞えているモデルが,その内部では異なる思考をしているという仮説を立て,モデルの内部表現から出力までの思考の一貫性を検証する.訓練データ・チェックポイントが異なる複数のモデルについて,内部表現一貫性評価のために我々が提案した新たな尺度で評価した結果,ペルソナを付与することでモデルの内部表現の一貫性が向上する事がわかった.一方で,モデル構築過程での内部表現の一貫性向上には限界があることも示され,より出力と内部表現が一貫したモデルを作る方策の必要性が示唆された."
C1-5,大規模言語モデル（LLM）の事前学習では，高品質なテキストを用いることが望ましい．本研究では，文書の「教育的価値」に着目した 2 種類の軽量な分類器を構築して，各文書に品質スコアを付与し，大規模日本語ウェブコーパスから高品質なテキストを抽出する手法を提案する．実験により，提案手法を適用することで，同等の学習計算規模で日本語の知識に関する LLM の能力をより効率的に向上できることを示した．また，分類器の特性比較，ヒューリスティック・ルールの調整，学習のエポック数を増やす実験などを通じて，提案手法の実用性やLLM構築の最良慣行について検証する．
P5-9,生成系タスクにおける大規模言語モデルを用いた自動評価では，評価基準の曖昧さが課題とされている．これに対し，チェックリストにより評価基準を細分化する方法が注目されているが，作成方法の検討はまだ十分でない．本研究では 6 つの生成手法でチェックリストを作成し，それに基づいて回答を評価，その有効性を 3 種の評価モデルで検証した．その結果，チェックリスト未使用時と比較して一致率が向上したケースは 22.6%に留まり，チェックリストの有効性は限定的であった．一方，項目数制限や付加情報の活用が有効であり，小規模評価モデルでも適切なチェックリストを用いることで大規模モデルと同等の評価を行える可能性が示唆された．
Q6-3,本論文では，専門家が作成した法令に関する QAの四者択一問題とその Ground Truth に対して，複数の大規模言語モデル(LLM)を用いて検証することで，Ground Truth に誤りがあることを発見した．発見する方式としては，Ground Truth を与えない状態で，3 種類の異なるファウンデーションモデルのLLM に 0-shot の設定で回答させた．生成された回答から majority voting などの方法で結果を統合し，すべての LLM の答えが一致しない問題を抽出したのち，再度専門家に確認を依頼し，一部問題でGround Truth が誤っていることを突き止めた．
Q1-21,"Graphical Abstract (GA)は論文の要点を視覚的に伝える重要な表現手段である.効果的な GA の作成には高度なデザインスキルが求められ,設計支援技術の実現が期待される.本研究では,約 14.5 万の論文と GA を含む 141 万枚の図からなるデータセットSciGA-140k を構築した.また, GA 設計支援の前段として, Abstract を基に論文内から GA として適切な図を検索するタスク Abst2GA Retrieval を提案する.我々は CLIP を基盤とするベースラインを設計し,提案タスクの有効性を示した.ベースラインは他の論文の GA を検索し,デザイン案を提示する支援機能も提供する.我々のアプローチは GA 設計支援の新たな方向性を示し, AI for Science の発展に貢献する."
Q8-11,本稿では，従来研究における RNN ベースの深層系列処理モデルの持つ課題，（1）記憶の劣化，（2）不正確な勾配の逆伝搬，（3）次トークン予測に対する親和性，の 3 点を同時に解決する DNN 記憶機構の実現に取り組む．具体的には，課題 1〜2 に対処するため，記憶領域に保存されて以降，別の時刻の隠れ状態で上書きされるまで，記憶が保存時の値の恒等写像として完全に保持される Flashback 特性を定義し，その性質を満たす Flashback 機構を提案する．また課題 3 に対して，次トークン予測が可能な方式で，Flashback 機構を従来の Transformersと Mamba それぞれに組み込んだアーキテクチャを提案する．実験では，多様なテキストデータを含むThe Pile データセットを学習に用いて，従来手法への Flashback 機構の導入による常識推論精度，処理速度，メモリ使用量のトレードオフを評価することで，Flashback 特性の有効性を検証した．
Q6-14,本研究では，「質感」に焦点を当て，大規模視覚言語モデル（LVLM）の質感知覚能力を調査し，さらに LVLM と人間との間の質感知覚の整合性を分析することを目的とする．はじめに画像内の物体に対して人間が知覚する質感語を人手で収集した．次に，収集した質感語をもとに，LVLM が適切な質感語を選択できるか評価する分類タスクを設計し，LVLMと人間の正解率を算出した．また，LVLM に質感語を生成させ，その出力を人間が評価する生成タスクも実施した．最終的には，分類タスクの正解率が高い LVLM は，生成タスクにおいても高いスコアを示すことを確認し，分類タスクが，LVLM の質感知覚能力の評価だけでなく，人間知覚の整合性まで簡易に評価できる可能性があることを示す．
Q10-23,"「発想や類推を機械によって行う,あるいは人間の類推の補助が出来ないか」というテーマで研究を行う.例として(爆発物)- (ガソリン)→ (水素)からエンジンの代替エネルギーの発想を得るなどである.以前の村田の研究[1]では,「ネコ」という単語の属性を考え,その属性に「大きい」という属性を追加することで「トラ」という単語を類推して,「ネコを大きくするとトラが導き出される」拡大や縮小の類推を行った.田代の研究[2]では,類似する２単語の引き算により得られる属性を類推する研究を行った.これらの研究では McRae のデータセット[3]を基に研究を進めた.本研究は,入力次第で様々な類推が可能なChatGPT を使用し,「田代の研究で行った類推との比較」,「McRaeと同様のデータセットの作成」,「ChatGPT による様々な類推」を行った.田代の研究の引き算の類推では類推性能 0.46 であったが,本研究の引き算の類推では類推性能 0.48 に向上した.ChatGPT で引き算の類推を行う時も集合で引き算をした場合の方が向上することが分かった.また,McRae のようなデータセット生成で意味の一致を正解とした場合,性能 F 値 0.61 と高性能なデータセット作成が可能であることが分かった. 9 種類のオズボーンのチェックリスト[4]での ChatGPT を用いた類推において,類推性能 0.88 で類推できることを確認できた."
P9-4,"Counter-Argument Logical Structure Analysis(CALSA) is a task that analyzes logic patterns of acounter-argument in relation to an initial argument. Itholds substantial educational value, as informative feed-back for improving counter-arguments can be providedbased on the analyzed logic pattern. However, due tothe complex nature of the task, the implicit reasoningskills required to identify these underlying logic patternspresent signiﬁcant challenges for current LLMs. Toaddress this, we explore decomposing the logic patternsinto ﬁne-grained logic components and tackling themindividually. Our experimental results demonstrateimprovements compared to identifying coarse-grainedlogic patterns. More impor tantly, we ﬁnd that whetherpredicted logic patterns can be considered plausibledeeply depends on the degree of implicitness involved ininterpreting an argument."
P10-23,近年，日本の総人口に占める高齢者人口の割合は過去最高となり，要介護者数も増加している．介護現場において，高齢者の発言を傾聴することは信頼関係を築くために重要である．しかし，近年の介護士の人材不足や介護負担等から被介護者に十分な時間をかけることが困難である．本稿では，外部情報に基づき応答を生成する RAG（Retrieval-AugmentedGeneration）を用いて，傾聴応答の生成可能性を検証する．評価実験では，傾聴応答の生成件数や，ファインチューニングの必要性に注目して考察する．
A5-4,近年，プロンプトを与えることでタスクごとに適した埋め込み表現を出力する，プロンプトに基づくテキスト埋め込みモデルが高い性能を示している．しかし，これらのモデルはしばしば数千次元に及ぶ巨大な埋め込み表現を出力するため推論コストや保存コストに課題がある．本稿では，分類，クラスタリング，検索という 3 種のタスクに対し，事後的にこれらの埋め込みの次元数を削減した場合の性能を調査し，分類・クラスタリングタスクについては次元数を大幅に削除しても性能がほとんど損なわれないことを示す．さらに，固有次元の大きさや等方性を調査することで，大幅な次元削減が可能なタスクに適した埋め込みは冗長性が大きいことを示す．
Q4-1,"Machine learning for structured data has lagged be-hind text and image, with current methods remainingapplication-dependent and requiring extensive algorithmselection and hyperparameter tuning. Large tabular models(LTMs) oﬀer a promising solution for context-aware Au-toML by pretraining on diverse tabular datasets. However,scalability remains a challenge due to the quadratic growthof contexts. This paper introduces a novel in-context Au-toML paradigm focused on semantically informed featureengineering, where input data, rather than model parame-ters, are treated as learnable components. By leveragingtask-speciﬁc insights from data card descriptions and his-torical logs, a large language model (LLM) enhances con-text creation for a LTM. Empirical results on ten benchmarkdatasets demonstrate this paradigm delivers competitiveperformance compared to conventional AutoML methods."
B8-4,広告の成功には人々を惹きつける効果的な言葉選びが欠かせない．本研究は広告文の言語表現に焦点を当て，どのような言語的特徴を持つ広告文が好まれるか明らかにすることを目的とし，選好評価データ付きの広告文言い換えデータセット AdParaphraseを提案する．AdParaphrase は広告文の言い換えペアから構成され，選好評価データを含む．これにより人々が魅力的に感じる広告表現の分析が可能となる．実験では広告文の言語的特徴量と選好評価データの関係を分析し，魅力的な広告文の特徴を明らかにした．またこれらの知見や提案データセットを活用し，魅力的な広告文を生成する手法を探求した．
Q3-24,本研究は、動画キャプション生成タスクにおけるマルチモーダル LLM のハルシネーションの分析を行う。また、ハルシネーション分析に向けて、モデル生成文に対する誤り区間のスパンとそのスパンの修正を付与した新しいデータセットを構築した。分析は言語情報と視覚情報の２つの観点から行い、誤りパターンの分析や動画の明るさや動きといった視覚的要因との関連性に注目した分析を行う。分析結果から、モデルの生成文は入力動画の視覚情報よりもマルチモーダル LLM の Decoder の影響を強く受けた文表現となることや、動画の明るさが大きいほどハルシネーションが生じやすい傾向にあることなどが分かった。
Q4-11,アライメントは大規模言語モデル(LLM)の振る舞いを人間の選好に合わせて無害で正確な，バイアスのない応答を生成するようモデルを誘導する手法である．アライメントの効果は選好データセットの質と量に大きく依存することが知られているが，人手による高品質な選好アノテーションを集めることは非常に高価である．そのため，高性能な LLMを用いて選好データを自動生成する手法が広く研究されている．しかしながら先行研究の多くは英語の多量のデータのあるドメインでの評価がほとんどであり，真に合成データが必要な非英語少データドメインにおける合成方法は明らかにされていない．本研究は日本語 LLM (CALM3)を用い，日本語の AnswerCarefully データセットを基にデータ合成手法を評価した．人手評価の結果，データ合成を行わない場合および外部の報酬モデルを用いた合成方法と比較して，CALM3 のみを使った合成方法の方が高い性能が得られた．本研究成果は日本語の少データドメインでも選好データの合成が効果的であることを示すものであり，今後の日本語 LLM の研究開発に活かされるものであると考えられる．
Q3-18,デザイン会社などで多くのデザイン画像が蓄積されている一方で，近年の Stable Diﬀusion1）をはじめとする Diﬀusion モデル[1]を利用した言語から画像を生成する研究が発展している．本研究では既存のデザインデータを利用することで，目的に応じた新たなデザイン画像を生成する手法について研究する．第一段階として本稿では，デザイン画像として，シンボルマークに注目し，Diﬀusion モデルにシンボルマークと関連するテキストを学習させた場合の画像の出力についてどの程度反映されているかを明らかにする．約 770 件程度のシンボルマークデータを学習させた結果，学習したデータの画像に近い絵を出力するようになったが，一方で，現段階ではデザイン画像として利用できない点があることを明らかにする．
C5-1,サッカーの試合の臨場感や興奮を直接的に伝える主要な手段として，アナウンサーなどによる試合中の実況がある．一方で，サッカーの試合実況は専門人材やコスト面での制約が大きく，下位リーグやアマチュア，育成年代といったあらゆるカテゴリーにおいて実施することは容易ではない.そこで，本研究では，サッカーにおける多様なカテゴリの試合に実況を付与することを目指し，試合映像や選手・ボールの位置情報等の情報から自動的に実況を生成する下流タスクを新たに提案する．J リーグの試合映像に対して実況を付与したサッカー実況生成モデル構築のための大規模なデータセット Live FootballCommentary (LFC)を作成した上で，選手・ボールの位置情報データを入力として，大規模言語モデル（LLM）を用いて実況を生成するベースラインモデルを構築し，評価を行なった．
A3-2,本研究は，複数の大規模言語モデル（LLM）エージェントが協力してタスクを実行するマルチエージェント（MA）アプローチを，社会心理学的な観点から分析することを目的とする．人間同士の相互作用が問題解決に与える影響に関する理論であるSteiner’s theory に基づき，LLM の MA アプローチのエージェント間の相互作用を類型化し，新たな評価指標を設計した．複数のタスクと MA フレームワークにおいて各評価指標を計測し，誤った考えの伝播がグループ全体の結論に悪影響を及ぼすことを明らかにした．また，MA によって単一エージェント（SA）では現れなかった意見が出ることや，誤った意見が出たときに正しい意見を提示することが性能向上につながるかはタスクやフレームワークに依存することが分かった．
E6-2,本論文の目的は，有価証券報告書の表から情報を抽出するタスク（NTCIR-18 U4 Task）に参加するためのシステムの構築である．NTCIR-18 U4 タスクは，表検索サブタスクと表質問応答サブタスクに分けられる．本研究は，表質問応答サブタスクに注目した．表質問応答サブタスクでは，多くの自然言語処理タスクで優れた結果を示している最先端の大規模言語モデル（LLM）を利用し，既存の事前学習済みのモデルを上回り，最高の性能を達成することが期待される．
Q2-7,ユーザのパーソナリティ情報を用いて、興味に合わせた会話を提供することが求められている。本研究では、特にシステム発話を起点とした雑談会話を想定し、ユーザのパーソナリティ情報を利用してユーザの興味のありそうな話題かどうかを推定することができるかを検討した。追加学習した BERT がベースラインを上回る性能だった一方、GPT-4o はベースラインを下回った。パーソナリティ情報から興味の有無を一定の性能で判定できることを確認した。
D9-5,良い対話システムの定義はシステムの用途や評価する個人によって様々である．本研究では，システム設計者など特定の個人の評価傾向を反映した対話システムの自動評価手法を目指す．事前調査として，対話評価における個人差を定量的に分析した．具体的には，対話評価用データセットに付与されている各評価者の評価値から評価傾向の違いを検証した．結果として，評価者間の相関は低く，重視する評価軸の相違が確認された．
P3-21,未成熟な大学生は、謝罪の経験が不足していることが多い。例えば、授業に遅刻したり、レポートの提出期限に遅れたりする場合、教員との適切なコミュニケーション方法として、対話を通じた回復戦略を学ぶことが学生の将来にとって有益である。また、学生が教える立場に立ち自己の学びを深める Learning by Teaching（LBT）やソーシャルスキルトレーニング（SST）の手法を活用することで、生成 AI を利用した対話エージェントの開発が可能となる。このアプローチでは、過失を犯したロボット（アバター）に対し、学生自身が教育的指導を行うことで、実践的な学習素材として活用できる。本論文では、学部 1 年生向け実習科目において導入した対話システムと、その教育効果について論じる。
P4-14,本研究では，アジア地域の英語学習者が書いたエッセイを対象に，各地域特有の言語使用の特徴を明らかにすることを目的とした．ICNALEコーパスの中級レベル（B1_1 および B1_2）の「大学生のアルバイト」に関するエッセイデータを用い，TF-IDF でベクトル化したデータに基づきロジスティック回帰モデルで地域分類を実行した．モデルの正解率は 0.74 であり，混同行列と使用単語の寄与度の分析から，各地域特有の語彙傾向が確認された．これは，文化的・教育的背景が特徴に影響を与えることを示している．
C7-3,会話エージェントが人間に代わって語りの聴き手となることが期待されている．聴き手は，語り手に対して相槌などの応答をすることが重要であり，会話エージェントが聴き手として認められるためには，傾聴態度を示す応答（傾聴応答）の生成が望まれる．傾聴応答には複数の種類が存在し，語り手の発話に対する適切なものは必ずしも 1 つではない．そのため，発話に適する応答種類を複数推定したうえで，その種類に基づいて応答表現を生成することが望ましい．本論文ではある発話に対して表出可能な応答を複数生成する手法について述べる．語り手の発話に適する応答種類をマルチラベル分類により複数推定，発話と推定結果から応答表現を生成する．実験により，応答種類の推定において macro-F1で 0.83 を得た．また応答表現の生成において，比較モデルより Distinct-N の値が向上していたことから，応答種類を利用する有効性を確認した．
E4-1,本研究では，朝日歌壇に掲載されている短歌の特徴を，Fisher の線形判別分析を用いて調査する．どのような短歌が朝日歌壇に掲載されているのかを調査するために，比較の対象として生成モデルによって作成された短歌を用意する．生成短歌には，もし朝日歌壇に投稿されていたら掲載されるような短歌(正例)から，掲載されないような短歌(負例)まで，多様な短歌が幅広く含まれている．こうした朝日歌壇短歌と生成短歌に対して，本研究では従来の線形判別分析を PU 学習の枠組みに拡張した手法を提案し，朝日歌壇短歌を正例データ，生成短歌を正例と負例が混在するラベルなしデータとみなして，これらが混在する PU 学習の枠組みで分析を行った．
A1-1,大規模言語モデル（Large Language Model; LLM）はジェイルブレイク攻撃に対して脆弱であり，違法行為や非倫理的な内容などの有害な出力をしてしまうリスクがある．このジェイルブレイク攻撃に対して，LLM が有害な出力をしてしまうメカニズムは十分に解明されていない．本研究では LLM のアテンションヘッドに着目して内部状態の分析を行い，数%のアテンションヘッドが有害な出力に大きく関与していることを明らかにする．また，分析結果を利用して，アテンションヘッドへの介入による防御手法を提案する．実験の結果，提案手法によ性能の低下を 3%以内に抑えつつ，攻撃成功率を 2，3%程度まで低下させられることが確認された．
C7-2,本論文では，音声・音響・音楽信号を対象とするオープンな音基盤モデル構築に向けた，データセットの策定結果を報告する．汎用的な音基盤モデルを構築してその知見を共有するには，構築に資するデータセットを再現可能な形で整備すべきである．本論文では，音基盤モデルの満たすべき入出力条件を整理し，策定したデータセットについて分析する．
P4-15,談話分析手法の一つである「修辞機能分析」は，発話機能の分類と，主語や主題の分類と述部の時制の分類の組み合わせから修辞機能と脱文脈度を特定するものである．本研究は親子会話の発話に付与された談話行為情報のうち行為要求に分類されている発話の修辞機能を確認して，修辞機能分析と談話行為情報との関係を明らかにすることを試みた．その結果，典型的な行為要求の修辞機能だけでなく，間接的な表現がさまざまな修辞機能として用いられており，修辞機能分析の分類法によってこれらの観察ができることが明らかになった．
D9-4,対話翻訳におけるスタイライズされたコンテンツや対話の一貫性は，機械翻訳にとって重要な課題である．本研究では，これらの問題を評価する指標として「対話翻訳のための多次元品質評価基準（MQM-Chat）」を提案する．MQM-Chat は曖昧さ，流行語，対話不整合性などの 7 種類のエラータイプで構成される．5 つの機械翻訳モデルで生成した対話データに対し，人間によるアノテーションを行った結果，MQM-Chat は既存の評価基準よりも効果的にエラーを分類し，対話特有の問題を明確に示した．
Q2-6,"本研究では，英語母語話者の文法性判断と生成AI のその判断の差異を調査した.英語の主要 56 構文（合計 4,483 例）を用い，AI の文法性判断と母語話者のそれを比較した結果,母語話者が文法的と判断した例では約 82 ％，非文法的文と判断した例では約 62 ％の一致率を確認した．特に話題化，外置，寄生空所など移動を伴う構文において AI と母語話者の判断が乖離する傾向にあることが示された．本研究により，文法性判断に関して生成 AI の苦手分野を特定できたことから，AI の文法性判断能力向上を目指した適切な学習データの構築とベンチマークの開発が今後の研究課題として浮き彫りになった．"
A3-3,"RAG システムの評価には,高品質な QA データセットが不可欠である.しかし,現行の手動作成方法は多大な時間的・人的コストを要し,また既存の自動生成ツールでは生成されたデータセットの品質に課題があるため実案件での利用が難しいという問題がある.そこで本論文では, RAG の評価データセットに求められる品質観点を整理した上で高品質なデータセットの自動生成手法を提案する.実験の結果,一定程度の品質を持つデータセットの生成が可能であり,また従来の実案件データセットと同様に RAG の精度向上を適切に捉えられることを確認した."
E6-3,ティックサイズとは、投資家が注文を行うときに出す注文価格に関する変更可能な単位のことを表す。証券取引所がティックサイズを変更するのには、流動性を高めて、自社の取引所に投資家を呼び込無ことを目的としている。ティックサイズに関してはかず多くの研究があるが概ね流動性の改善が見られているが、東京証券取引所が２０１３年に実施した変更では流動性の悪化が一部で見られた。そこで、本研究では、ティックサイズ変更に関連したパブリックコメントを活用して、売買高の予測モデルの作成を行うことを目的とする。
Q4-10,大規模言語モデル（LLM）の事前学習は，モデルパラメータの多さからメモリ要求量の問題に直面する．本稿では，モデル拡張を用いたメモリ効率に優れた事前学習法である STEP を提案する．実験結果から，STEP を用いることにより，標準的な事前学習と比較して，最大で 53.9%の最大メモリ要求量を削減しながら同等の性能を達成することを確認した．さらに，STEP により訓練されたモデルが，下流タスクに対しても標準的に訓練されたモデルと同等の性能を達成することを示す．
Q3-19,"本研究では,動画データと画像キャプション生成モデルを活用した,音とテキストのペアデータの自動生成手法を提案する.提案手法は 3 段階で構成される.まず,画像キャプション生成モデルを用いて動画のフレームごとにキャプションを生成する.次に,これらのキャプションの選択/統合により動画全体を説明するキャプションを作成する.最後に,生成されたキャプションと音データのペアに対して, CLAPによる類似度計算を用いてフィルタリングを行うことで,高品質な音とテキストのペアを自動的に生成する. ClothoV2 と AudioCaps を用いた language-basedaudio retrieval タスクでの評価実験では,提案手法で生成したデータによる学習が,人手でアノテーションされたデータと同等の性能を達成することを確認した."
Q3-25,近年，ソフトウェア開発において LLM の活用が注目されている．しかし，視覚的な情報を扱えないLLM にテキストのみで開発における複雑な情報を正確に伝えるのは難しい．一方，ソフトウェア開発現場では，要件定義や設計を効率的に行うために，UML ダイアグラムなどの視覚的情報が広く利用されてきた．視覚的情報を活用することで，テキスト主体の LLM の限界を補い，より実用的な支援が期待できる．そのため，視覚的情報とテキストを統合理解する VLM の導入が求められる．しかし，現状の VLM がソフトウェア開発における図表をどの程度理解できるのかは不明である．本研究では，VLMのソフトウェア開発における図表理解能力の調査を目的として，これらの図表に特化したベンチマーク「JSWEMU」を開発した．本論文では，JSWEMU を用いた調査結果について述べる．
B8-5,著者らは漢字の読み推定の学習・評価用コーパスとして「青空文庫振り仮名注釈付き音声コーパス」を構築し，2024 年 1 月に国立国会図書館 NDL ラボから公開している．音声コーパスの構築においては音声と元テキストとの間の対応付けの成功率が最終的なコーパスのサイズに影響を及ぼす．本研究では対応付けの成功率を高めるため，OpenAI の Whisperにおいて，専門用語等の未知語の音声認識を高める目的で使用されるプロンプトを追加し，認識精度の改善を図ることで，コーパスの拡張を試みた．結果として 7604 万文字，4617 時間の振り仮名注釈付き音声コーパスの構築に成功した．本コーパスは近日の公開を予定している．
C3-6,CLIP の埋め込み空間はテキストと画像で大きく分離している(modality gap)ため，異なるモーダル間の類似度が低いことが問題となる．本研究では，事前実験として画像とテキストのデータを外部知識に持つ RAG の検索器に CLIP を用い，画像が必要なケースにおいて正解画像データが検索上位に現れないことを確認する．そこで，外部知識のモーダルに応じて検索スコアを標準化することで，modality gapを考慮した検索手法を提案する．評価実験により，画像の外部知識を必要とするケースの検索精度は0%から 56%に改善し，RAG の生成精度は ROUGE-1で 0.26 ポイント向上したことを確認した．
A5-5,Transformer decoder の認識する言語を所属性問題として定義し，softmax 関数および定数精度浮動小数点数を採用した場合，認識する言語は有限言語および余有限言語クラスと一致することを示した．
P9-5,YouTube や TikTok に代表される動画共有サービスは，現代において様々な人の行動や選択に大きな影響力を持つようになっている．それにより動画共有サービスはビジネスやマーケティングの場としても活用されるようになった．視聴者が動画を閲覧することでどのような感情を得るかという情報は，視聴者とマーケターの両方において有益となる．本稿では，オンライン動画共有サービス上にアップロードされた動画に付けられたコメントから，動画の視聴者に引き起こされる感情の推定を行う手法を提案する．BERT 及び数種類の大規模言語モデル(LLM)を用い，動画コメントを利用した各モデルの感情推定に関する能力の違いを明らかにする．提案手法では，7 種類の感情の強さを成分とした 7 次元ベクトルにより感情を表現し，推定を行う．実験の結果，100 件のコメントを使用して精細な感情の強度を推定する場合には LLM が優位であることが分かった．また，10 件の少ないコメント件数から最も強い感情を推定する場合，BERT が高いスコアを示した．
P10-22,雑談対話コーパスの構築コストが高いという課題を解決するため，本研究では小説の台詞を用いた対話コーパスの自動構築に取り組んでいる．小説には様々な人物が登場するため，単に台詞を抽出するのみでは口調の一貫性を保ったコーパスが構築できない．そこで本稿では，台詞と口調，台詞周辺の地の文から得られる手がかりを用いて，台詞の発話者を特定する手法を提案する．実験の結果，ルールベースで発話者を特定する手法と比べて，提案手法はPrecision をほとんど減少せずに，Recall を向上できることを確認した．
Q10-22,2024 年度から施行された医師の働き方改革によって，医療現場では医師の業務の効率化が求められている．特に，書類の作成は大きな負担となっており，書類作成業務支援が医師の労働時間短縮に貢献することが期待されている．本研究では，医師による診察のサマリー作成を支援するため，外来診察における医師と患者の模擬会話記録を用いて，発話ごとにトピックのマルチラベル分類を行う手法を提案した．実験の結果，提案手法はベースライン手法を上回る性能を示し，診察会話における発話ごとのトピック分類において有効性が確認された．
Q6-15,本稿では，場所を表す言語表現（メンション）を地理データベースの適切なエントリと紐付け，地理座標（緯度・経度）を出力するモデルのための大規模データセットを構築した．具体的には，Wikipediaの各記事に出現するメンションと紐づけられているWikidata のエントリを収集することによって自動構築した．実際に構築したデータセットで学習したモデルは，異なるドメインのデータに対しても高精度で解析可能であることを示す．
Q8-10,本研究では、大規模言語モデル（LLM）による初期アノテーションと、弱教師あり学習の一種であるRobust Unlabeled-Unlabeled Learning を組み合わせた反復的な学習フレームワークを提案する。従来、専門領域や大規模データセットにおけるテキスト分類では、アノテーションコストとラベルノイズが精度向上の大きな障壁となっていた。本手法ではまずLLM を用いて未ラベルデータに対し擬似ラベルを一括付与し、正例比率が相対的に高いコーパスと低いコーパスを疑似正例・負例として構築する。次にRobust UU Learning を適用することで、LLM が付与したノイズを含むラベルにも頑健な分類器を学習し、その分類器で再度データをラベリングする手順を複数回繰り返す。これにより、初期アノテーションの誤りを段階的に削減し、高精度な分類器を獲得できることを実験的に確認した。また、本手法により、GPT-4o などの言語モデルの性能を上回る成果を得られることも示した。
Q1-20,国立国語研究所では，2024 年度より文化庁からの委託事業「信頼できる言語資源としての現代日本語の保存・活用のためのデジタル基盤整備事業」を開始した．この事業は「現代日本語書き言葉均衡コーパス」（BCCWJ）の拡張として企画されているものである．構築の中心となるのは，BCCWJ の出版サブコーパスの書籍部分の拡張で，2006 年～2025 年の書籍サンプル約 1 億語を現在の BCCWJ に追加するものである.本発表ではその設計について報告する．
Q6-2,日本語 LLM の開発が盛んな一方，日本語評価ベンチマークの数や質は十分でない．また，既存のベンチマークはサンプル数が多く，評価コストが高いという問題がある．本稿では，高品質かつ少サンプルな評価用日本語ベンチマーク JAMSE を提案する．JAMSE は，7 つのベンチマークから構成されており，1 ベンチマークあたり 100 サンプルである．そのため，日本語 LLM の言語理解能力と生成能力を低コストで評価することができる．国内外の継続学習モデルや GENIAC コンペティションで開発されたモデルで評価を行ったところ，Nejumi LeaderboardNeo による評価結果と強い相関が確認された．1）
P5-8,"日本語に特化した大規模言語モデル（日本語LLM）の日本語数学能力を改善するには、高品質な学習データを大量に用意することが必要である。本研究では、任意の英語数学問題-回答ペアをシードに、日本語で記述された思考過程付きの数学学習データを、出力の正解を保証しながら半自動で合成する方法を提案した。また、実際に英語数学データに対して提案手法を適用し、約 17 万件の学習データを合成した。PRM800K および GSM8Kの日本語翻訳版を用いた評価では、提案手法により合成された学習データは、日本語 LLM (e.g.,Llama-3-ELYZA-JP-8B)の日本語数学推論能力を確かに改善することを示した。その過程で、学習データが日本語で記述されていることの有用性、データ合成時における正解保証の有用性を示した。"
C1-4,本研究では，重要意見抽出のためのデータセット構築および大規模言語モデル（以下：LLM）を用いた重要意見抽出の手法を提案し，その有効性を検証した．そこで，人間がラベリングを実施せずに SNSから企業がマーケティング活動に必要となる重要意見抽出モデルが構築可能であることを示す．これにより，重要意見データセットの作成や抽出にかかる時間的かつ金銭的コストの削減が期待できる．データセットの構築検証ではワークショプを開催することで重要意見に関連する議論を実施し学生による重要意見データの作成が可能であるかを検証した．また重要意見の抽出検証では，LLM による Zero-shot分類および擬似データを作成した後，ファインチューニングによる重要意見分類の精度を比較した．
P1-19,かな漢字変換は日本語話者において広く普及している自然言語処理応用の一つであるが，その精度は未だに十分とは言えない．本研究では，入力のかな文字列に対応する漢字かな交じり文を生成する条件付きニューラル言語モデルを用いたニューラルかな漢字変換システムを提案し，統計的かな漢字変換システムをドラフトモデルとする投機的デコーディングによって提案手法を高速化する．提案手法の精度および速度の検証を行った結果，従来手法に比べて大幅に高い変換精度と，投機的デコーディングの高速化への有効性が示された．
P6-10,本研究では、効率的なメール管理のために、メールから送信者情報(氏名・会社名・部署・役職)を抽出する重要性に着目し、送信者のメールヘッダとメール本文を入力として、質問応答によって送信者情報を抽出する手法を提案する。実験では、Transformer をベースとした複数の言語モデルの性能を比較した。結果として、モデルのアーキテクチャによって抽出性能が高い項目が異なること、GPT-4oは正解が存在しない場合も誤抽出する傾向があるがEncoder-only モデルより性能が高いこと、入力長による性能低下はモデルや抽出項目によって違った傾向があることがわかった。
P8-15,本研究では、新商品などの教師データに該当商品がなくて予測が困難になるコールドスタート推薦に取り組む。この問題に取り組むために、従来は商品名やカテゴリーといった補助情報を用いる推薦システムが提案されていたが、十分な量の訓練データが必要であった。近年では、大規模言語モデル（LLM）を用いることで教師データなしにコールドスタート問題を解けるようになったが、運用時のコスト面に課題があった。本論文では、LLM をデータ拡張機として活用し、教師データ収集とコスト効率の両課題を解消する RevAug を提案する。RevAugのアイディアは、ユーザがその商品を好きかどうかを予測させる従来の推薦プロンプトを、ユーザが好きそうな商品を生成させるプロンプトに変換し、それにより得られる出力を擬似サンプルとして学習データに活用したことである。4 つの実データを用いた数値実験では、RevAug は少ない教師データで高い推薦精度を達成し、LLM の処理時間と利用料金を大幅に削減した。
A9-5,機械翻訳の問題として学習データの対訳文不足がある．この問題への対策として単言語データを用いたデータ拡張などが行われている．提案手法は日本語と英語の対訳文から英日対・日英対・日日対・英英対の対訳を作成する．そしてそれぞれを英日翻訳，日英翻訳，日本語言い換え，英語言い換えタスクとしてマルチタスク学習を行う．提案手法の特徴としてアーキテクチャの変更，単言語データを用意する必要がない．実験の結果，自動評価と人手評価でベースラインを上回った．
P6-21,複数 Web サイトに点在する人物の略歴文を収集し，Web 検索結果に表示することで，検索サービスのユーザ体験向上が期待できる．しかし，略歴文収集に係る作業は，人間が行った場合においても難易度が高く，大規模な略歴文収集には大きなコストがかかる．そこで，本研究では，LLM を用いて，クロールデータから人物の略歴情報と関連する Webサイトを自動的に紐付け，引用形式を保ったまま略歴文を抽出するタスクを提案し，手法の有効性について検討する．
P8-18,本研究では，企業内で蓄積される論文形式の技報の効率的な活用を目的とし，RAG（Retrieval-Augmented Generation）システムにおける質問分類に基づく動的検索手法を提案する．技報は，技術的な知見や情報を記録した重要な資産である一方，必要な情報を迅速かつ正確に検索することが課題となっている．本手法では技報に関する QA データに質問分類のラベルを付与したデータセットを構築し，質問分類に応じて検索戦略を動的に調整することで，応答精度の向上と応答速度の維持を実現する．
P1-14,"In this work, we dissect mixed ﬁne-tuning for adapt-ing multilingual models to English-to-Japanese translation.We explore diﬀerent sampling regimes across specializedand generic translations. Our ﬁndings indicate that over-sampling the in-domain data leads to notable improvementsin domain-speciﬁc performance, yet at the cost of severedegradation in generalization to unseen languages, per-forming even worse than basic ﬁne-tuning with no genericdata. In contrast, undersampling the generic data pre-serves more of the original multilingual capabilities whilestill achieving moderate domain adaptation gains. Theseresults highlight the critical role of managing training sizeand data coverage to optimize the trade-oﬀ between spe-cialization and generalization during adaptation."
B2-3,本論文では，Haskell の Web アプリケーションフレームワーク Yesod を用いて，日本語推論システムlightblue による文の解析結果や推論結果を可視化する文法開発環境 express の改良を行った．特に，型検査証明図や推論証明図を可視化し，解析結果や推論結果の構造を直感的に理解可能とした．また，ユーザが証明図を操作できる機能を実装し，解析プロセスを詳細に検討できるようにした．加えて，証明が失敗した場合には，その情報をユーザに明示することで，エラーの特定とデバッグ作業を効率化した．本論文では，express のシステム概要と実装についての詳細や，実使用に向けた今後の課題を示す．
P5-5,本研究においては，人工データを用いて二つの時系列データの関係を説明する文生成を行う手法を提案し，実測された時系列データへの適用可能性について検証を行った．具体的には，初めに二つの時系列データの関係を捉えるため Transformer のクロス注意機構を拡張したモデルを用いて，人工的に作成した時系列データの挙動および関係性についての説明文生成の訓練を行う．そしてそのモデルを用いて，実測された時系列データの振る舞いについての説明文生成を行ない，人工データで学習したモデルの実測データへの転移学習の有効性について検証を行った．実測データについての説明文生成の精度は十分に高いものではなかったが，人工データの挙動に近い場合は正しく文生成を行うことが可能であることが確認された．
B10-4,人間同士の対話・コミュニケーションのモデル化する上で、対話中にやりとりされた発話が持つ構文・意味構造や談話構造は重要な役割を持つ。本研究はこうした対話分析に活用可能で、また既存の意味役割解析が対話においてどの程度利活用可能かを測るテストベッドを作成する目的で、日本語日常対話コーパスへの意味役割ラベル・述語項構造のアノテーションを行った。構築したアノテーションスキーマ・フレームワークを用いることで、1 人月あたり 300 対話程度のアノテーションが可能であり、今後の対話研究に本枠組みを用いることが出来そうな見通しが立ったことを報告する。
P10-13,広告文生成は，個々のニーズに応じた広告文を自動生成する技術であり，広告文の誘引性を高めることが広告効果を向上させるうえで重要である．しかし，広告の魅力を左右する要因は十分に解明されておらず，広告効果の高い広告を作成する際の方略が立てにくい．本研究では，広告誘引性における影響要因を分析するために広告特有の特性を考慮した選好データセット AdPsyche を構築し，Bradley-Terry-Luce モデルを要因分析に援用することで，心理的特性が広告選好に与える影響を明らかにする．
Q6-24,近年，大規模言語モデル（LLM）の性能は飛躍的に向上しているが，ハルシネーションと呼ばれる，誤情報を生成してしまう問題が知られており，生成主体の LLM が持つ知識の信頼性や事実性を測定することは重要である．特に，時事に関する誤情報は，ユーザーの実生活における意思決定や行動に直接的な影響を与えるリスクが大きい．そこで本研究では，様々なジャンルのニュースをもとに作成された，時事的知識を日本語で問うベンチマーク『ニュース Q』1）を提案する．主要な LLM のベンチマーク正答率を算出したところ，高品質な日本語コーパスを事前学習する重要性が示唆されるとともに，よりパラメータサイズの大きいモデルの方が時事的な知識をより正確に把握している傾向が確認された．
Q10-13,"特定分野を対象とした日本語向けの大規模言語モデル（LLM）に関する性能評価の取り組みが知られている。しかしながら、製造業分野においては日本語 LLM の性能調査が不十分である。本研究では、製造業関連機器についての質問応答タスクに対して複数の事前学習済み日本語 LLM の性能を比較し、製造業分野における専門知識の学習にどの日本語LLM が適しているかを調査した。結果、教師ありファインチューニング（Supervised Fine Tuning, SFT）を施した LLM において、SFT 前後で Rouge-L が0.080 から 0.224 に向上することを確認した。一方で、依然としてハルシネーションの残存など、LLMの特定分野の専門知識の定着に課題が見られた。"
P9-8,本研究では、絶対的な文難易度が付与されていないコーパスから文難易度推定器を訓練し、所与の文集合を難易度でランキングする課題に取り組む。文難易度は読み手の知識に依存するため、客観的かつ絶対的な難易度の判定には専門家による高コストな評価が必要となる。そのため、絶対的な文難易度が付与されたコーパスは少ないが、2 文間の相対的な文難易度が付与されたテキスト平易化パラレルコーパスは比較的多くの言語で利用できる。本研究では、多言語展開を念頭に置き、テキスト平易化パラレルコーパスに基づく文難易度推定の手法を提案する。英語における評価実験の結果、提案手法は既存の教師なし文難易度推定の性能を上回るとともに、絶対的な文難易度のラベル付きコーパスで訓練した教師あり手法にも匹敵する性能を達成した。
Q8-21,指示チューニングを効率的に行う手段として，高性能な大規模言語モデル（LLM）の挙動を模倣する手法が注目を集めている．既存研究では GPT-4を模倣した学習が主流であるが，ライセンスの制限が厳しいうえ，汎用的な知見が得られにくい．本稿では複数のオープンな LLM を模倣先とし，模倣学習の有効性を検証する．実験結果により，Llama-3.1-Swallow-8B-v0.1 に Gemma-2-27B-IT の模倣学習をさせることで，13B 以下のモデルの中でトップクラスの性能を達成した．また，性能は高いものの模倣学習の効果が限定的な LLM や，模倣学習で習得しにくい能力の存在を明らかにした．
Q1-11,"本研究は,日本語の比喩表現コーパスとして構築した「BCCWJ-Metaphor」における比喩表現の認定手法と情報付与について報告する．MIP に基づきMRW を認定するため，MFlags や結合（選択制限違反）の抽出，比喩種別（擬人化，具象化，換喩，提喩など）の分類を付与している．日本語比喩表現に対応するため，実際の作業手順では，中村(1977)の比喩表現把握モデルを援用し，MIP の基本的意味と文脈的意味の対照による比喩認定を行うこととした．また，比喩性の認定根拠を明確化するため，転換の種別や印象評定情報を付与した．"
Q6-18,広告文生成(ad text generation [ATG])において、望ましい広告文は、入力に忠実であると同時に、潜在顧客にアピールする重要な情報を含む、すなわち、情報性に優れている。既存の評価データである CAMERA [1]は、広告制作者が作成した参照文からなり、情報性の評価に適している。しかし、これらの参照文には入力に忠実でない情報が含まれていることが多く、ATG の研究を推進する上で顕著な障害となっている。そこで本研究では広告制作者と協力して CAMERA の参照文を修正し、忠実性を保証した新たな ATG の評価データセット(FaithCAMERA)1）を構築した。また、既存の忠実性向上手法が、忠実性を維持しながら情報性に優れた広告文を生成できるかどうかを評価した。
D3-2,一般的な音声対話システムはユーザの発話終了検知後に音声応答を生成するため，ユーザが応答生成の時間に待機するユーザ知覚遅延（UPL）が発生する．予測信頼度モデルは，予測したユーザ発話と完全なユーザ発話の文字列が一致する確率を推定するもので，UPL を軽減するために考案された．しかしシステムがユーザ発話を完全に予測せずとも，発話の途中で発話全体の意味を捉えることで，適切な対話応答を生成できる可能性がある．本研究では予測信頼度モデルを再定義し，発話同士の意味的類似度を推定させることで，応答の精度を維持しながらUPL をさらに削減できることを示す．
C10-1,大規模言語モデル（LLM）の事前学習において新聞記事はどのような恩恵をもたらすのか？本研究では，LLM の日本語継続事前学習における新聞記事データの有用性，およびその効果を引き出すための手法について報告する．はじめに，新聞記事のみを用いて LLM の継続事前学習を行ったが，テキスト量と多様性の不足のためか，十分な効果を得ることができなかった．そこで，ドメイン適応の既存研究を参考に，新聞記事をシードとして LLM で合成データを生成し，継続事前学習のデータに追加した．実験の結果，合成データを併用することにより前述の問題を解消し，新聞記事に関連する分野を中心に，LLM の日本語能力が向上した．
P7-7,本研究では，日本語特有のニュアンスに対応したLLM 向けのガードレールモデルである「chakoshi」を開発し，その有効性を検証した．chakoshi は，複数のオープンデータセットを再編成し，独自の学習データセットでファインチューニングした，軽量なLLM である．gemma-2-9b-it をベースとした chakoshiモデルは，複数のテストデータセットにおける F1スコアで平均 0.92 以上を達成し，既存のモデルと比較して高い性能を示した．さらに，防ぎたい話題を自然言語でカスタマイズできる機能を実装し，実験によってその有効性を確認した．
Q4-21,公開されている汎用的なニューラル言語モデルを利用する際，当該タスクやドメインの文書を用いた継続事前学習を行って，下流タスクの精度向上を図ることがある．また，訓練データから重複を除去することで，学習効率が向上することが知られている．そこで本研究では，情報圧縮を用いて訓練データ中の重複を削減する手法を提案する．実データを用いた類似文書検索タスクにて，完全一致を除去するナイーブな手法や，ランダムなデータ選択などと比べて，提案法がより高い検索精度を実現する言語モデルを構築できることを示した．
E8-1,小説を読んでいる途中で「何かについての印象が強化される」と言うことは適切だろうか.その何かというものが出来事等の混合物であり単純に一語で表されてはいないというときにはどうだろうか.小説においては、「強化」というものは単独では終わらずに、さらにその「強化」されたものの影響を受け得る別の項に働きかけ、その項において変形や価値的な反転が生じる.本稿では「出来事の混合物についての心象の強度」が関わる先行研究を取り上げる.ドゥルーズ「差異と反復」(1968)において「強度」「巻き込み」という概念、ドゥルーズとガタリ（以下 DG とする）の共著「ミル・プラトー」(1980)において「表現の形式と内容の形式の相互性、交錯性」を概観する.また実験科学の知見に少し触れる.
Q3-14,本研究では，漫画におけるゼロショット話者認識という課題に取り組む．既存研究では，大規模言語モデルとコンピュータビジョンモデルを組み合わせた手法が提案されているが，複雑なパイプラインに依存し，必ずしも精度向上に貢献しないという課題がある．そこで本研究では，単一の Vision andLanguage Model を活用した新たなゼロショット漫画話者認識手法を提案する．実験の結果，提案手法が既存手法を上回る精度を達成することを示す．興味深いことに，既存手法と提案手法における視覚情報の寄与を詳細に分析した結果，視覚情報が認識精度に及ぼす影響が限定的であることを明らかにする．
D5-4,人間と同様の言語能力を達成するために必要十分な構造しか持たないニューラル言語モデルはどのようなものか？可能な限り簡素なニューラル言語モデルを出発点としてこの問いに取り組むべく，本稿は Reservoir Computing の基本的なモデルであるEcho State Network（ESN）と呼ばれる回帰型のモデルを再訪し，ESN やそれを少し拡張した言語モデルの能力を検証する．実験の結果，適切な初期化のもとでは埋め込み層と出力層のみ訓練し，回帰行列は凍結したとしても統語構造の獲得が損なわれないことが示唆された．
P1-1,同時音声翻訳は，原言語文のセグメント化や目的言語文を原言語文の語順に近づけることで，低遅延と高品質の両立を目指してきた．しかし，既存の評価データは語順の並び替えを多く含むため，低遅延の同時音声翻訳評価に適していない．本研究では，目的言語文が原言語文の単語・句の並びになるべく沿うような語順の単調性に焦点を当てた新しい評価データを提案する．実験の結果から，提案評価データ simul-tst-COMMON は，既存の評価データよりも適切にモデルの性能評価ができることを示した．
P4-24,近年の大規模言語モデルの急速な発展を受けて、言語研究の領域では言語モデルの言語学的・科学的な意義について活発な議論が行われている。しかし、そのような議論において、各々の研究者が（自身がすでに受け入れている）特定の理論的前提に基づいて必ずしもフェアとは言えない主張を展開している場面がしばしば見受けられる。このような背景から、本稿では、言語モデルの科学的理解への貢献を評価する際に考慮すべき要件を、科学哲学における文脈主義の立場を援用しつつ明確化することを目的とする。そして、文脈主義の枠組みに基づき、言語研究における言語モデルの有用性を評価するためには、(1)理解の対象は何か、(2)使用する理論は何か、(3)理論の使用者は誰かの 3 点を考慮する必要があると主張する。
P4-18,本研究では、系列ラベリングの手法を用いて日本語の比喩表現をスパンレベルで抽出した。モデルには BERT を使用し、コーパスには BCCWJ-Metaphorコーパスを用いた。比喩表現一般を抽出するモデルと比喩表現の 4 つの種類である結合比喩、文脈比喩、換喩、提喩それぞれを抽出するモデルの 2 種類を作成した。さらに、各モデルの性能を評価し、エラー分析を行った。これにより、日本語の比喩表現の自動抽出とその課題を明らかにする。
P3-11,本研究は，教員支援を目的に，授業発話分析に基づくアドバイス生成と LLM-as-a-judge による自動評価手法を提案した．教員や児童を模倣した LLM のAttention 機構を用いて，教員発話の影響を推定し，その推定結果を統合したアドバイス生成を行った．さらに，LLM による自動評価を用いて，生成されたアドバイスの質を客観的に評価する手法を提案した．実験では，影響推定を統合したアドバイス生成が，LLM による自動評価で高い評価を得る傾向を示した．提案手法の有効性が示唆されたが，自動評価の改善と信頼性向上が今後の課題である．
B4-5,近年，子供向けの発話（CDS）が言語モデル（LM）の学習効率を向上させる可能性が示唆されている．しかし，CDS のどの特性が LM の学習に有効であるかは明らかになっていない．本研究では，CDS の一つの特徴であるバリエーションセット（VS）に着目し，VS が LM の学習に与える影響を調査する．具体的には，人工的に作成した VS を含む学習データを用いて GPT-2 の事前学習を行った．その結果，文法の学習と自然言語理解において，学習データ中のVS の存在がモデルの性能向上に貢献する可能性を示した．これらの結果から，VS が LM の学習効率向上に有益であることが示唆される一方，効果の詳細を解明するためのさらなる調査が必要である．
P3-3,本稿では，参照文なし文法誤り訂正自動評価手法である IMPARA-GED を提案する．我々は文法誤り訂正の自動評価手法である IMPARA に使用される品質推定モデルに着目し，文法誤り検出能力を強化した事前学習済み言語モデルを用いて，IMPARA-GEDの品質推定モデルを構築した．文法誤り訂正自動評価手法のメタ評価用データセットである SEEDA を用いた性能評価実験の結果，IMPARA-GED は特に文単位の人手評価結果と最も高い相関を示す自動評価手法であることが示された．
P3-2,英語学習者向け英文要約課題の自動評価のため，大規模言語モデル(LLM)を活用し，要約の内容に基づいた評価を実現する新たな手法を提案する．本研究では，Few-shot 学習，採点基準の自動展開，要約内の重要な概念や表現の自動アノテーションを組み合わせることで，要約内容に関する質の高い評価を可能にした．
B4-4,本研究では、失語症者向け意思疎通支援者（以下支援者）と実践経験豊富な言語聴覚士（以下 ST）が使用する会話方略を比較し、新たに活動を始める支援者や訓練未経験者が習得しにくい会話態度・技術について検討した。支援者と ST のそれぞれが失語症のある方と対面で会話をする様子を録画し、それを成人の日本語母語話者24 名が視聴し、Measure of Skill in Supported Conversation(MSSC)[1]に基づき評価した。分析の結果、ほぼ全ての項目で ST の方が支援者より有意に高い得点を得ていた。特に「矛盾する反応への確認」の方略に顕著な差が見られた。支援者は ST に比べ、選択肢や Yes/No 質問を活用できず、同じ質問を繰り返す場面があった。言語・非言語手段を用いた「確認」を取り入れることで、認識のずれを防ぎ、会話の満足度向上が期待される。
P4-19,本稿では、BERT ベクトルを用いてオノマトペ候補の分析を行う。国語研日本語ウェブコーパスから2 モーラが繰り返される ABAB 型のオノマトペ候補を収集し、クラウドソーシングによる調査で分析対象のオノマトペ候補を 64 種類にしぼった。これらのオノマトペ候補の zero-shot の BERT ベクトルを、「ABAB」、「ABAB する」、「AB る」という三種類について主成分分析を用いて二次元上にプロットした。「ABAB」、「ABAB する」、「AB る」のクラスタ間距離を目視で遠い/近いに分けて分析し、これらのクラスタ間距離によるオノマトペ候補の分類を用いて、オノマトペ由来の新動詞の検出を試みた。
P3-10,本稿では，文法誤り検出/訂正においては，訓練データと評価データのドメインが同じときよりも異なるときのほうが性能が高くなるという直感に合わない現象が起こることを報告する．特に，書き手の習熟度が低いデータを訓練に用いると同現象が生じやすいことを示す．この現象は，実質の訓練データ量という観点から自然に説明できることも明らかにする．更に，このことが外国語習得研究および文法誤り検出/訂正研究に与える示唆についても述べる．
P4-25,本研究の目的は，英米文学の分野における文芸批評の客観的分析と大規模言語モデルの分析を結び付ける方策を探ることにある．テクストどうしの影響を調べる影響分析において，BERT の単語埋め込みを使用して，単語埋め込みを組み換えた場合と組み換えない場合の影響の効果を英米文学の影響分析のための評価指標を使用して調べた．単語組み換えに顕著な効果はみられなかったが，主観的な要素を含める文学的読解と自然言語処理を結び付ける方法の一端として有益な試みである．．
C9-1,本論文の目的は，先行研究[9]の情報探索の問題点の解決と，大規模言語モデルによる良否判定の能否を判明させることである．その手法として，まずウェブページの芸能人に関する記事から対象の芸能人に言及している文を収集する．この際，記事を全て人が確認することは困難であるため，その収集を大規模言語モデルの ChatGPT で行う．次に，集めた文章を ChatGPT によって内容でカテゴリ分けし，カテゴリ名を付ける．ここで付けた名前を芸能人の観点と呼ぶことにする．この芸能人の観点について，先行研究[9]の手法との対応付けや，大規模言語モデルによる経歴の良否判定を行う．
D5-5,本研究では，複数の視覚言語モデル（VLM）を記号創発の枠組みで統合する手法である，メトロポリスヘイスティングスキャプション生成ゲーム（MHCG）を提案する．MHCG では，異なるデータで事前学習した VLM エージェント間で画像に対するキャプションを提案・受容・更新するプロセスを通じて，モデル間の知識(本稿では画像に対する言語表現)を統合する．この手法は，既存のモデル統合の手法が持つ推論コストやモデル構造の一致の成約を受けない．実験では，COCO と CC3M でそれぞれ事前学習した２体のエージェントが MHCG を行い，相手のエージェントの学習データに対するキャプション生成性能が向上することを示した．
B6-6,学術情報の電子化・大規模化に伴い，学術データが大量に蓄積され，学術ビッグデータと呼ばれるようになっている．学術ビッグデータの解析は，専門分野の動向を把握・予測し，新しい課題を開拓することが期待されている．しかし，専門性の高い学術情報を解析するにはその分野の特有な表現（専門用語やトピック）を抽出することが難しいとされている．本発表では，学術情報の自然言語解析による用語抽出を検証しつつ，複数生成 AI の統合による専門用語抽出を考案し，実験による評価結果を報告する．
Q3-15,"We aim to explore the extent to which Large LanguageModels (LLMs) can guide 3D digital human agents inperforming body movements without supervised training.Given an existing human model and a textual instruction,we prompt the LLM to generate a high-level plan decom-posing the whole motion into consecutive steps, followedby specifying the positions of every body part in each step.We then render the animation by linearly interpolating theselected body part positions across steps. We evaluatethe generated animations from a diverse set of motion in-structions through both automatic and human evaluation,and ﬁnd that LLMs generally struggle to recognize accu-rate body part positions. Speciﬁcally, LLMs struggle withcomplex motions with multiple steps and body parts, andcomplex body parts with more possible positions."
Q4-20,事前学習済みモデルの性能を新たな言語、特に低資源言語に転移させる際、事前学習済みモデルのサブワード埋め込みを用いて目的言語のサブワード埋め込みを初期化する手法が知られている。それらは目的言語のコーパスを用いるが、低資源言語の中には十分なコーパスが存在しない場合が多い。その一方で、多くの言語には対訳辞書が存在している。そこで本研究では、対訳辞書に基づくサブワード埋め込みの初期化の手法を提案する。実験の結果、既存の手法では課題となっていた言語に対して提案手法は有効であることが明らかとなった。
P7-6,大規模言語モデル（LLM）の評価は，LLM による自動評価が主流となっているが，自動評価には多くの課題が存在し，LLM の評価方法論そのものにおいて決定的な解は未だ得られていない．本研究では，今後の LLM 評価に関する研究を支援することを目的として，484 件の日本語プロンプトに対する10 種類の LLM の応答を対象に，5 つの評価項目に基づいた大規模な評価を実施し，その結果を公開する．本稿では，評価項目の設計方法と評価の実施手順を報告するとともに，構築した評価データに基づく予備的な分析として，評価項目間の関連性分析やLLM の性能比較についても触れる．
D3-3,"Recent advancements in large language models (LLMs)have signiﬁcantly improved dialogue agents, enabling themto generate context-aware, human-like responses. Whilequantitative evaluations eﬀectively compare performancebased on predeﬁned metrics, they may fail to capture nu-anced user experiences, such as memorable exchanges orunexpected opinions, which are crucial for reﬁning the sys-tem. To address this issue, we conducted thematic and sen-timent analysis by collecting participant feedback throughdialogue experiments. Speciﬁcally, we assessed GPT-3.5-Turbo and GPT-4o as dialogue models for dialogue robots.Thematic analysis allowed us to identify recurring patternsin user experiences, while sentiment analysis helped gaugethe emotional tone of those interactions. Our experimen-tal results provided rich insights in the form of themesand sub-themes, such as perceptions of knowledge depthand mistake correction. Sentiment analysis complementedthese ﬁndings, showing that GPT-4o received a positiveimpression, while GPT-3.5-Turbo garnered mostly nega-tive feedback."
Q1-10,タンパク質の立体構造データは原子の位置座標を用いて分子の形を表現したものであり、それと同時に、構造生物学者による解釈の対象でもある。AlphaFold などの高精度な立体構造予測手法は、立体構造を計算機で取り扱うことの可能性と価値を証明したが、いまだに立体構造データの解釈、つまり「立体構造が意味するところ」をバイオインフォマティクス的に扱うことは難しい。一方、近年の自然言語処理技術の発展により、言語データを媒体とすることで「意味を計算する」ことが可能となりつつあるようにみえる。したがって、物質科学的な計算手法と自然言語処理を組み合わせることで、分子の機能予測や設計など、物性と意味が絡みあうタイプの科学の発展に寄与することができると期待される。だが、そのような物質科学的データと「それに対する記述」を詳細にペア化したデータセット──物性と意味とをリンクし得る資源──は存在しない。無いなら作れば良い。本稿では、われわれが構造生物学ドメインにおいて進めている立体構造に紐づいたコーパスの要件定義と試作について報告する。
Q6-19,"Socratic questioning (SQ) is an eﬀective strategy for fos-tering critical thinking. One of the key requirements for us-ing SQs in educational settings is maintaining transparencyand logical alignment with the content. For generatingpedagogically appropriate SQs, we explore a logic-basedtemplate approach by ﬁrst leveraging argumentative com-ponents. We conduct an annotation on top of argument-SQ pairs and achieve moderate inter-annotator agreement(Cohen’s Kappa: 0.49) and 84% for annotating SQ compo-nents. We analyze areas of disagreement, oﬀering insightsfor curating a template set. This work lays a foundationfor advancing template-based Natural Language QuestionGeneration methods and improving model transparency."
Q8-20,大規模言語モデルは小規模なファインチューニングで高い性能を発揮できると他のタスクで報告されているが，テキスト平易化タスクにおいて必要なデータ量は未知である．本研究では，テキスト平易化のためのパラレルコーパスフィルタリングの手法を提案し，大規模言語モデルのファインチューニングに必要なデータ量を削減する．日本語における実験の結果，テキスト平易化のタスク遂行能力は 16〜64 文対という非常に少量の訓練データから獲得できることがわかった．充分なドメイン知識を得るにはより多くの訓練データが必要となるが，それでも提案手法によって，約 7 割の訓練データを削減しつつ全件で訓練するよりも高い性能を達成できた．
P9-9,ソーシャルメディア投稿の政治的傾向を予測することを目的とし，政治的投稿であるか検出するモデルを事前に構築したうえで，データを政治的投稿かどうかでフィルタしてから，学習・評価する方法を提案する．異なるソーシャルメディアプラットフォームの投稿を用いた検証では，フィルタを用いる提案手法がフィルタなしの評価結果を大幅に上回り，国会議員投稿におけるアカウントの与野党分類では最大で F1 値が 13 ポイント向上した．
Q10-12,本研究では，MBLink（Mineutes-to-Budget-Linking）で提供されている小樽市の令和 4 年度の議会会議録と予算表に対して，表の含まれる文書の前処理において，マルチモーダル LLM(M-LLM)を使用することによる，検索における精度への影響を検証する．また，embedding model 間の性能差や ChunkSize，Overlap Size の値の影響を検証する．
Q6-25,本研究では，LLM が生成するテキストが読者の意思決定にどのような影響を及ぼすかを検討し，特にアマチュアと専門家という二種類の受け手に焦点を当てる．実験の結果，GPT-4 が生成する分析はアマチュアと専門家の双方の判断を動かす説得力を有していることが示唆された．さらに，生成テキストを文法，説得力，論理的一貫性，有用性といった観点から評価したところ，これらの多次元評価スコアと，実際に読者が下す意思決定との間に高い相関があることが確認された．このことから，LLM が生成するテキストは人間の意思決定を左右し得る潜在力とリスクを併せ持つこと，そして読者の意思決定を生成テキストの評価指標として活用することが有効である可能性が示唆された．
P10-12,本論文では，半構造化インタビューを対象として，状態遷移モデルと大規模言語モデルを組み合わせた対話制御の枠組みのモデル化を提案する．具体的には，状態遷移モデルの各状態におけるインタビュアの発話生成，および，インタビュー対象者の発話理解に基づく条件分岐判断において大規模言語モデルを適用する．そして，インタビュー対象者の回答に応じて質問項目のスロットを生成・更新しながら，インタビュー対話における柔軟な対話制御を実現する．また，提案手法により，複数のインタビュー対象者との間のインタビュー対話を通じて，インタビューテーマの話題構造を構築し，半構造化インタビューを効率よくモデル化する仕組みを実現する．
P5-4,多言語大規模言語モデル（MLLM）の文脈内学習（ICL）における事例選択では、意味の一致、言語構造の類似、言語の優位性の 3 項目が重要となる。既存研究ではこれら 3 項目を総合的にどのように考慮するべきか明らかにされていない。我々は 3 項目の指標を再定義し、最適なバランスで事例選択する手法を提案する。実験の結果、既存手法と比較して提案手法が最高性能を達成した。
B10-5,従来，読みの推定を行う形態素解析では教師あり学習が用いられてきた．しかし，人手による読み情報の付与はコストが大きく，読み付きコーパスは一部の言語資源に限られている．一方で，読みの付与された単語辞書や生コーパスは入手可能なものが多数存在している．そこで本研究では，読みを含む単語辞書と生コーパスを用いて読み推定と単語分割の教師なし学習の提案を行う．提案手法を用いることで，教師なし学習手法で F 値 90 程度の読み推定精度を達成した．
B2-2,理論言語学において，統語構造を決定するテストの一つに弱交差現象がある．英語の二重目的語構文，与格構文内の二つの目的語のなす階層構造には異なる分析が存在するが，弱交差現象が観測できれば，それらの間の優劣を決めることができる．しかしながら，上述の二つの構文についての弱交差現象の判断には一般的に揺れがあり，これまで決定的な結論は得られていなかった．本研究では，言語機能科学の手法を採用して，上述の異なる分析について，判断に関わる様々な要因をコントロールした厳密な実験を行った．検証の結果は，生成文法における Larson の古典的な分析や，近年の継続文法を支持し，組み合わせ範疇文法と依存型意味論によるBekki の分析を反証するものである．
D1-1,単語の意味は時間とともに変化することがある．近年では，この時間的変動を捉えるため，埋め込み空間上で用例集合を分析する研究が数多く行われてきた．同様の時間的変動は，生態系の生息分布や社会学の犯罪発生分布など，他の多くの分野にも存在する．しかし，このような点集合の動的な変化は非常に複雑であり，解析が困難だという問題がある．本研究では，ガウス過程を用いて点集合を一つの複雑な分布として表現し，それを周波数空間の実ベクトルとしてコンパクトに表すことで，点集合の時間遷移を解析する手法を提案する．提案手法で単語の意味変化を分析し，応用例として社会学の空間データにも適用することで，その有用性を確認した．
Q8-1,本研究では、テキスト内に含まれる複数のパラメータの組み合わせに基づく異常を検出する手法に関する実験結果を報告する。これまでの研究では、BertMaskedLM 手法が高い有効性を持つことが示されている。しかし、先行研究ではモデルを 1 から学習させており、既存の学習済みモデルを用いて追加学習を行う方が精度向上が期待できると予測可能である。そこで、本研究では、先行研究で提案された改善手法による結果と、有名な学習済み BERT モデルを比較、さらに学習済み BERT モデルに同様の改善手法を適用した場合の結果を調査する。
P1-15,本研究では，フィールドワークによって収集されたデータを用いたジンポー語の機械翻訳システムを開発する．ジンポー語は主にミャンマー北東部のカチン州でカチン人によって話される言語であり，言語資源が極めて限られているため，機械翻訳などの言語処理タスクの応用が未だに進んでいない．そこで，本論文では，言語学者がカチン州でのフィールドワークで収集した民話と，母語話者によるその翻訳を対訳データとして用いて，英語・ジンポー語の機械翻訳システムを開発する．実験の結果，フィールドワークに基づく対訳データは少量ながら，ジンポー語から英語への機械翻訳では，民話ドメインにて最大約 10.7 ポイント，会話ドメインにて最大約7.9 ポイントの BLEU スコア上昇が確認された．この結果は，低資源機械翻訳におけるフィールドワークデータの活用の可能性と重要性を示している．
P8-19,トピック分析とは，文書群を内容によってグループに分類する技術であり、大規模テキストデータの分析に有用である．トピック分析の代表的手法として LDA (Latent Dirichlet Allocation)があり，政治学，文献計量学，ソーシャルメディア分析などの分野へ応用されてきた．一方，LDA を単語数が少ない文書に適用すると，人間が解釈しやすい分類結果を得ることが難しいという問題があった．本研究では，文書埋め込みとクラスタリングを組み合わせたトピック分析手法を提案する．4 つのデータセットを分析した結果，既存手法に比べ，提案手法はより人間に近いトピック分類を行うことが示された．
A9-4,双方向学習はタスク対の入出力の対称性を利用して，各タスクのモデル性能を相互的に高める手法である．機械翻訳分野でも，双方向学習は翻訳性能の向上や単言語データを使ったドメイン適応など幅広く応用されている．一方，双方向学習を単一モデルで行うモデルレベル双方向学習では単言語データの活用例が少ない．そこで本研究ではモデルレベル双方向学習での単言語データの利用法を提案する．具体的には，単言語データを用いる補助タスクおよび主タスクである翻訳と補助タスクとを併用するための訓練フレームワークを提案しドメイン適応実験で有効性を示す．
P6-20,場所参照表現を抽出するタスクについて，次の設定を検証した．災害発生直後のソーシャルメディアを対象とし，過去の災害時に流通した投稿で学習したモデルの利用可能性を検証する．国内で発生した6 つの事例を含む災害データセットを構築し，以下の研究課題を設定した．RQ1.災害種別および事例間で場所参照表現の性質は異なるのか．RQ2.過去の災害時の投稿をどのように利用すればよいか．本研究の結論は RQ1.検証した災害種別間では大きな差はない．RQ2.全事例を使うよりも，少量で同等かそれ以上の性能を得られる事例の組み合わせがある．
P6-22,研究活動において研究データの適切な引用は論文の信頼性のための重要な要素である．URL を参照識別子として研究データを引用すること（URL 引用）が多いが，これを対象とする引用要否判定にはデータセットの品質が低いことや分野が限定されているといった課題がある．本研究では，より高精度な OCR を用いて高品質な複数の分野からなるデータセットを作成し，学習データの品質とドメインの違いが URL 引用の要否判定の性能に与える影響を分析した．実験の結果，高品質なデータセットを用いることでモデルの F 値が 14.1%向上することを示した．また，異なるドメイン間でも高い性能を維持できることを明らかにした．
A9-6,最小ベイズリスク（minimum Bayes risk; MBR）復号は、出力候補の中から品質の期待値を最大化する仮説を選択する復号法であり、従来の最大事後確率復号よりも高品質なテキストを出力する。しかし、MBR 復号の出力は、テキスト生成モデルが生成するサンプルに依存するため、生成モデルの学習が不十分なドメインにおいては、ドメインの知識や情報を反映したテキストを出力することは難しい。この課題に対処するため、本研究では、ドメインデータを利用した事例ベース意思決定理論に基づく復号を提案する。独英ドメイン翻訳実験より、提案法は、最大事後確率復号よりも高品質なテキストを出力でき、また、MBR 復号と組み合わせることで、MBR復号よりもドメインに特化した高品質なテキストを出力できることを確認した。
Q8-3,継続学習は、モデルが新しい情報を取り入れつつ、既存の知識を保持する能力を向上させる技術であり、本研究では大規模言語モデル（LLM）における継続学習を通じた知識の埋め込みの手法について検討する。本研究では、LLM に特定のドメインデータの知識を覚えさせるために、継続学習時に対象ドメインデータから作成した複数の NLP タスクを混ぜ、さらに指示学習時においても、ドメイン特化した指示データで学習を行う。QA タスクによる実験の結果、人手評価において、対象のドメインで指示学習データを作ったモデルが最も正答率が高く、ドメイン特化させる場合は指示学習データもドメイン特化させる方がよいと考えられる。また本研究では、継続学習時のコンテキスト長が与える QA タスクの性能変化についても調査した。
P1-17,"大規模言語モデル（LLM）は対話などの生成タスクで成功する一方，翻訳性能の向上や計算コストの高さに課題がある．そこで本論文では，これらの課題を解決するために機械翻訳に適した新たな協力デコーディング手法を提案する．本手法は各言語の単言語データの継続事前学習をしたのち，対訳データによる追加学習をした小型 LLM と，より大型なLLM を組み合わせて翻訳を行う．日英・独英翻訳タスクについて双方向で実験した結果，提案手法はパラメータサイズの小さなモデルを学習することで計算コストを抑え,既存の協力デコーディング手法を上回る翻訳性能を示した．"
D1-3,"Detecting and ﬁltering false infor mation has become acritical area of academic research with the rapid spreadof multimodal fake news on major social media platforms.However, eﬀectively integrating diverse feature types forreliable fake news detection remains challenging. To ad-dress this, we propose a novel fake news detection modelbased on consistency contrastive learning. Our model usesan MLP-mixer to extract features, and consistency con-trastive learning to measure the semantic distance betweentext features and text attribute features. This approach en-hances the MLP-mixers ability to extract consistent high-level features. Experimental results on the LIAR datasetdemonstrate that our proposed model outperforms existingmethods in detecting fake news."
P5-6,アスキーアートはイラストや画像を文字で表現するテキストアートである．文字だけを用いて様々な表現を可能にするアスキーアートは現代社会で広く用いられている一方で，その作成は容易ではない．また既存の生成ツールは画像を機械的に変換するなど柔軟性が低い方法に限定されている．本研究では，自然言語からアスキーアートを生成する手段としての LLM・LVLM の利用可能性の検証を行った．結果として現行のモデルでは生成が困難だが，アスキーアートに特化したデータセットを用いて学習することで生成可能になる兆しが見えた．
Q10-10,単語アライメントは自然言語処理の重要な基礎タスクである。既存の手法はほとんど Transformerエンコーダモデルに基づいている。本研究では、Transformer デコーダモデルに基づく単語アライナーを提案する。また、翻訳文ペアをラベルなしデータとして活用し、Transformer エンコーダベースおよびTransformer デコーダベースの単語アライナーの両方に適用可能な単語アライメントのための半教師あり学習手法を提案する。実験結果は、数万の翻訳文ペアを用いた提案手法が、単語アライメントデータセットにおいて、現在の最先端手法を上回ることを示している。
P10-10,語る機会を創出するために，会話エージェントが語りの聴き手を担うことが期待されている．これらが聴き手として認められるためには，語り手に対して傾聴態度を示す発話（傾聴応答）を生成することが有効である．傾聴応答の 1 つに，語り手の発話を言い換える応答（言い換え応答）がある．言い換え応答を適切に生成できれば，語りを理解していることを示すことに寄与する．本論文では，大規模言語モデルによる言い換え応答の生成可能性を検証する．生成実験を行い，その性能を評価した．
Q1-12,"This paper presents a comprehensive evaluation for as-sessing large language model (LLM) capabilities in theMongolian language, addressing a critical gap in multilin-gual LLM evaluation. We introduce MonMLU, a novelbenchmark derived from native-level university entranceexams, alongside Mongolian adaptations of establishedbenchmarks including Vicuna, MT-Bench, MGSM, andXCOPA. Our evaluation of leading commercial and openlyavailable models reveals that while GPT-4o-mini achievesthe highest performance (8.86 on Vicuna, 8.10 on MT-Bench), openly available models signiﬁcantly underper-form. These ﬁndings highlight future opportunities forimproving LLM performance in Mongolian and other low-resource languages."
Q8-22,近年，大規模言語モデル（Large Language Model：LLM）の発展により，質問応答や文書生成をはじめとする多様な自然言語処理タスクで高い精度が実現されている．従来の BERT やロジスティック回帰と比較して，LLM はより優れた性能を示しているが，その学習および推論には大量の GPU リソースを必要とするため，業務での安定運用には高額なコストが伴う．一方で，BERT やロジスティック回帰などの従来手法を利用することで，運用コストを削減しながらも一定の性能を維持する方法が考えられる．しかし，分析に必要な十分なデータを集められない事例も多く，これがモデルの性能向上を妨げる要因となる．本研究では，LLM を利用して学習データを人工的に生成する手法に着目し，文書分類タスクにおける軽量モデルの精度向上に寄与するかを検討した．実験の結果，参照なし文書生成プロンプトが最も効果的であり，軽量なモデルでも精度向上が可能であることを確認した．
D3-1,LLM の登場により対話システムはより自然な発話が生成できるようになったが，依然として対話の破綻が生じているため，破綻を修復する手法が必要となる．本研究では対話システムの自然な修復を実現するため，人同士の会話における修復開始発話の言語パターンを分析することにより，人がどのように修復を開始するかを明らかにする．トラブルの発生をどのように伝えるかによって他者開始修復（OIR）発話のタイプが 3 つ提案されているが，日本語日常会話コーパスを用いて分析を行った結果，OIR 発話タイプ毎に品詞の出現パターンが異なることが明らかになった．具体的には，OIR 発話タイプ毎に形態素数が異なることや，品詞の種類や出現頻度が異なることが示された．本結果は，対話システムが自然に修復を実行するための基礎的な知見となり得る．
P7-4,大規模言語モデルの普及に伴い，その出力の安全性を担保することが重要な研究課題として認知されている．本研究では，英語の社会的バイアス評価データセットである SocialStigmaQA をもとにして日本語の社会的バイアス評価データセットである SocialStigmaQA-JA を構築する．英語版SocialStigmaQA は米国の文化や法律を背景として構築されたものであるため，日本における社会的バイアスの評価に適するデータセットを構築するためには，単純な翻訳を超える修正が必要である．本稿ではこれらの日本の文化・法律を考慮した修正について詳述する．さらに，構築した SocialStigmaQA-JAを利用して日本語を利用可能な大規模言語モデルの社会的バイアスを評価し，今後の安全性評価の指針について議論する．注意：本論文には不快な表現が一部含まれます．
C10-2,農研機構は、内閣府「研究開発と Society 5.0 との橋渡しプログラム（BRIDGE）」における AI 農業社会実装プロジェクト」にて、農業分野に特化した日本語大規模言語モデルの開発を進めている。本研究では、三重県農業研究所より提供を受けたイチゴに関するマニュアル類を元にインストラクションデータを構築を行い、これを用いて Elyza-8B モデルに対しインストラクションチューニングを実施した。本稿では、これらのデータおよびモデルの構築の概要について解説したのち、実際にこのモデルが専門知識を含んだ回答ができているかを LLM as a Judge にて評価する手法を提案する。
Q4-22,自然言語処理技術の進展に伴い，対話システムが多様なユーザと対話を行う場面が増加している．しかし，特殊な話者スタイルを示す小規模のユーザグループに対しては，データ不足がシステム性能向上を妨げる要因となっている．本研究では，話者スタイルと対話行為の流れを組み合わせたデータ拡張手法を提案する．大規模言語モデル（Large LanguageModel; LLM）を用いて話者スタイルを抽出し，事前学習済み言語モデル（Pre-trained Language Model;PLM）を活用して対話行為系列を生成することで，その話者に特化した豊かな対話データを生成する．実験により，提案手法が低リソースユーザグループに適応可能な対話システムの開発に寄与することを示した．
E8-2,心の理論は，他者の心的状態を推測する能力であり，人間の社会的相互作用において重要な役割を果たす．近年，大規模言語モデル（LLM）が人間と同等の心の理論の能力を示すことが報告されているが，そのメカニズムはまだ十分に解明されていない．本研究では，LLM の内部表現を解析することで，心の理論のメカニズムに関する理論的枠組の一つであるシミュレーション説の LLM における妥当性を検証する．実験の結果，LLM におけるシミュレーション説に対して肯定的な証拠は得られなかったが，解釈可能性の研究で広く用いられる介入の限界を明らかにし，LLM における心の理論のメカニズムに関する今後の研究の方向性を提供する．
Q3-17,"Social media websites have had the option of multime-dia uploads for more than a decade now. However, therelation between the text and the posted images is not al-ways unambiguous if there is a relation at all. We explorehow multilingual vision-language models tackle the task ofimage-text relation prediction in diﬀerent languages, andprepare dedicated balanced benchmark data sets from Twit-ter posts in Latvian and English. We compare our resultsto previous work and show that the more recently releasedvision-language model checkpoints are becoming increas-ingly capable at this task, but there is still much room forfurther improvement. Experiments with in-context learn-ing outline how further improvements can be achieved."
B6-4,"熟練から若手エンジニアへの故障解析の知識継承は自動車業界喫緊の課題である.故障に関する文書は非構造的でデータ量が多いため,そのままでは活用が困難である.このような文書をデータの構造化に優れるナレッジグラフ(KG)に変換することは有効であるが,依然として理解が難しい.GraphRAG は, KG と大規模言語モデル(LLM)によるRAG (Retrieval-Augmented Generation)であり, KG 自体の理解を深めることも期待される.既存の KG を用いた GraphRAG に必要な処理を調査するため,本稿では LLM と継続事前学習済みSentence-DeBERTa で拡張した既存の KG と,クエリの分解に焦点を当てた EdgeGraphRAG を提案する.独自のデータセット構築と自動評価により,現時点での有効性の検討と既存の KG を用いた際の課題を論じる."
Q2-8,大規模言語モデル（LLM）の発展に伴い，正確ではない情報の生成・流布が問題となっている．この課題に対応するため，日本語 LLM の正確性の評価用ベンチマークが必要だが，既存のものは英語のものが多く日本特有の偽・誤情報を十分にカバーしていない．本研究では，実際のソーシャルメディアで流通している日本語の誤解を招く情報に基づいたベンチマーク JSocialFact1）を用いたベンチマーク評価とその課題を議論する．このベンチマークは，X のコミュニティノートと投稿データを活用し，複数アノテータにより作成したデータセットであり，多様な種類の誤情報を網羅することを目指している．本研究では，提案する JSocialFact を用いて複数の LLMの正確性および安全性を評価する．
P1-2,化学反応の高精度な予測は，実験を行う前に実験結果の予測ができることから，創薬をはじめとする分野で実験コストの削減の視点から注目されている．これまでに化学反応予測モデルの開発は活発に行われてきたが，利用可能な学習データが限られていたことから，分布外データへのモデルの微調整（ファインチューニング）を想定した事前学習モデルに関する研究は限定的であった．本研究では，大規模化学反応データベースを用いた事前学習を通じて化学反応基盤モデルを構築した．本モデルを活用することで，従来のモデルと比較して非常に少ないファインチューニングデータで，優れた予測性能を実現できることを示した．
C9-3,特定ドメインを対象とする検索タスクにおいて埋め込みモデルのドメイン適応は重要であるが，対象とするドメインの種類数が膨大な場合には追加学習による方法を適用するのは難しい．本研究では，ニューラルモデルに基づく密ベクトル検索において，モデルを追加学習することなくドメイン適応させる方法を提案する．具体的には，ドメイン適応先の単言語コーパスからクエリの k 近傍事例を計算して，近傍事例の埋め込み表現を統合した表現によってクエリの表現を調整する．実験では，独自に収集するデータを用いた故障事例検索タスクにおいて，提案法により検索性能が向上すること，また検索結果が解釈性の向上につながることを示す．
P3-12,複数の料理を同時かつ効率的に調理するには，利用可能な調理器具の制約と調理・物理現象に対する常識的な理解が不可欠である．自然言語で書かれたレシピから自動的に効率的な調理計画を組み立てるには大規模言語モデル(LLM)がもつ推論能力は非常に有用と考えられる．本研究では LLM を活用して同時調理の工程を計画する手法を検討し，解くべきタスクと課題の考察を行った．
B4-6,"大規模言語モデル（LLM）は汎用的な言語能力を持つが，言語獲得効率では人間と大きな乖離がある．本研究では，人間が特定の時期において言語獲得が特に効率的に進むとされる臨界期における作業記憶の発達的特性を言語モデルに組み込む手法を提案した．提案手法では，学習初期に“作業記憶”を制限し,学習が進むにつれて指数関数的に制限を緩和する仕組みを導入する．文法評価ベンチマークで性能を評価した結果，提案手法は従来手法を上回る性能を示し，特に，局所的な規則性と文全体の複雑な関係を含む文法項目で顕著な改善が見られた．これらの知見は，データ効率の高い LLM 設計の新たな指針を提供するだけでなく，人間の言語獲得における臨界期仮説を支持する重要な間接証拠となる．"
P3-1,本研究では，手書き答案の文字認識誤り訂正を目的として，RoBERTa による誤り箇所推定と T5 による誤り訂正を組み合わせた 2 段階モデルを提案する．既存研究では，T5 を用いたモデルで答案全体を対象に訂正を行っていたため，必要のない箇所まで訂正される問題があった．これに対し，本手法では，RoBERTa を用いて誤り箇所を推定し，その結果に基づき T5 で該当箇所のみを訂正する．中学生185 名による国語ドリルの記述式問題の手書き答案をデータとして実験を行った結果，提案手法は T5単独モデルに比べ訂正精度が向上し，不要な訂正を抑える効果が確認された．
D7-4,"不完全情報ゲームである人狼において、大規模言語モデル(Large Language Model, LLM)を利用したエージェントが人間のように戦略的な発話を行うには、会話履歴の情報から状況を把握する等の難しさがある。本研究では、自身が置かれた状況を把握し、状況に適切な発話方針をプロンプトとして与えるエージェントを提案した。この手法により、提案したエージェントは戦略的な発話を多様に出力することが可能になった。また、LLM を単純に適用した場合と比較して、発話が個性的で論理的になっていることを定性評価により示した。"
P3-13,E コマースにおいて商品の特性を表す属性情報は，ユーザーの購買判断における重要な情報であり，これらのデータの整備はユーザー体験向上のための重要な課題である．しかし未整備の属性情報には，実際には同一とみなせる表現が異なる表記で扱われていることが多く，これらを統一するためには高い精度での表現の正規化が必要となる．そこで本研究では，蓄積された人手による目視検証と修正を加えた整備済みの属性情報から，動的に Few-shot の事例選択した大規模言語モデルによる属性値正規化システムを提案し，実際の E コマースの商品情報から抽出した属性値を用いて評価と分析を行う．
C9-2,膨大なアンケートデータから，分析目的に合致する設問を検索する作業は，マーケターにとって手間と時間がかかる工程の一つである．この作業工程をユーザのクエリ入力による設問検索で効率化することを提案する．このとき，クエリの意味や内容が抽象的であってもユーザが望む設問を検索することを目指す．本研究では，アンケートデータ設問検索タスクに取り組む．それに伴い，マーケターのアノテーションによる設問検索データセットを構築した．複数の手法を用いた設問検索実験の結果，文から直接埋め込み表現を取得しクエリとの類似度を求める手法が高い精度を示した．また，設問検索特有の課題が明らかとなった．
P1-3,近年，材料の用途探索に自然言語処理を活用する取り組みが広がっている．材料固有の特性を発揮させる使用法が用途であることから，用途探索は，材料の特性が発揮できる用途を探し出すタスクとなる．本論文では，材料固有の特性に類似する特性エンティティを含む文書を検索したのち，特性エンティティに関係する用途エンティティを同文書中から取得することにより，材料特性を活かした用途アイデアの獲得手法を提案する．さらに本論文では，提案手法で獲得した用途アイデアを対象に専門家による新規性と実現性の評価を実施し，その有効性を確認する．
Q2-9,"We study the generalization capabilities of Large Lan-guage Models through the lens of mathematical reasoning,asking if these models can recognize that two structuresare the same even when they do not share the same nomen-clature. We propose a human study to evaluate if LLMsreproduce proofs that they have most likely seen dur ingtraining, but when the symbols do not match the ones seen.To test this in a controlled scenario, we look at proofs inpropositional calculus, foundational for other logic sys-tems, semantically complete and widely discussed online.We replace the implication operator (→) with an unrelated,arbitrary symbol (♠) and ask experts to evaluate how theoutput of a selection of LLMs changes in terms of com-pliance, correctness, extensiveness and coherence. Our re-sults show that nearly all our tested models produce lowerquality proofs in this test, in particular open-weights mod-els, suggesting the abilities of these LLMs to reason in thiscontext have important limitations."
B6-5,法令文では定義規定・略称規定が頻繁に使用されている（例：新型インフルエンザ等対策の推進を図るため、内閣に、新型インフルエンザ等対策推進会議（以下「会議」という。）を置く。）．これらの規定文は複雑になりやすく，読者の混乱や負担を生じさせうる．そこで本研究では，既存法では不十分であった定義規定・略称規定に関する文型を導入し，これに基づき正式名称と略称のペアを抽出するパターンベースの手法を提案する．結果，提案法は複雑な構造や文型に対応し，既存の手法や大規模言語モデルとの比較で高い精度を達成した．また，今後の法令解析研究の促進のために，実験で使用した正式名称と略称のペアのデータセットを公開する．
D5-6,抽象的な物体を指示対象とする共通基盤の構築過程を，シミュレーションにより検討した．利用したモデルは，コミュニケーションの過程を，対象の知覚，イメージ生成，言語生成などのモジュールの組み合わせにより説明する．各モジュールの機能を検討する実験により，(1)対象知覚の調整に比べ，言語生成の調整が，対話相手との意思疎通の成立に有効であること，(2)イメージ生成は，言語生成の多様化を促進することが明らかになった．この結果は，共通基盤構築に寄与する認知機能の役割を検討するうえで，本研究のアプローチの有効性を示す．
Q3-16,"Vision Large Language Models (VLLMs) usually takeinput as a concatenation of image token embeddingsand text token embeddings and conduct causal modeling.Based on observations, this paper hypothesizes that in-tensive multimodal interactions happen in the mid-to-latelayers. To verify, we apply cosine similarity measurementand norm-based attention analysis. Our experiments indi-cate that in the mid-to-late layers of LM decoder, there isa rise in inter-modal similarity and gradual accumulationin attention allocation to visual tokens, suggesting a four-phase inference dynamics against the LM layers, includingI) Alignment, II) Intra-modal Encoding, III) Inter-modalEncoding, and IV) Output Preparation."
E8-3,錯視画像とは，その実際の特徴と見かけの特徴が異なるような画像のことである．大規模視覚言語モデル(Large Vision-Language Model: LVLM)に関して，その錯視画像の認識能力を評価する研究が近年行われている．先行研究においては，実験の結果により，LVLM は錯視に騙されやすい，あるいは人間と同様の騙され方をすると考えられている．しかし，先行研究は錯視に関する重要な区別を見落としているため，その実験結果に曖昧さを残している．本研究では，可能な限り曖昧さを排した手法を提案し，それを用いて LVLM の錯視認識能力を評価する．実験の結果，LVLM は一見して錯視を理解しているように思われるものの，実際には錯視に関する一般的な知識から回答しており，錯視を視覚的に正しく認識しているわけではないことが示唆される．
Q4-23,"データ分析において不可欠なステップであるデータ前処理（DP）に対して，大規模言語モデル（LLM）の活用が注目を集めている．しかし，既存手法の多くは GPT の API に依存しており，プライバシーやコスト面での課題が残されている．本研究では，ローカル環境で実行可能な，Llama3-8B,mistral-7B などのパラメータ規模が小さい LLM にのInstruction-tuning を実施し，代表的な DP タスクにおける性能を包括的に評価した．本実験により，全てのモデルの性能向上が確認され，GPT-3.5/4 に匹敵する処理能力を実証した．この取り組みは，ローカル環境で実行でき，プライバシーとコストを考慮しつつ高性能な DP を実現しうる LLM による実用的な解決策を提案するものである．モデルおよび学習データは https://huggingface.co/NECOUDBFM で公開されている．"
C10-3,"我々は,日本語を主とした 700 億パラメータの日本語・英語・中国語のトリリンガル大規模言語モデル(LLM: Large Language Model)を転移学習によって開発した.開発にあたっては,トークナイザーの差替,カリキュラム学習,モデルマージといった複数の手法を順に組み合わせた.本稿ではその手法の詳細と,評価結果を報告する.結果として,継続事前学習においては日本語に転移学習済のモデルをベースに学習を行ったことに起因すると思われる日本語性能の飽和が見られたものの,その後の SFT,及びモデルマージによって,元モデルと比較して大幅な指示追従性能の向上が確かめられた."
P7-5,昨今，大規模言語モデル（Large Language Models;LLM）が生成する文を検出する需要が高まっており，代表的な手法の一つに透かし（Watermark）がある．生成文に埋め込まれた透かしトークンを調べることで高性能な検出が可能な一方で，そのトークンはランダムに選択されるため，その生成文の品質やタスク性能に課題がある．そこで，本研究ではLLM のタスク性能を維持したまま，その LLM の生成文を検出しやすくするフレームワーク PUPPET を提案する．具体的には，生成文に対して検出器とタスク評価器の二つから報酬関数を設計し，LLM の強化学習を行う．評価実験の結果，我々のフレームワークで学習した LLM は文書要約タスクにおいてタスク性能を維持したまま，その検出が容易（再現率 6pt 向上）となったことを確認した．
Q8-23,大規模言語モデルは，重みの勾配や最適化状態を保持するため，推論時よりも訓練時に要求される GPU メモリ量が多いことが知られている．したがって，例えば同一の計算資源上で基盤モデルの訓練と推論を行う際には，基盤モデルのサイズは訓練時の資源制約から決定されるため，推論時には GPUメモリの余剰が発生する．本研究ではこの推論時のメモリの余剰に着目し，これを活用して LoRA モデルの性能を向上させる新たな量子化-LoRA フレームワークとして，Post LoRA Restoration（PLR）を提案する．評価実験の結果，訓練時の計算コストはそのままに，PLR による最大 12 倍の精度向上が確認できた．
Q1-13,関西方言を研究するための形態論情報付きコーパスとして，ケビン・ヘファナン教授によって構築された「関西弁コーパス」のテキストの一部を UniDic短単位に分割し，171 万語に形態論情報を付与した短単位版「関西弁コーパス」を構築した．うち 77.5万語は人手による検証・修正を行い，残りの 93.5 万語は形態素解析器 MeCab と人手検証済みデータで学習した関西方言用 UniDic を利用して解析した．本稿では，短単位版「関西弁コーパス」の構築について論じ，その価値を示す活用例として予備的な分析結果を示す．短単位版「関西弁コーパス」は，関西方言の研究に有効な資料として利用されることが期待される．
P10-11,雑談対話システムの性能を参照応答に基づいて評価する際，評価の妥当性を担保するためには，参照応答集合が評価対象の対話履歴に対して想定される応答候補を十分に網羅している必要がある．本研究では，言語モデルが出力する応答の多様性が，評価に必要な参照応答集合の大きさを予測する指標として有用であるかを検討した．実験の結果，少数の参照応答でも評価可能と分類された対話履歴は，それ以外の対話履歴と比較して応答候補の多様性が低いことが確認された．得られた結果から言語モデルが出力する応答の多様性が，必要な参照応答集合の予測に有用である可能性が示唆された．
Q10-11,"The Knowledge graph completion (KGC) task aims topredict missing relations in knowledge graphs (KGs). Re-cently, text-based KGC approaches have gained attentionbut they present challenges: encoder-based methods re-quire ﬁne-tuning making it non-ideal when an ideal KG fortraining cannot be obtained, such as when KG is sparse orpredicting new relation-types. Meanwhile, decoder-basedmethods make prediction by generating tokens, where en-tity disambiguation becomes a challenge. KGC is also usedin knowledge proving, which aims to evaluate the knowl-edge retrieval capability of pre-trained language models(PLMs), but existing probes for generative PLM capable ofranking all multi-token and single-token entities are com-putationally ineﬃcient. To address these problems, we pro-pose DEER, an encoder-based few-shot KGC, leveraging agenerative PLM that achieves a linear inference time com-plexity. Our experiment shows that DEER outperforms aﬁne-tuned KGC model in a relationally inductive settingand aligns with an existing knowledge-probing method,positioning it as a possible alter native."
B10-6,本研究は，言語モデルに実世界に対応した定量的推論（特にファジィ推論）機能を組み込むことを目的とする．二つの物体が衝突した後の状態を言語モデルにより自然言語で推論すると同時に，推論の中に含まれる程度を表す表現に対する物理量を回帰型ニューラルネットワークを用いて学習させる．これにより定量的な状態変化を反映したファジィ推論により帰結となる定量的な物理量を表すメンバーシップ関数を推定する．特に，具体的な値で表せない「かなり」「少し」などの程度の表現の意味合いを学習させることを対象とし，その曖昧な表現を表すメンバーシップ関数として予測されたものの精度を測ることにより，推論の妥当性を検証する．
P5-7,本研究は，Game Description Language(GDL)を基にしたゲーム記述生成において，文法的正確性を改善する新しいプロセスを提案する．GDL は多様なゲームを統一的に表現できるドメイン固有言語であり，ゲームデザインの自動化に広く利用されている．本研究では，大規模言語モデル(LLM)を活用し，文法に基づいた生成候補を逐次提示するアプローチを開発した．さらに，部分出力と文法的に妥当な候補を含むデータセットを構築し，LLM を教師ありファインチューニングで学習させた．その結果，提案手法は生成されたゲーム記述の文法的に正確さにおいて従来手法を上回る性能を示した。
D1-2,2022 年の ChatGPT 登場以降，多くの大規模言語モデルが提供されているが，それらの多くがTransformer のデコーダモデルを採用している．一方，意味役割付与タスクでは依然として Transformerエンコーダモデルが主導している現状がある．本研究では，Transformer デコーダモデルを利用した日本語意味役割付与タスクにおいて，精度向上に寄与する特徴量の位置および Attention Mask の形状を検討し，ベースラインモデルとの比較実験を行った．EOS，LA，PS，PS-Attn.の 4 つの手法を提案し，PSと PS-Attn.でベースラインモデルと比較して F1 値における大幅な精度の向上を示した．
B2-1,本研究は，依存型理論に基づく自然言語の意味の理論である依存型意味論を通して，様相表現(modalexpressions)の分析を試みる．依存型意味論は，照応や前提が絡む複雑な言語表現に対応可能であることが示されてきたが，物事の可能性(possibility)や必然性(necessity)に関わる様相表現への分析の拡張は依然開拓の余地がある．そこで本論文は，依存型意味論を様相型で拡張した Modal DTS を提案する．これにより，照応とモダリティが相互作用する様相従属化(modal subordination)をはじめ，前提を伴う様相従属化についても分析を与えるなど，依存型意味論が対象とする言語現象を拡大した．
P1-16,近年、大規模言語モデル（LLM）の発展により、高度な自然言語処理タスクの実現が可能となっている。しかし、文章校正タスクにおいて、LLM は入力文の意図を超えた過剰な書き換えを行う傾向があり、元の文意を保持できないという課題がある。本研究では、BART モデルにコピー機構を導入することで、必要最小限の編集に限定した文章校正の実現を目指した。評価実験では、ERRANT による F0.5 スコアを用いて編集精度を測定し、従来のBART モデルと比べて精度が向上したのを確認した。また、LLM である Gemini とも比較を行い、本手法が有効であることを示した。この成果は、我々の文章校正 AI サービス「ちゅらいと」の改善に向けた重要な知見となる。
Q8-2,大規模言語モデル（LLM）の業務活用では業務に必要な独自知識を LLM が扱う必要がある．個別の業務・製品の知識をLLMに活用させる方法としてRAG が主流であるが，複数の業務・製品が複雑な知識体系を持つ小規模なマイクロドメインを形成する場合に有効な知識活用方法は明らかでない．本研究は JP1 というミドルウェア製品を対象ドメインとし，追加学習と RAG を併用したマイクロドメイン特化の有効性を検証する．追加学習ではデータ合成によりデータの量・多様性を補強する．多肢選択問題から成る JP1 の資格認定試験で評価した結果，マイクロドメイン特化により正答率が向上し，最難関の試験では合格点（70%）に達した．
P6-23,近年大規模化しているゲームやアニメ、映画、漫画などといった物語を扱うコンテンツにおいて、物語およびその設定に関わる知識をどのように整備・運用するかが課題になっている。本研究では、物語の制作・監修を容易にするために動的に変化する物語世界内のエンティティの状態に関わる事実を検索する手法を提案する。具体的には① LLM によって物語テキストから情報抽出・構造化を行い、②時相論理を用いて検索を行う。提案手法を単純な構造を持つ物語に適用し、簡易的に評価を行った。
P8-22,研究者への情報推薦は論文調査や関連研究者の探索に有用である．個々の研究者の業績一覧が入手可能な場合，そのコンテンツ情報を各人の専門興味のモデル化に用いることができる．一方，共著者情報が適切に整備されている場合，研究者や論文をノードとしたグラフ構造に基づくモデル化手法を採用できる．近年はこのようなグラフベース手法が注目を集めているが，コンテンツ情報のみでのモデル化手法と同一条件下で比較した例は未だ報告されていない．本論文では，学術情報推薦をグラフ内のリンク予測問題とみなし，これら二種類の手法を比較する．実験方法を情報推薦の観点から再設計した結果，コンテンツベース手法がグラフベース手法より高い性能を示した．また，リンク予測の観点での推薦性能と推薦結果の意外性はトレードオフの関係にあることが示唆された．
Q8-6,"日本法と外国法において，類似条文の対応付けに一定の需要がある．先行研究[1]では日本とドイツの民法の自動対応付けが行われた．しかし，対応付けできない条文も多く,高い評価は得られなかった．本研究では先行研究[1]の対応付け手法と評価手法を見直し， fine-tuning の実装を行った．実験により，本研究で行った類似条文の自動対応付け手法が先行研究[1]の手法を上回った．また，fine-tuning を実装することでさらに高い評価を得ることを確認した．"
P1-12,"Scene text translation aims to automatically translate textin images or videos while preserving its visual features. Inthis work, we focus on scene text translation for complexwriting system by taking Japanese as a typical example.We build a pipeline to translate from English to Japanese,leveraging publicly available modules for text detection,recognition, and translation, and train our own text replace-ment model specialized for English-to-Japanese transfor-mations. Experiments show that the system can eﬀectivelygenerate translated text in Japanese while retaining muchof the original style, although background regeneration andhandling of Kanji remain open challenges."
A9-3,特許請求項は特許範囲を規定する重要部分だが，その長さや独特の書式が原因で NMT モデルでは訳抜けや繰り返しといった誤訳を引き起こしやすい．本論文では，この課題を解決するために，節分割モデルを用いた分割統治翻訳手法を提案する．翻訳元文を節分割モデルを用いて節に分割し，それぞれの節を節翻訳モデルで翻訳，その後並び替え・編集モデルで最終的な翻訳文を生成する．さらに，節分割モデルと節翻訳モデルを訓練するための節単位の対訳コーパスを，単語対応情報をもとに文単位の対訳コーパスから作成する手法を提案する．実験では，提案手法が通常のモデルを BLEU で上回り，訳抜けや繰り返しの改善を確認した．
P5-3,Transformer-デコーダをベースとした大規模言語モデルは、文脈理解・回答における精度の高さから活用が広がっている。近年では長文入力への需要が高まっているが、自己注意処理(Attention)における計算量が入力長の 2 乗に比例すること、KV キャッシュのサイズが入力長に比例するという理由により、入力長に対して制限が存在する。本研究ではTransformer 内の各レイヤ・各ヘッドについて注意スコアの分布を調査し、同一レイヤにおいてスコアを共有できるヘッドが存在すること、また各レイヤについてスコアが大きなトークンが共通していることを明らかにした。これを元に自己注意処理の効率化と KV キャッシュの削減を行い、削減前と比較してベンチマークにおける精度低下が限定的であることを確認した。
B10-2,本稿では，技術文書のように厳密に事実を伝えるべき文書中の矛盾を検出する方法について議論する．文書中の矛盾を放置したままにすると重要な損害がもたらされる場合は多い．例えば，システムの開発において，文書中の矛盾に気付かずにシステムを製造してしまうと，テスト時に不具合が発生し，製造をやり直すことになる．本稿では，技術文書中の矛盾を検出する基本的な方法を提案する．特に，システム開発において実際に発生しやすい矛盾に焦点を当てる．
Q6-9,近年，ソースコード生成などのタスクにも大規模言語モデルを活用する動きが活発化している．しかし，日本語を用いたコード生成ベンチマークは限定的であり，特に Python 以外のプログラミング言語を用いた高品質なデータセットは存在しないことから，正確な評価はできていない．本稿では，既存のデータセットを拡張し，高品質な日本語タスク説明文を伴う，複数のプログラミング言語のコード生成評価ベンチマーク JMultiPL-E を構築した．実験により，日本語での継続事前学習が日本語を用いたコード生成において効果的であることの示唆を得た．
B2-5,"本研究では，依存型意味論(Dependent Type Seman-tics, DTS)を基盤とした自然言語推論システム NeuralDTS の学習アルゴリズムを実装し，その挙動を検証した．DTS は文の意味を型理論に基づいて厳密に表現する一方，曖昧な述語を表現したり，言語表現同士の類似度を計算したりすることはできない．この課題に対処するため，Bekki らにより提案されたNeural DTS の枠組みを基に，その学習アルゴリズムを実装した．また，自然言語文データセットで分類器の学習を行い，DTS の述語と名前を埋め込むことによって構築したニューラル判定器の性能を検証した．"
D1-6,言語モデルを特定のタスクに対して最適化するチューニング手法は現在多くの場面で用いられている．チューニングには言語モデル内部のパラメータを更新する手法や，入力文を更新する手法など様々なアプローチが存在する．これらのチューニング手法は対象の言語モデルの内部のアクセス性によって使用できる手法が異なる．本研究では言語モデルのアクセス性に応じて分類されたチューニング手法を多角的に比較することで，それらの特徴や傾向を分析する．
Q1-17,ゲーム内テキスト，特にキャラクターのセリフを効率的に文字起こしする方法について，4 つのゲームを対象に Google  Cloud  Vision の OCR 認識精度を比較した．比較は，テキストのレイアウトおよび解像度の観点から行い，誤認識パターンの分析も実施した．その結果，記号類の認識が弱い傾向が見られるものの，全体的に精度が 0.88～0.99 と，情報抽出に大きな影響はないことが判明した．ただ，極端に短い文の場合には別言語や類似文字への誤認識が発生する傾向が確認された．また，レイアウトが固定されていないゲームでは精度が相対的に低く，低解像度の古いゲームでは濁点の欠落や一部の文字が飛ばされて認識されない事例が観察された．
Q6-22,日本と韓国の肥満率は，先進国の中でワースト 1位，2 位である．過度なやせは摂食障害をもたらすことがある．摂食障害は，身体面，心理面，行動面への治療が必要であり，数ヶ月から数年の時間を要するといわれている．本研究では，日本と韓国を対象に，摂食障害とダイエットのソーシャルメディアテキストを収集し，分類した．そして，摂食障害やダイエットに関連する言語的特徴は，文化間（日本と韓国）でどのように異なるのかを調査した．結果としては，日本と韓国による言語的な文化差がみられ，2 言語のテキストを活用した方が性能が僅かに向上した．
Q10-15,関係抽出における LLM を用いたデータ拡張において，生成されたデータを評価するための指標と拡張データを利用する学習手法について提案する．具体的には，生成されたテキストの正しい関係トリプルの内容の保持と多様性の評価のため，元の訓練データのテキストと生成されたテキストの比較方法について検討・比較を行う．また，拡張データと訓練データの分布の違いによる悪影響を抑えるために拡張データと訓練データを順に学習に利用する手法について提案する．DrugProt データセットを利用した実験では，拡張データの違いが抽出性能に大きく影響することと提案した学習手法によって拡張データによる悪影響を抑えられることを確認した．
P10-15,近年，大規模言語モデルの性能向上に伴い，対照学習（contrastive learning）を活用した誤生成抑制の手法が注目を集めている．本研究では，人間の「失敗から学ぶ」学習プロセスを模倣し，対照学習において誤りをあえて一度強化してから修正を行う新たな学習手法を提案する．具体的には，通常の正例データと負例データに加え，負例データの誤りトークンをあえて「正例扱い」するデータを作り，一時的に誤りを増幅させてから再度誤りを強く抑制する学習ステップを導入する．これによりモデルが誤りを深く認識し，修正効果の向上を狙う．OpenDialKGを用いた対話生成タスクの実験では，提案手法が従来の対照学習よりも高い性能を示すことを確認した．
P7-1,大規模言語モデル(LLM)は様々な生成タスクで用いられ、高い性能を示すが、一方で hallucination と呼ばれる入力文章と矛盾する情報や入力からは事実性が検証不可能な情報を出力することが問題になっている。様々な hallucination 検出手法が提案されているが、その精度はまだ十分でなく、さらなる改善が求められている。本稿では、hallucination を含む出力が入力文章にない情報や推定困難な情報を含む点に着目する。この特性から入力文章と hallucinationを含む出力ではそれぞれの埋め込み表現が乖離すると仮定し、対照学習を用いて hallucination 検出器を訓練する手法を提案する。実験の結果、提案手法はベースラインよりも hallucination 検出精度を大幅に向上させることが示された。
D3-4,本研究では、俳句創作において生成 AI による、どのような学習支援が可能なのかを事例をもとに明らかにすることを目的とし、AI を活用した俳句創作の具体例を示しながら、俳句創作における AI の学習支援の可能性と課題について検討する。その結果、AI による俳句創作を学習支援として成り立たせるには、創作者自身の発想を刺激させる問いかけを含む「対話型」支援が必要であることは示されたが、先行研究同様、俳句の評価に関する課題は残った。
Q3-12,大規模視覚言語モデル（LVLM)は言語情報に加えて視覚情報も扱うことができる言語モデルである。一般的に LVLM は、視覚と言語の両方を同時に扱うようなタスクで用いられることが前提とされているが、言語情報のみで解決可能なタスク（言語タスク）に限定して使用することも可能である。ただし、LVLM の構築過程では画像情報と整合が取られているため、視覚情報が追加的に与えられる状況において、その画像がタスクに密接に関連する場合だけでなく、逆に敵対的であったり無関係であったりする場合に応答がどのように変化するのかは明らかではない。本研究では、心理学的効果検証の一種であるプライミングを参考に、LVLM を用いて言語タスクを解く際に、視覚情報を追加的に挿入することで言語タスクへの影響を調査する。実験の結果、言語タスクにおいて視覚情報を追加することで、精度と確信度の両方に変化が観測され、LVLM でもプライミング効果を確認でき、LVLM が言語タスクを扱う際でも視覚情報の影響を受けることが明らかとなった。
P1-7,"最小ベイズリスク復号 (Minimum Bayes Riskdecoding)は,自然言語処理のテキスト生成において効果的であることが知られている手法である.この手法は基盤となる人間の嗜好確率分布に基づく期待効用を最大化することを目的とし,出力選択を行う.先行研究における実験的評価ではこのアプローチが顕著な成功を収めていることが示されているが,これらの手法が有効に機能する原因については未だ解明されていない.本研究では最小ベイズリスク復号が何故高い性能が得られるかを明らかにすることを目的として,その理論的な性能を分析する.分析の結果として,いくつかの仮定の下,最小ベイズリスク復号の誤差が計算に用いる参照仮説集合の大きさ𝑛に対して高い確率で𝑂(1√𝑛)に収まることが示された."
D5-2,仮に人間がランダムに parsing action をとる言語理解をしていたならば、どんな階層構造を取っても理解できるような頑健な記号体系が作られていた可能性もあるが、人間の parse 戦略がそうなっていないのはなぜだろうか？実際に、階層的なバイアスを持つモデルによる言語創発の先行研究では、メッセージをランダムに parse する、人間の言語理解と乖離した戦略をとるエージェントのコミュニケーション精度が高くなることが報告された。本研究では、(I)ランダムな parse 戦略では意味の理解が難しくなるような、階層的構造を持つより複雑な入力を用いる、(II)言語の単語や文字の順序に影響を与えるとされる surprisal に関する項を目的関数に組み込む、というシンプルで自然な変更を実験設定に加え、ランダムな parse 戦略を取るエージェントのコミュニケーション精度がどうなるか、検証を行った。
B6-1,生物学的プロセスなどのエンティティは、医学生物学文献内で常に明示的に言及されているとは限らず、しばしば専門知識の共有を仮定して暗黙的に言及される。本研究では、医学生物学文献からのオントロジー自動構築を目指し、プロセス抽出と文書レベル関係抽出の二段階からなるメンション非依存型情報抽出システムを提案する。提案システムでは、一貫してメンション表現に依存せず、入力文書に対して対象オントロジーに紐づいたプロセスエンティティ集合の抽出とエンティティ間関係の同定を可能にする。新たなベンチマークデータセットを構築し、BERT ベースまたは LLM ベースのメンション非依存型アプローチを提案し、評価と比較を行う。
P3-17,近年，大規模言語モデル（LLM: Large LanguageModel）は発展の一途を辿ってきたが，これまで日本語の国語問題，特に大学入学共通テストのような全国試験レベルの問題に LLM を用いて取り組む研究は十分に行われてこなかった．本研究では，この課題に取り組むため，複数の LLM を用いて大学入学共通テスト試行調査の国語科目における答案を作成し，採点ガイドラインに基づいてその答案を評価する．また，Retrieval-Augmented Generation（RAG）手法を活用し，答案生成の手法を検討する．この際，再検索プロセスを考慮した手法を取り入れることで既存の RAG 手法を改良し，生成される答案の精度や一貫性の向上を目指すとともに，単純な LLM での生成との違いを調査した．実験の結果，再検索プロセスを考慮した RAG 手法を用いることによって，より採点条件を満たした答案を生成できるようになることを確認した．
P4-22,本研究では，分類語彙表の基本義を活用した日本語メタファー検出手法を提案する．メタファーは言語の認知的およびコミュニケーション機能において重要な役割を果たしているが，その自動検出には文脈内での表現の意味理解が必要となる．既存のメタファー検出モデルは主に英語を対象としており，日本語に特化したモデルは限られている．提案手法では，日本語 BERT をベースに分類語彙表から得られる基本義情報とその用例文を活用し，対象単語の文脈的な意味と基本義の文脈的な意味を比較することでメタファーを検出する．基本義には，山崎らが作った基本義を利用する．また，手法には BasicBERT を基本として利用し，基本義の用例はBCCWJ から取得する．本研究では，分類語彙表の基本義を活用した既存手法の日本語への効果的な適用により，日本語の比喩抽出を行った．評価はBCCWJ-Metaphor コーパスを用いた 5 分割交差検証により行い，高精度な日本語メタファー検出の実現を目指す．
C9-6,RAG に基づく質問応答システムによる応答の正確性を自動評価する方法を提案する。特徴は、知識ベース中のコンテキストを、質問、正答例と同時に考慮して、生成回答を LLM で評価する点である。特にコンテキストの選び方に工夫を施す。また、マルチターンの質問応答における連続応答の性能を測るための評価観点を導入し、この観点での評価を自動化する。その後、人手評価との相関、および、連続応答性能の差の検出に基づいた評価実験を実施し、これらの提案手法の有効性、実効性を確認する。
P3-5,本研究では，看護師国家試験問題における誤答選択肢の自動生成に大規模言語モデルを活用する．生成には日本語大規模言語モデルと，API を通じて利用可能なモデルをそれぞれ複数用い，過去の試験や予備校の模擬試験の問題をデータセットとして出力の制御を行う．生成した誤答選択肢を選択肢候補として看護師国家試験問題作成経験者に提示し，実際の問題作成における負担軽減や効率改善への寄与を分析した．その結果，大規模言語モデルによる誤答選択肢は有用であり，作問作業の効率改善の可能性が示された．
B4-3,本研究では、日本語生成モデル llm-jp-3-13B-instruct に構造化 Pruning を適用し、失語症の言語症状の再現可能性を検証した。結果、高頻度語が低頻度語よりも復唱タスクにおいて高い正答率を示し、失語症者に見られる高頻度語保持の傾向と一致する可能性が示唆された。また、層ごとの Pruning が出力に与える影響を目標語と出力語のコサイン類似度にて評価した結果、一部のモデルで目標語との意味的類似性が観察され、意味性錯語に近い現象が確認された。これにより、LLM の Pruning が失語症者の発話特徴の再現や回復過程のシミュレーションに応用できる可能性が示された。本研究は、失語症の病態の機序解明やリハビリ手法の開発など、臨床応用できる可能性を示した点で意義深いと考えられる。
B4-2,"認知症の言語症状は患者の予後や QOL を規定するが,その発症メカニズムは未解明である.近年の言語モデルを用いた研究は,主に言語表出の分類に重点を置き,病因を直接的に検討するものは少ない.そこで本研究は言語モデルを生成モデルとして捉え,単語の出現確率を変化させるパラメータを操作することで,認知症特有の単語選択や言語構造の再現を試みた.結果として,係り受け距離や一部の品詞の頻度においては再現ができた一方,意味情報量の点においては認知症患者の言語表出とは逆の傾向が得られた.本研究は言語モデルを用いて認知症患者の言語表出そのものを再現することで,認知症の言語症状の発症メカニズムの解明につながると期待される."
D7-1,嘘をつき嘘を見破る会話ゲーム人狼の自動プレイ対戦を行う人狼知能コンテスト 2024 冬季自然言語部門開催概要を報告する。人狼ゲームでは一貫した論理的な会話を通じて他のプレイヤーの役割を推測し、説得する役割を果たすと同時に、雑談も混ざる特徴がある。人狼の自動プレイを通じて、大規模言語モデルの能力と限界が明らかになると期待する。
P3-4,本論では語彙学習を目的とした多肢選択式空所補充問題の作成のため生成 AI 等の技術を活用し，その性能を検証した．最初に英単語 300 語に対し，ChatGPT にプロンプトを与え問題文と錯乱肢を生成した．錯乱肢には人手で訂正の有無をアノテーションし，ChatGPT と Gemini を用いて自動訂正の可能性を検討した．結果として，問題生成については訂正が不要であった一方，錯乱肢生成では約 17.8%で訂正を要した．この結果を受けて，生成 AI の錯乱肢の訂正能力を検証したところ，F1 値が最大 0.291となり，不十分な結果となった．提案手法として，予め準備した錯乱肢を BERT の確率により選別する方式を試した結果，訂正が必要な場合は 11.0%となり，生成 AI に対する優位性が明らかになった．
P4-23,本研究は，「あらゆる言語は等しく複雑である」という，いわゆる言語の等複雑性について，単位形式系列当たりの語義数とその出現確率の偏りを通して，言語の複雑性を計測を試みる．このために，BERT を用いたサブワードへの分割や分散表現を利用している．12 言語1）を対象とし，ランダムサンプリングした Wikipedia の 100 記事をデータとして，各言語につき 4 回の分析を行った．結果として，全体的には単位形式系列当たりの語義数に大きな差が見られなかった．一方で 4 回の分析に渡って，各言語はそれぞれ非常に近い値を示すことが多かった.このことから言語の複雑性は，非常に狭い領域に収ま理ながら，その領域内で各言語が特有の傾向を持つことが示唆される．
P3-16,本研究では、クラウドアーキテクチャ設計の複雑さを取り上げ、その設計支援システムとしてCloudArchitectBuddy（CA-Buddy）を提案する．CA-Buddy は要件と設計を状態として構造的に表現・制御することで設計の理解と一貫性を支援し、システムが主導的に検証と具体化を進めることでスムーズな設計作業を実現する．実務者による CA-Buddyと ChatGPT の比較実験の結果、設計品質は同等ながらも CA-Buddy は高いユーザー体験を示した．またフィードバックから、CA-Buddy の構造化された設計情報とシステム主導型の設計支援はチャット UIの柔軟な対話を統合することによってより効果的なクラウド設計支援ができる可能性が示唆された．
D5-3,如何にして対象の音声言語の音声データから，その言語において言語学的に妥当な文字記号の体系を機械に創り出させるか．この問いに答えるべく，本研究では深層ベイズに基づく機械学習手法を提案する．提案手法では，世界の言語の音素数の報告データをもとに，文字記号の種類数の弱情報事前分布を導入する．これにより，従来研究のように，文字記号の種類数に関する事前の仮定に無限や定数を無理に持ち出すことなく，対象言語が持ち得る文字記号の種類数を推定しながら，その言語の文字記号の体系を創出することが可能になる．実験により，提案手法の文字体系と人手で創られた文字体系に，従来手法と比較してより強い対応が示された．
P1-6,特許翻訳は，その専門性と厳密さから高い翻訳精度が求められる分野である．しかし，従来のTransformer ベースのニューラル機械翻訳(NMT)モデルでは，特許文特有の長文構造や複雑な書式に起因する訳抜けや繰り返しといった誤訳が発生しやすいという課題がある．さらに，近年急速に発展している大規模言語モデルの翻訳訂正能力については，特許翻訳における有効性が十分に検討されていない．本論文では，mBERT を用いたトークンレベルの誤訳検出と大規模言語モデル(LLM)を用いた訂正手法を組み合わせた手法を提案する．BLEU および COMET のスコアで評価を行い，提案手法が最も高い翻訳精度を達成し，誤訳や繰り返しの改善に寄与することが示された．一方で，訳抜け文の訂正においては，課題も確認された．
E8-6,"本研究ではアモーダル補完(amodal completion:AC)と呼ばれる現象に着目して大規模視覚言語モデル(Large vision language model; LVLM)の視覚的認識能力を評価した.ベンチマークの構築に上位オントロジーの一つである Basic Formal Ontology(BFO)を利用することでより体系的な評価を試みた.実験の結果,特に規模の大きな LVLM は全般的に人間に近い AC 能力をもつものの，人間と比較して，その能力には補完される対象の種類によってばらつきがあることが確認された．また LLaVA-NeXT モデルの一部については，基盤言語モデルのパラメータ数が大きくなっているにも関わらず正答率の低下が見られた.この結果は知覚動詞を適切に理解するという課題は基盤言語モデルのパラメータサイズを単純に増やすだけでは克服できない可能性を示している."
Q3-13,Large Vision Language Model (LVLM)は近年急速に進化しており、文書画像理解のタスクにおいても End-to-End で高い精度を達成している。一方で、GPT-4o クラスのモデルであっても画像内の文字認識誤りが発生することがあり、ビジネスでの実運用において課題となっている。本研究では、LVLM に文書画像内テキストを埋め込むことで、高精度な文書画像理解を実現することを目指す。既存の LVLMに文書画像内テキストをプラグイン的に埋め込む方式を提案し、その有効性を検証した。
D3-5,日常会話音声は，テレビなどで耳にするアナウンサーの発話とは異なり，非流暢性に満ちている．そのことから，合成音声に非流暢性を取り入れると，マシーンコミュニケーションがさらにリアルでインタラクティブになると考えられる．本研究では，まず日常会話音声データを，既存の AI による合成音声システムに学習させた．次に，同じ言語内容の非流暢性を加えた発話とそうでない発話を合成し，調査回答者にどちらがより人間味のある話し方かを尋ねた．その結果，非流暢な合成音声の方を，より人間味のある話し方だと判断する回答者の割合が優位に高かったことが明らかになった．
C10-6,大規模言語モデルを人間の意図に合わせるアライメントのためには、事後学習としてのSupervised Fine-tuning (SFT)が不可欠である。しかしながら、ベースモデルの種類や学習データの特性が下流タスクの性能に与える影響について、広範な検証はほとんど行われていない。そこで本研究では、複数の大規模言語モデルと多様な学習データを用いて全 245 種類の SFT モデルを訓練する。それらのモデルをさまざまな下流タスクで包括的に評価することで、先行研究で提案されてきた知見や定説を実証的に検証する。また、作成したすべてのファインチューニング済みモデルを公開予定である。
P10-14,"本研究では，ソフトウェア仕様書の品質向上を目的に，大規模言語モデル(Large  Language  Model,LLM)を活用した自動レビュー手法を提案する．本手法では Retrieval-Augmented Generation (RAG)を用いて，レビュー対象に関連する情報を取得し，レビュー観点毎に自動レビューを実行する．用語統一をレビュー観点とした実験を行った結果，性能に課題が残るものの，正しく指摘できる例もあり，知見が得られた．また，レビューの性能向上にはプロンプト内の表の形式を統一させることやレビュー対象に関連する情報を必要な情報に絞ることが重要であることが示唆された．しかし，他にも性能が低い要因があると考えられ，要因の特定は今後の課題である．"
Q10-14,近年、従業員等への健康投資を行うことで、従業員の活力や企業の生産性を向上させる「健康経営」に対する関心が高まっている。本研究では、健康経営度調査票内の「健康経営課題、それに対する施策実施の結果、効果検証結果」の文章を定量的に評価する手法を提案した。また、この評価スコアを利用して各企業の健康経営課題に対して適切かつ多様、なおかつ各企業の健康経営評価の改善に繋がるような施策を提案するレコメンドシステムを開発した。
Q6-23,大規模言語モデル(LLM)の高い文生成能力を活かすことで，データ拡張(Data Augmentation)による分類モデルの性能改善が期待できる．しかし，この手法でニュース記事の分類のような多値分類において精度を向上させた研究はまだ少ない．本研究では，ニュース記事を対象として LLM が生成したデータを訓練データに水増しすることで，分類精度が改善されるかを検証した．カテゴリーのキーワードを与えて新たな文書を生成するアプローチを試みたが，このアプローチでは精度が低下することが確認できた．また，拡張したデータの埋め込み表現を分析することで，元となる訓練データと異なる分布のデータが生成され，分類の際のノイズとなっていることが明らかになった．
Q1-16,"This study proposes a zero pronoun annotation schemethat is easy to adopt cross-linguistically, regardless of lan-guage types, due to its reliance only on raw corpus data andthe absence of prerequisites such as constituency trees orpredicate-argument structures. A spoken language Malaycorpus has been annotated using it. The results are com-pared to the distribution of zero pronouns in a Japanesecorpus, namely the NAIST Text Corpus."
B2-4,比較表現を含む自然言語推論(NLI)は，比較対象となる性質が成り立つ程度を文から読み取り推論を行う必要があるため，挑戦的なタスクである．このような推論を頑健に扱える推論システムの実現に向けて，合成的意味論に基づく論理推論システムが提案されている．しかし，日本語の比較表現に注目したシステムの開発は十分に取り組まれていない．そこで本研究は，形式意味論に基づいた日本語比較表現のための論理推論システムを提案する．提案システムの評価には比較表現を含む日本語 NLI データセットを用いる．既存の LLM との正答率の比較により本提案の有効性を示す．
Q6-8,本研究では，日本語の書き手が行う述語の項省略の適切さを，読み手側の視点に立った際に適切に指摘できるかという新しいタスクの設計を検討する．この設定は，項省略の可否を第三者の指摘に基づいて学ぶ学習支援システムの開発を見据えたものである．この問題設定を精緻に検討するために，我々は，読者側が得られる情報のみを用いて項省略の不自然さを指摘できるかについて，判断の要因になりうる複数の観点に基づく質問の回答をアノテーションするデータを作成し，結果を詳細に分析する．分析の結果，我々の設定した省略判断の観点の組み合わせによって，読み手の実際の省略判断を高い割合で説明できることが示された．
P5-2,Table Generation は，複数の要素を比較する際に有用な技術である．本研究では，観光地（POI）のレビュー情報を基に観光地間の比較表を自動生成する新しい手法を提案する．レビューから属性-レビューペアを抽出し，それを属性ごとに整理した情報を LLMs に入力することで，客観的要素と主観的要素を含む比較表の生成を可能にした．評価実験では，無作為なレビュー入力やレビューを使用しない手法と比較して，提案手法が優れた比較表を生成できることを確認した．本研究は，観光地選定を支援する実用的なアプローチを提示し，Table Generationタスクに新たな視点を提供するものである．
B10-3,反語文は，疑問文の統語形式をとりながら，意味的には関連の陳述命題を断言する構文である．本研究では，反語文の陳述命題が会話の共通基盤に格納されるやり方は，言語によって異なっていると主張する．英語では陳述命題は前提として組み込まれるのに対し，日本語では会話の共通基盤の最上段の文脈に組み込まれる．さらに，中国語では，書面語は英語と同じように前提として処理され，口語では日本語と同じように共通基盤の最上段の文脈に組み込まれる．この格納方法の違いは，反語文における否定極性成分の認可の可否と反語文の陳述命題を後続文脈で指示できるかどうかに反映されている．
A9-2,パターン翻訳は，古典的な機械翻訳の方法である．従来，文パターンは，人手で作成される．しかし，簡単な文パターンは，単語辞書を利用して，自動的に作成可能である．そして，NMT において翻訳精度を向上させるため，学習データに文パターンを加える方法がある．しかし，翻訳精度は，ほとんど向上しない．この原因として，文パターンの作成方法に問題があると考えた．そこで，対訳単語の対偶を考慮して文パターンを選択して，学習データに加えた．作成した NMT の翻訳精度を評価したところ，文パターンの選択前と比較すると大幅に向上した．
P1-13,言い換えと翻訳は，同一言語と他言語の違いがあるが，意味が同じ文章を生成する点において同一の処理とみなせる．そこで，１つのシステムにおいて，言い換えと翻訳が同時におこなうシステムを構築することを試みた．そのとき，以下の概念を組み込んだ．最も精度が高い言い換え文は入力文である．つまり，入力文と出力文が同一のとき，もっとも精度の高い言い換えになる．翻訳は言い換えの一種である．この概念から，対訳学習文に，”（ソース）入力文：（ターゲット）入力文”を追加する．その結果，高い精度で，言い換えが得られた．また高い精度の翻訳が可能になった．
Q8-7,大規模言語モデル（LLM）の様々な分野での応用が広がる中，専門知識を要する学術ドメインでの活用は難しい課題である．特に，日本語の学術ドメインにおける LLM の開発は未だ発展途上である．本研究では，LLM が生成した QA データを活用し，学習と自動評価を統合したフレームワークを提案する．まず，学術論文を対象とした合成データセットを作成する．次に，そのデータセットを用いて LLMをチューニングし，学術的な文脈での質問応答能力を強化する．さらに，LLM による自動評価手法により開発したモデルの性能と有効性を検証する．
P8-23,Information Retr ieval を始め，様々な用途で分散表現を用いた研究や製品が開発されており，高性能な分散表現モデルへの需要は日々高まっている．本研究では，日本語の多様なタスクに対して効果的な分散表現作成モデルを構築した．作成したモデルの検証結果から，学習データとして様々なタスクのデータが分散表現モデルの学習に効果的なこと，英語に関するデータが日本語向け分散表現に効果があることが確認できた．
P6-18,"大規模言語モデル（LLM）は自然言語処理で高い性能を示す一方，多様な文化的背景への対応には課題がある．本研究では，日本語コーパスで学習された LLM を活用することで，日本文化知識データベース NINJA を構築した．NINJA は，既存の文化知識データベース MANGO が持つ日本文化に関するデータと同数の 4,597 件生成し比較した結果，データの多様性を示す指標である Self-BLUE が 0.787 から 0.350 に改善した．さらに，日本の文化的背景への理解が必要な常識道徳推論タスクに対して，NINJA を外部情報として組み込んだ RAG（RetrievalAugmented Generation）システムを構築し，日本文化に即した推論における有用性を検証した．"
P1-11,同時通訳では，原発話の語順を極力維持して訳出することで遅延を抑制する，順送り方略がよく用いられるが，オフライン翻訳では，流暢さを優先して原発話と語順が大きく異なる訳出がされることがある．オフライン翻訳を参照訳とする従来の評価手法では，同時機械翻訳モデルが出力する同時通訳らしい語順の訳出を十分に評価できていない可能性がある．そこで本研究では，語順差が大きい英語・日本語間のオフライン機械翻訳，および同時機械翻訳モデルを順送り訳データを用いて評価した．順送り訳データで同時機械翻訳モデルを評価すると，オフラインデータセットで評価したときに比べて高いスコアとなり，同時機械翻訳の自動評価で語順を考慮することの必要性が示唆された．
P8-21,スキルマッピングは職務記述書や履歴書中の文で言及されるオントロジーで定義されたスキルを特定する作業であり労働市場の分析に不可欠である．詳細な分析に必要な細分化されたスキルが付与された学習データを人手で構築するのは高いコストなため既存研究は Large Language Model (LLM)が生成した合成データが bi-encoder の学習に用いる．合成データを活用したさらなる精度改善のため，提案手法(𝑘NNBE)は推論時に学習に利用したラベル付き合成文を𝑘-nearest neighbor (𝑘NN)によって取得し入力文との類似度を bi-encoder のスコアに加える．実験により𝑘NNBE は bi-encoder の精度改善，さらに既存の最高精度を示す LLM でスキルをリランキングする手法と比較して高いスループットを維持しながら精度改善を確認した．
Q8-5,バイト符号化を用いた日本語マスク言語モデルの開発における知見と学習したモデルの分析結果について報告する．本論文前半では，モデルアーキテクチャ・学習戦略の探索を行い，大規模言語モデルで用いられるアーキテクチャは，バイト単位マスク言語モデル構築時においても有効であること，マスク率は 50%が最適であることを確認した．後半では，学習したバイト単位マスク言語モデルの表層的な類似に対する頑健性及びモデル内部での複合化過程を分析した．学習したバイト単位マスク言語モデルは，表層的な類似に対して頑健であり，モデル内部での複合化はモデルの初期及び最終層付近で行われていることを確認した．
B10-1,新旧のコーパスから得られる対象単語の文脈付き単語埋め込みの集合を比較することで，時代の経過に伴う単語の意味変化を検出できるようになった．ただし既存手法は，対象単語の意味が全体としてどのくらい変化したかを測るものであり，個々の使用事例に踏み込んだ分析には至っていない．本稿では，新旧コーパスにおける文脈付き単語埋め込みの集合の間に不均衡最適輸送を適用し，使用事例間のアラインメントの過不足に注目することで，語義の消失・出現を自然に定式化できることを示す．特に，対象単語の使用事例ごとに，その事例における語義での単語使用頻度の変化を測る Sense UsageShift (SUS)という量を導入する．SUS を用いることで，使用事例ごとの意味変化の定量化が可能であることを，評価実験を通して示す．
D1-5,近年，数多くの SNS が存在する中で X（旧 Twitter）を対象とした皮肉判定の研究が活発に行われている．日本語の皮肉分類器の性能向上を図る手段の一つとしてデータ増強の適用が考えられるが，皮肉表現はその特性上，文章内の特定の単語を置き換えるとたとえわずかな変更であっても元の皮肉性が失われ，皮肉でなくなる（分類ラベルが反転する）可能性がある．本稿では，データ増強の際にノイズを加える箇所を Transformer の Attention を用いて選定するという，皮肉判定に特化したデータ増強を通じて皮肉分類器の性能向上を図る手法を提案する．本手法は既存手法や GPT を用いたデータ増強手法と比べ，正解率，F 値にともに高い性能を示した.
B2-6,本発表では、情報構造に関する類型論的研究に向けた談話データのコーディング作業の概要と、その作業の課程で認識された理論的な問題点を報告することを通し、情報構造の研究のための談話資料のあるべきコーディングについての議論を行う。
Q8-24,本研究では、大規模言語モデル（LLM）の連合学習における LoRA の統合数がモデル性能に与える影響について検証する。LLM に基づく連合学習の多くは、複数のクライアントがローカルデータを用いて LoRA を学習し、その重みを統合することでグローバルモデルを構築する。しかし、LoRA の統合数が増加するにつれ、モデル性能の低下が予想されるため、その定量的評価と原因の解析が必要である。本研究では、データ分布が同一であることを仮定し、テキスト要約タスクおよび数学的推論タスクを対象に実験する。その結果、LoRA の統合数が増加するにつれてモデル性能が低下する傾向が観察された。特に数学的推論タスクでは、統合数の増加によって正解率が顕著に低下した。これらの結果は、従来の統合手法である FedAvg が LoRA 重みの統合において性能劣化を招くことを示しており、統合手法の改善が求められることを示唆する。
Q1-14,テキストに含まれる地理情報の解析技術は，観光・防災支援などの応用に有用である．本研究では，日本語旅行記の英訳とアノテーションにより，日・英 2 言語の地理的解析・生成タスクのデータセットを構築した．基本的な 3 タスクにおいて，言語（日・英）および地域（国内・海外）の観点でシステムの性能評価・分析を行った．
P10-16,本研究は，Bloom [1]が提案する情動的共感と認知的共感の二軸を用いて，既存の対話コーパスに共感に関するアノテーションを付与した．アノテーション手法の検討においてクラウドソーシングと GPT-4o による自動アノテーションを比較したところ，後者の方が評価用に作成した人手によるアノテーションとより高い一致率を示した．このGPT-4o によるアノテーションを用いて対話モデルの学習を行い，共感を制御した応答生成を評価した結果，ベースラインモデルを大幅に上回る精度を達成した．
Q8-18,近年の大規模言語モデル(LLM)の発展により，様々なドメインに特化した LLM の研究が進んでいる．ドメイン特化 LLM を下流タスクに用いる場合，タスクのラベル付きデータで教師ありファインチューニングする前に，そのドメインの知識獲得を目指し，特定ドメインの生テキストを用いた継続事前学習が先行して行われることがある．しかしながら下流タスクのデータ量に着目した継続事前学習の有効性については不明な点が多い．本研究では新聞ドメインにおける見出し生成タスクを対象に，ドメイン特化を目的とする継続事前学習と下流タスクのデータ量が性能に与える影響を分析する．分析の結果，下流タスクのデータ量が極めて少ない状況では継続事前学習の効果が大きい可能性が示唆された．
Q6-21,同じ発話文でもパラ言語情報が異なれば，与える意図やニュアンスが異なる．音声対話システムが持つこれらパラ言語情報処理能力を測るため，パラ言語情報の特に感情に着目した Speech-to-Text 対話ベンチマーク「paraling-data」を提案する．同じ発話文にパラ言語情報のみが異なる発話を収集し，それぞれのニュアンスに対応する応答を収集した．また，テキスト対話システムと Speech-to-Text 対話システムを構築し，感情ラベル予測を補助タスクとした対話応答生成を学習し評価した．
Q10-16,"村田ら[1],野田ら[2]は情報整理の一環としてWeb 上の複数の関連した文章から表を生成していた.これらの研究での表の評価として,予め用意した正解の表との類似性で自動評価を行っていたが,出力された表の構造が正解のものと異なる場合,実際の表生成の性能を正しく評価できないと考えられた.本稿の研究では,より信頼性のある評価を目指し,人手で評価をした.村田らと野田らの単語ベクトルと ChatGPT を使用した手法をそれぞれ評価したところ,自動評価では単語ベクトルの手法のほうが性能が高かったが,人手での評価では ChatGPT の手法のほうが高くなった.人手評価の単語ベクトル, ChatGPT の手法の性能はそれぞれ 0.79, 0.90 であった.また自動評価の問題である,正解と出力の表の構造が異なる点について,調査をしたところ,実際に評価に影響を及ぼしていることがわかった."
C10-4,Meta の Llama-3-8B をベースに、バイオ医療ドメインに特化し 3 ヶ国語（英日中）に対応した大規模言語モデル ELAINE (EngLish-jApanese-chINesE)-medLLMを提案する。本 LLM は多様で大規模な 3 ヶ国語のバイオ医療分野のコーパスを用いて継続事前学習を行い、医療ドメインの QA データセット用いた教師ありファインチューニング(SFT)により学習した。3 ヶ国語に対応した医療分野の QA ベンチマークによる評価から提案モデルはベースモデルの英語性能の劣化を抑制し、既存の 2 ヶ国語あるいは多言語のmedLLM と比較して各言語で優れた性能を示すことを確認した。
Q4-8,回路設計を行う企業では，すでに設計した回路図が存在する一方で，新たな回路設計の際に，それまでの設計知識を活かした設計は人手により任されている．近年，大規模言語モデル(LLM)は記号列である言語の生成を文脈まで反映した形で実行することが可能になってきている．そこで，本論文ではLLM を利用した回路生成についての第一段階の研究成果を報告する．回路生成には素子間の結合と配置の問題があるため，本稿では素子間の結合に焦点をあて，回路を表現する言葉から素子と素子間の結合をあらわすnetlistを生成させるタスクを設定して回路生成の可能性について小規模な実験を実施した．実験の結果，現段階では生成がむずかしいことを明らかにする．
P7-2,近年，科学論文執筆支援技術の研究が進み，科学論文における関連研究セクションの自動生成が試みられている．関連研究セクションの自動生成を構成する技術の一つに，与えられた引用論文と作成対象の論文との関係性を考慮しつつ，引用論文の内容を簡潔に表現した引用文を自動生成する引用文生成技術がある．近年の引用文生成技術では，大規模言語モデル（LLM）が用いられることが増えているが，事実と異なる文章の生成（ハルシネーション）が課題となっている．本研究では，LLM による引用文のハルシネーション検出について，評価用ベンチマークデータを構築し，引用方法の観点から分析を行った．
Q3-11,本研究では，マルチモーダル大規模言語モデルを用いてロールプレイングゲーム（RPG）の画面から，選択対象のテキストを抽出する手法を提案し，その精度を検証した．テキスト情報を多く使用するビデオゲームのジャンルである RPG の自動プレイを機械学習モデルが行うには，画面に表示されたテキスト情報の処理能力が必要となる．本研究では，RPGの自動プレイに必要なサブタスクの一つとして，選択肢の提示された画面から，選択可能なテキストを行列形式で抽出する手法を提案する．また，データベースとの照合によるフィードバック手法を導入し，精度が向上することを確認した．
Q4-18,Transformer の事前学習済みモデルでは，各層の予測分布の意味的収束性が示される一方で，隠れ状態ベクトルの数値的収束性が確認されておらず，両者に乖離があることが問題である．本研究では，事前学習済みモデルに自己蒸留を適用し，隠れ状態ベクトルの数値的収束性を改善する．自己蒸留は，同一モデル内で深い層から浅い層へ知識を蒸留し，モデルの性能を維持しながら隠れ状態ベクトルの収束性を高めることが可能である．提案手法により，最終層付近での隠れ状態ベクトルの収束性が向上した．
Q4-24,特定のタスクのために BERT モデルをファインチューンする場合、最終層の出力の一部を選択し、新しく作成された全結合層に入力することが一般的に行われる。しかし、最終層のどの部分を選択すべきか、また、層の各次元がどのような情報を保持しているかは、よくわかっていない。本研究では、GLUE タスクに対する BERT のファインチューンを通じて、トークンに対応する最終層のベクトル、Transformer の層、ベクトルの次元について、有効性と冗長性を総合的に調査した。その結果、最終層はどのベクトルでも同等の情報を含むこと、ほとんどのタスクは 2-3 次元しか必要としないこと、上位層ではどの Transformer 層でもほとんど差がないことが示された。さらに、異なるタスクで順次ファインチューンを行うクロスファインチューンを実施した。その結果、ファインチューンにより隠れ層が大きく変化すること、複数タスクを同時に学習保持できる冗長性があることが示唆された。
E8-4,脳情報解読技術は，神経活動を解釈して思考や感情を再現する手法として注目されている．Tang ら(2023)[1]は，fMRI データを使用した，言語モデルを生成モデルとして活用する新たな解読手法を提案した．本研究はその拡張として，先行研究で用いられた GPT モデルに加え 3 種類の言語モデルを導入し，精度比較を行った．結果として，高い解読精度には，使用する言語モデルが脳活動の予測に優れていることだけでなく，言語モデルが生成するテキストの種類も重要である可能性を明らかにした．
P1-4,医療従事者の負担軽減を目的として，大規模言語モデル（LLM）を用いた SOAP ノート生成手法を提案する．提案手法は，SOAP 生成プロセスをSO 抽出タスクと AP 生成タスクの 2 段階に分割する．SO 抽出タスクでは，患者と医療従事者との対話文から主観的情報と客観的情報を抽出する．AP生成タスクでは，抽出された主観的情報と客観的情報からアセスメントと計画を生成する．さらに，Retrieval-Augmented Generation (RAG)を導入し，過去の SOAP データを参照することで LLM の医学知識を補完する．実験の結果として，論理的一貫性と安全性の配慮において高い評価を得られたが，臨床的妥当性と完全性においては課題が残った．
B6-2,本研究では、情報抽出パイプラインにおけるエラー伝播問題を軽減するための方法を提案する。エンティティの偽陰性問題(抽出漏れ)に対して、「オーバーサンプリング」を導入する。また、エンティティの偽陽性問題(過剰抽出)に対しては、「フィルタリング指向学習」を提案する。さらに、エンティティ曖昧性解消による間違った概念とメンションの紐づけの文書レベル関係抽出に対する影響を軽減するために、「概念対応」を導入する。複数ドメインのデータセットを用いた実験の結果、提案手法によって、情報抽出パイプラインのエラー伝播に対するロバスト性が向上することを確認した。
D5-1,我々には想像もつかないような帰納バイアスにおいて，想像もつかないような記号体系が最適であったかもしれないのに，構成性が言語の必然的な性質であると信じて良いのだろうか？この問いに答えるためには，言語の進化（文化進化）のみならず，人類の進化（生物進化）にも思いを馳せながら，構成性と帰納バイアスの関係を考察する必要がある．事例研究として，Echo State Network モデルがカオスの縁と呼ばれる超パラメタ領域において構成的な（高い TopSim スコアをもつ）記号体系に適合・汎化するバイアスをもつことを実験的に示し，構成的な言語が創発する必然性への傍証を試みる．
P3-14,自然言語処理技術を活用した医療支援が始まりつつあり，医療分野における AI の需要が上昇している．本研究では大規模言語モデル（LLM）の医療応用に着目し，医療プロセスの中でも AI による診断への応用可能性を探る．具体的には，曖昧な患者表現から病名を予測するタスクについて，複数 GPTモデル間の差異検証を行う．また，予測病名からICD-10 コードを階層的に推定し，その推定精度の検証を行う．結果，差異検証ではファインチューニングを行うことで，より正解病名に近い予測ができる傾向を確認した．また，予測病名が正解病名と一致しない場合においても ICD-10 コードを正しく推定可能なケースが存在することを確認した．
C9-5,"大規模言語モデル(LLM)の応用の一つに,検索エンジン最適化(SEO)の目的に沿った高品質な Webコンテンツ生成が挙げられる.本研究では,コンテンツの品質指標であるユーザ評価をターゲットとした LLM の調整(アラインメント)を行い,高品質かつ長文のコンテンツの生成を目指す. Google 検索により取得した Web コンテンツと,コンテンツに対しユーザ評価ラベルを付与したデータセットを利用して,指示チューニングと Direct Preference Optimization(DPO)によるアラインメントを行なった.評価の結果,生成コンテンツの質と長さの両面で改善が確認できた."
P4-21,大規模言語モデルが人間らしい言語的なふるまいを示すようになってきたことを受けて、言語モデルから人間の言語について何らかの示唆を引き出そうとする研究が増えてきている。他方、言語処理のメカニズムが言語モデルと人間とで大きく異なることを根拠に、この手の研究の妥当性が疑問視されることもある。本稿では、この議論の文脈に、科学哲学における「多重実現」という考え方を導入する。本稿は、この考え方を導入することで、この種の研究手法の妥当性を評価する際に考慮するべき、哲学的・概念的な論点を浮き彫りにすることを目指す。
P3-6,本研究は，日本語学習者のエッセイ評価と言語的特徴量の関係性について，さらなる検討を試みたものである．従来，英語教育の分野では L2 学習者によるエッセイ評価と関連する言語特徴量が盛んに研究されている一方，日本語教育分野においては言語特徴量と評価との関連性があまり盛んに議論されていない．そこで本研究では，学習者日本語エッセイ評価に有効な言語的特徴量についてより深く検討・提案し，その評価に対する有効性を示すことを目的とした．分析では 13 の言語的特徴量を扱い，それぞれの特徴量が学習者の習熟度予測へどれほど寄与しているかを検討した.結果，一文あたりの用言数が最も有効な特徴量であることや，内容語 Guiraud 値や機能語 Guiraud 値も一定の説明力を示すことが示された．さらに，副助詞や接続助詞，格助詞の数などの機能語の数も詳細な条件として機能していることが明らかとなった．
D7-3,"本研究では,人狼エージェントにおいて,事前に定義された戦略を他者の態度や会話状況に応じて切り替えることで,パフォーマンス向上を図る手法について述べる.従来のプロンプトエンジニアリングを用いた人狼エージェントでは,あらかじめ有効な戦略を明示的に指定する手法が存在したものの,状況に応じて変化させるものはなかった.本研究では,他者の発言内容や役職の推定結果に基づき,戦略プロンプトを動的に切り替える手法を提案する.評価実験では,従来手法や固定戦略を用いたベースラインと比較し,勝率の向上を検証する．"
D7-2,大規模言語モデルが未だ苦手とする推論などの複雑な問題への対応を目指し、推論が求められる人狼ゲームを題材に、GPT-4 を基盤とした人狼ゲームエージェントを開発し、明示的な論理構造を組み込む手法を提案する。その結果、論理情報を提示する手法は提示しない手法と比較して推論精度が向上し、主観的評価においても優位性が確認された。
B4-1,"近年の計算心理言語学では、アテンションの人間の記憶想起のモデルとしての妥当性が検証されている。しかし、Transformer のアテンションが扱う表現の単位はトークンであるのに対し、伝統的に計算心理言語学では人間の文処理は統語構造の構築を伴うとされてきた。本研究では、統語構造を表現単位として扱う Transformer (Transformer Grammar, TG)のアテンションが、人間の記憶想起のモデルとして妥当なのかを検証する。結果、TG のアテンションはTransformer を上回る読み時間の説明力を達成し、アテンションの記憶想起アルゴリズムとしての妥当性を裏付けるとともに、統語構造を表現単位として想定することの重要性を示した。"
P3-7,"In this work, we explore how to leverage the meta-linguistic knowledge of large language models (LLMs) bycombining rule-based techniques with few-shot prompt-ing to produce new sentences in Indigenous languages,despite the LLMs having little to no prior knowledge ofthe language. Integrating rule-based preprocessing forBribri signiﬁcantly improves accuracy―over six times theedit-tree baseline and twice that of few-shot prompting―while a simpliﬁed version enhances performance for Mayaand Guarani. This research provides a generalizable so-lution for addressing linguistic challenges in low-resourcesettings through combining structured linguistic resourceswith LLM meta-linguistic capabilities to support languagerevitalization and preservation.1）"
C9-4,視覚的に表現された文書から成るコーパスを知識源に持つ新たな検索拡張生成（RAG）フレームワークである VDocRAG を提案する．VDocRAG は多様な文書を画像形式で統一的に理解することで，視覚的文書に含まれる図や表などの視覚情報を直接利用できる．VDocRAG の性能向上を目的として，大規模視覚言語モデルを検索タスクに適応させる新たな自己教師あり事前学習タスクを提案する．更に，多様な文書形式を網羅するオープンドメイン視覚文書質問応答データセットである OpenDocVQA を導入する．実験により，VDocRAG は従来のテキストベース RAG を大幅に上回る性能を示し，優れた汎化能力を有することが確認された．
P4-20,大規模言語モデル（以下 LLM）の行う処理について、どのようにすれば理解可能な説明が与えられるか。LLM では処理のブラックボックス性が指摘されており、ベンチマークによる評価では処理機構が必ずしもわからず、出力の説明性が低い。本論文ではこの点を問題とし、それを解決する手段として科学モデルの概念が有用ではないかと指摘する。その上で、科学モデルが現象の理解をもたらす条件を確認し、どのようにすれば LLM の行う処理について理解可能な説明が与えられるかを考察する。
P3-15,本研究は，アミロイド PET やタウ PET など経済的・身体的負担の大きい早期アルツハイマー病の検査の代替として，雑談を含む自由会話音声から早期アルツハイマー病を識別する手法を提案する．具体的には，自由会話音声とそれを書き起こしたテキストを HuBERT と RoBERTa を活用して音声・言語特徴量を特徴抽出器として用い，識別を試みた．その結果，特徴抽出器に高齢者音声や認知障害特有の音声を学習させることにより，従来手法である音響的特徴量を用いた手法と比較して，F 値で 8%，正解率で 7%上回る精度で正常群とプレクリニカル AD 群を識別できることが示され，自由会話音声からの早期アルツハイマー病の予測への応用が期待できる．
B6-3,大規模言語モデル（LLM）に、新たな知識を追加学習によって取り込むことは、いまだ困難なタスクと言われている。近年は RAG のように外部情報を参照する手法が注目されているが、この手法においては、LLM 内部に蓄積された膨大な知識と新たな情報を統合し、高度な推論を行うことは依然として難しい。本研究では、LLM が自己学習を行う手法や、DPO（Direct Preference Optimization）による選好最適化手法から着想を得て、LLM に新規知識を効果的に埋め込む枠組みを提案し、その有効性を検証する。
P1-5,大規模言語モデル（LLM）の意思決定特性を理解することは、人工知能技術の発展において重要な課題となっている。本研究では、行動経済学の基礎理論であるプロスペクト理論の枠組みを用いて、LLMの意思決定パターンを実験的に検証した。実験結果は、LLM の意思決定特性が人間とは異なる独特のパターンを示すことを明らかにした。具体的には、損失領域においては人間の意思決定に近い特性を示す一方で、利得領域では極端に歪んだパターンを示した。これらの結果は、LLM が人間とは質的に異なる意思決定メカニズムを持つことを示唆しており、LLM の意思決定特性の理解と制御に重要な示唆を与えるものである。
E8-5,"Zero-shot in-context learning allows large languagemodels (LLMs) to perform tasks using only instructions,yet calibration issues often limit their performance in zero-shot machine translation (MT). These issues result in prob-lems like hallucinations and oﬀ-target translations, reduc-ing output quality. This paper introduces ﬁxed preﬁx pairbootstrapping, a method that enhances zero-shot MT byinitializing translations with a correct bilingual preﬁx pair,guiding the model to produce accurate target-language out-puts from the start. Evaluation across four model architec-tures and translation directions shows consistent, substan-tial improvements, highlighting this simple yet eﬀectiveapproach for advancing zero-shot MT performance."
Q4-25,"Instruction tuning signiﬁcantly improves the perfor-mance of LLMs in tasks such as sentiment classiﬁcation. Inthis work, we propose a simple yet eﬃcient instruction aug-mentation method which does not rely on any actual labeledsentiment instances. With just 240 pseudo-instruction in-stances, the proposed method signiﬁcantly improves thesentiment classiﬁcation performance across several LLMson 12 sentiment benchmark datasets, increasing scores by30 points and outperforming LLMs that utilize more com-plex instruction tuning methods by 5.1 points."
Q3-10,近年，大規模言語モデル(LLM)に視覚情報を統合した，マルチモーダル大規模言語モデル（MLLM）が注目を集めており，その応用範囲は急速に拡大している．しかし，日本ドメインに特化した MLLM を作る上で，英語のデータに比べて公開データが少ない課題がある．本研究では，高精度な日本語 MLLMを構築するためのデータセットの作成方法について検討し，実験を行った．構築したモデルは，日本ドメインの画像理解を問うベンチマークにおいて，他のモデルよりも優位な結果を示し，その有効性を実証した．
Q4-19,大規模言語モデルは多様な入力に対しても有用な回答を生成できるが，出力された回答の安全性に関する課題も指摘されている．特に日本語 LLM の研究開発では安全性に対する対策がまだ十分には進んでいない．本研究では日本語 LLM の安全性向上を目的としたチューニングを行い，特に有用性を損なわずに安全性を向上させる手法について検討する．さらに日本語 LLM の安全性を自動で評価するツールを新たに作成し，チューニングによる安全性向上を定量的に検証する．実験では，SupervisedFine-Tuning や Direct Preference Optimization を適切に組み合わせることで，安全性を効果的に向上させられることを確認した．
D3-6,採血を行うロボットの処置の精度に関する研究開発は実用化も始まっている。しかしながら、採血ロボットと患者のコミュニケーションに関する研究は十分ではない。現行のロボットは患者に対するインストラクションは行うが、口頭で行われている異常感覚やしびれの有無など、患者の感覚の確認をロボットが自律的に行ってはいない。これを実現させるための研究の手法に関する提言を行う。採血ロボットに求められるコミュニケーションスタイルの研究のためには①対ロボットと対人の違い、②医療従事者、医療消費者という立場の違い、③いわゆる文化的な違い、国や地域による違い、それぞれに焦点をあてた研究が必要であることを述べる。
P7-3,"大規模言語モデルを用いた質問応答システムが広く注目されているが,生成される回答にはさまざまなバイアスが生じることが指摘されている.本研究では, LLM が In-Context Learning(ICL)における例示の与え方によって引き起こすバイアスに対し,キャリブレーション手法と Retriever-AugmentedGeneration(RAG)が与える影響を検証する.特に,与えた ICL 例示によってモデルの予測が大きく変動する問題を ICL 依存問題と定義し,それらを選択的に補正するキャリブレーション手法を提案した上で,RAG との併用効果を評価した.実験の結果,従来手法よりも効果的に ICL によるバイアスを抑制し,特定条件下では精度でも従来手法を上回ることを確認した."
C10-5,大規模言語モデル(LLM)の事前学習中に損失関数値が突然発散してしまう損失スパイクが LLM 事前学習の課題である．本研究は，パラメータのノルムに対するパラメータ更新量のノルムの相対値であるパラメータの更新比率がモデル内で不均一であり，この不均一性が損失スパイクの一因であることを指摘した．本研究は，全てのパラメータにゲートパラメータを導入し，共通の標準偏差によって初期化することを提案した．提案手法が，13B モデルのLLM の事前学習においてモデル内の更新比率を均一化し，損失スパイクを抑制することを確認した．
Q4-9,自然言語理解タスクのデータでは，ショートカットと呼ばれる，ラベルと擬似相関をもつ単純な特徴量が存在することがある．擬似相関はデータ分布の変動に対して頑健でないため，ショートカットへの依存は分布外データでの性能低下につながる．先行研究ではショートカットに依存しないモデルの学習が目標とされてきたが，この学習には実用上大きな困難が伴う．本研究ではこの学習を直接の目標とせず，それぞれ異なる潜在特徴量に基づいて予測するmixture-of-experts モデルをルールにより悲観的に統合することで，頑健に予測する手法を提案する．実験により，実用的な設定において先行研究を上回る分布外性能を示すことを確認した．
Q10-17,LLM を用いた交通分野における新しい固有表現抽出データセットの自動構築について提案する．既存の FindVehicle は 15 種類の限られたテンプレートに固有表現を置換して作成されており，実際の交通状況で見られる多様な表現を十分にカバーしていない．そこで本研究では，FindVehicle で利用された固有表現辞書を活用し，大規模言語モデルにより固有表現を含む文を生成することで，より自然で多様なデータを作成する．生成データの品質を人手で検証し，FindVehicle のみでは対応できない多様な文脈に対する固有表現抽出を実現した．
Q6-20,本稿では、『国語研日本語ウェブコーパス』（NINJAL Web Japanese Corpus: NWJC）の全データ（whole-NWJC）について概説する。本データは、国立国語研究所との共同研究を通じて利用できる。
P10-17,TRPG のゲームマスターにはプレイヤーからの要望に応えるための柔軟な応答が要求される．このような自由度の高い対話の実現はこれまで困難であったが，大規模言語モデル(LLM)の登場によりその可能性は飛躍的に向上した．本研究では，LLM のゲームマスターとしての能力を評価し課題を分析する．また，応答の質を向上させるため複数エージェントを用いてフィードバックを行い応答を改善する手法を提案し，その有効性を検証する．
Q8-19,近年、大規模言語モデル(LLMs)の各パラメータの重みを二値や三値に量子化することで、推論時のメモリ使用量を大幅に削減できることが報告されている。しかし、これらのモデルの学習には依然として多くのメモリが必要である。その理由の一つは、これらのモデルを学習する際に、Straight-ThroughEstimator (STE)に必要な、(量子化されていない)高精度の重み行列を保持する必要があるからである。そこで本研究では、学習時のメモリ使用量を削減するため、バックプロパゲーションにおいて STE を用いずに、量子化された低精度の重み行列を直接更新することを試みる。具体的には、確率的丸めを利用することで、低ビットの重みを用いる際に生じる情報の損失を防ぐ。LLaMA 構造の言語モデルを用いた実験の結果、低精度の重みのみでの学習が可能であることが明らかになった。
Q1-15,物語分析におけるセリフの話者推定は，物語の中で登場人物の心情変化や成長を分析していく上で重要なタスクである。しかし，話者推定は複雑な対話，発話パターンの多様性，および曖昧なキャラクター参照のような様々な要素が組み合わさっているため，データセットを人手で作成する場合、大量の作業時間と費用が必要になる．本研究では，大規模言語モデル（LLM）と少量の人手修正を組み合わせたラベル付けをすることで，効率良く高品質なデータセットを構築する手法を示す．実験では，人手でアノテーションした一部の少数の例を LLM に回答例として入力し，最小限の人間による修正を通じてデータセットを構築した．その結果，LLM は設定と話の展開が複雑な「三国志」という物語において約 90%の精度で話者名を正確に識別し，人手のアノテーションコストを抑えられることが示唆された．
D1-4,"文を単位とする言語現象を捉えるためには文分割(文境界認識)が必要となるが,実際に我々が扱うことが多い崩れたテキストには無数の文末表現があり,通常の教師あり学習で正しく分割することは難しい.本研究では,文分割をテキストの文字毎に存在する,二値潜在変数の推定問題ととらえる.セミマルコフモデルの枠組みで動的計画法と MCMC 法を組み合わせることにより,単純な文字𝑛グラム言語モデルを用いるだけで,最新の大規模言語モデルによるヒューリスティックな文分割を超える,最高精度の文分割を教師なし学習で行えることを示す."
P5-1,日本語において，語順や読点の使用法は比較的自由に書き手に任されるが，実際には選好が存在しているため，意味は伝わるものの読みにくい文が作成されることがある．本稿では，推敲支援のための要素技術として，Shift-Reduce アルゴリズムを拡張した，日本語文に対する係り受け解析・語順整序・読点挿入の同時実行手法を提案する．提案手法では，従来手法にビームサーチを組み込み，深層学習モデルとして RoBERTa を使用することにより，精度向上を試みる．また，逐次実行手法との比較を行い，同時実行することの有効性を検証する．
A9-1,大規模言語モデルは，自然言語処理タスクで優れた性能を発揮しているが，翻訳タスクではモデルサイズや訓練手法による性能差が見られる．本研究では，段落単位の対訳データを活用した継続事前訓練および Supervised ﬁne-tuning が翻訳精度に与える効果を検証した．Llama-3 ベースのモデルを用いて英日・日英翻訳を評価した結果．段落単位の対訳データを継続事前訓練と Supervised Fine-Tuning の両方で利用することで最も高い精度が得られた。また，推論時に段落全体を一括で翻訳する方法が有効であることを確認した．
Q8-4,学術論文数の急増により，論文推薦システムの重要性が高まっている．特に，「背景」「手法」「結果」といった観点のうち，どの観点が類似するかを示すことは，利用者の負担削減に有効である．これに対して，従来は要旨内の各文を観点に分類し，各観点類似度をもとに推薦理由を提示する手法がとられていた.しかし，これまで「手法」が類似している論文に対する推薦精度が低かった．本研究では，要旨内の「手法」の類似性に着目した新たな推薦手法を提案する．具体的には，要旨から分野情報を抽出し，分野情報を表す単語の埋め込みを調整することで，「手法」が類似している論文の推薦精度を向上させる．ベンチマークデータで提案手法を評価した結果，従来手法を上回る精度を示した．
P8-20,用例や言語現象をコーパスから素早く探し出すgrep などのパターン検索は，コーパスと人間をつなぐための基本的で重要な道具である．しかし，既存の文字列一致に基づくパターン検索では，表記揺れや類義語といった表層の変化を捉えることは難しい．文埋め込みを用いた密ベクトル検索も注目を集めており，意味的に粗く類似したテキストを検索できるが，具体的なクエリの出現位置の特定や列挙といった操作は困難である．本研究では，単語埋め込みを用いた柔らかいパターンマッチャーSoftMatcha を提案する．提案法は，転置索引を拡張したアルゴリズムを用いており，巨大コーパスに対して柔らかくも高速な検索・列挙をおこなうことができる．コーパス中の有害事例の列挙や，形態論的に複雑な特徴を持つ言語に対する用例検索を通して，SoftMatcha の有用性を実験的にも確認した∗．
P6-19,大規模言語モデルによる訓練データの暗記の懸念に注目が集まる一方，非英語や産業界のコーパスを用いる条件下での分析は十分に進んでいない．そこで本研究では，日本語特化の大規模言語モデル構築で一般的な継続事前学習に着目し，訓練データに対する暗記の定量化に取り組む．具体的には，Llama 3に対して Wikipedia と日本語ニュースメディア「日経電子版」の記事データを用い，2 種類の継続事前学習モデルを構築・分析した．実験では英語の実証的知見と同様，学習が進むごとに暗記量が増える傾向が観測された．この傾向は日経電子版の場合により明確で，一般的でない産業界のコーパスを用いる際の懸念が示唆された．
P1-10,"As Large Language Models support more and more lan-guages, they face increasing challenges in alleviating lan-guage inference and adapting to unseen languages. In thiswork, we propose a modular ﬁne-tuning pipeline for mul-tilingual neural machine translation, where adapters aretrained separately for input and output languages. Dur-ing translation, the parameters of the corresponding inputand output language adapters are combined using weightedsummation. Experiments on 5 languages show that ourmethods can reach 50% of full-parameter ﬁne-tuning per-formance with only 0.5% to 1% trainable parameters.Moreover, under certain weight conﬁgurations, merginginput and output language adapters outperforms using themindividually in some language directions, highlighting thepotential of our merging strategy."
Q2-23,大規模言語モデル(LLM)は自然科学，数学，歴史，社会科学などの様々な分野で高い言語理解能力および言語生成能力を持つことが示されており，様々な自然言語処理タスクで利用されている．一方，多くの LLM は英語の事前学習データセットによる学習を基礎とするため，英語圏以外の文化に関わる知識については不十分であることが指摘されている．そのため，主に日本語データを用いた事前学習モデルや日本語による継続事前学習モデルなど，日本語資源を利用して日本に特化させたモデルの開発が行われている．本研究は日本の文化・民俗の中でも特に妖怪を題材として，これらの LLM が日本の文化に関する知識を持っているかを評価した．妖怪は現代でも娯楽として親しまれながらもその根拠は日本の古くからの民話や浮世絵にあるため，日本文化の理解度を評価するための題材として有用であると考えられる．評価のため，995 問の妖怪に関する知識を問う四択問題を生成し 31 個の LLM で比較した．総じて明に日本語で学習したモデルの方が英語中心のモデルよりも正答率が高く，特に Llama-3をベースとした日本語による継続事前学習モデルが高い正答率であった．
C8-3,"近年，大規模言語モデル（LLM）は膨大な Webデータを活用することで性能を大幅に向上させている．しかし，実務適用においては，ドメイン固有の知識をモデル内部へ定着させる必要があり，これに対して多様な手法が提案されてきた．また，単一の事実をモデルに確実に学習させるためには，多角的な文脈や表現を 100〜1,000 回程度提示する必要があることが報告されているが，そのようなドメインデータを十分に収集・整理するには多大なコストや制約が伴う．本研究では，LLM に対する新たな知識定着を実現する継続事前学習に対して，複数の合成データ生成手法を適用し，効率的な知識獲得方法を検証した．さらに，能動学習を用いたデータセット削減手法を組み合わせることで，知識定着をより効率化する方法を検討した．実験の結果，事実ベースの合成データ生成手法によって多様な合成データを準備することで，単純な言い換え手法と比較して学習回数を 69 ％削減しつつ，モデル内部への知識定着が可能であることが明らかとなった．一方で，能動学習手法による学習効率化は，合成データを用いる環境下では期待した性能改善を示さなかった．"
Q5-16,本研究では，任意の題目に対する多様な視点の獲得を目的とした，ラップバトル形式のディベート生成システムを提案する．意見の対立する即興のディベートを視聴することで，多様な視点を養えることが知られており，これに類似する競技として，即興のラップを通じてお互いの意見を主張するラップバトルがある．本研究では，手動で作成したプロンプトを基に GPT-4o でラップバトル形式のディベートを生成し，その視聴を円滑にするためのデモシステムの作成に取り組んだ．評価は，全国中学・高校ディベート選手権の題目を基に生成したディベート20 件に対して，評価者 3 名の人手評価をおこなった．結果として，生成したディベートがラップバトルの形式に準拠しつつ，多様な視点の獲得に貢献していることを示した．
D6-5,エージェント間のコミュニケーションを通して共有されるサインを創り出すことができる記号創発モデルが提案されている．これまでの研究ではサインの生成・認識能力の学習過程はモデル化されていなかった．そこで我々はこれまでに連続信号をサインとして用いた記号創発モデルを提案した．その手法では，複数の音素を組み合わせて単語を構成する音素の合成性を導入した連続信号から，エージェント間で対象を表現するサインを学習する．本稿ではその手法の比較・評価を行った．実験では，各エージェントは同一の物体を観測し，その物体を表現する物体の潜在表現と，それを表現するサインである連続信号を，コミュニケーションによって推論する．提案手法がエージェント間で高い一致率かつ高い精度で物体を表現するサインを学習可能であることを示した．
E9-2,近年の大規模言語モデルの性能向上において、Direct Preference Optimization (DPO)によるモデルのアラインメントの成功が大きな役割を果たしている。しかし、学習で用いられるラベルの作成には多大なコストが必要であり、作業者の負担も大きい。本研究では、作業者がテキストを読んでいる際の脳波から選好情報を抽出し、それに基づきモデルを学習する手法として Cognitive Preference Optimization (CPO)を新たに提案する。CPO では、作業者はテキストを読むだけでラベルを作成でき、負担の軽減が期待できる。人間のフィードバックを用いた場合と比較して、手法の妥当性を検証した。
P2-26,本研究では，紙への筆記用具による筆写と，デジタル端末へのキーボード入力という書く方法の違いにより，作文活動に必要な字・語・句の記憶定着に差異が生じるのかを中学一年生を対象に調べた結果を報告する．先行研究において，書く活動では記憶の定着や理解の程度に方法の違いによる差が見られるという報告がなされている．ただし，書く活動は多様であり，ノートテイキングやメモといった文単位の内容の記憶や理解について調べる研究が多い．本研究では漢字・熟語・慣用表現・四字熟語という比較的小さい単位を題材に，方法の違いにより記憶定着の差異が生じるかを調べた．調査の結果，未習の漢字の形は筆写練習で記憶されやすかったが，既習漢字を組み合わせた未習の読みの語は入力で記憶されやすかった．また，慣用表現・四字熟語の意味記憶に方法の違いによる差は認められなかった．
P5-13,本研究では、大規模音声認識モデルである Whisperに基づく音声感情認識手法を提案する。近年盛んに研究が行われている、事前学習済み音声エンコーダに基づく音声感情認識手法では、言語的な情報を十分に考慮することができなかった。そこで多量のデータ・複数の音声言語処理タスクで事前学習された Whisper のデコーダを用いることで、言語情報も考慮した感情認識手法の実現を目指した。また、音声認識や性別認識といったサブタスクのトークンを含めた単一系列をデコーダで生成するマルチタスク学習手法を提案した。
B7-4,裁判官による判決作成では，争点の事実に関連する法律を解釈し事実を当てはめて結論を導く．他方モデルによる判例予測では，法律領域の精度向上とAI の信頼性観点での推論過程の明確化が課題である．本研究では，どのように法律解釈を行ったかを可視化し，モデルが法律解釈を学習することでドメイン知識を向上させるため，EU 法判例を用いて判例内の事実の法的関連性のグラフ生成タスクである LegalViz を提案する．更に，グラフ構造と法律内容の双方を考慮したグラフ可視化評価を行うため評価手法を提案する．実験では，学習したモデルがFew-shot 設定の GPT モデルの性能を上回ることから提案データセットの有効性を示した．
Q3-8,本研究ではユーザが画像をなぞった軌跡（トレース）が示すユーザ固有の説明意図を生成文に反映する画像キャプショニング手法を提案する．トレースの密集度から関心領域を特定し，座標変化に基づいて説明順序を決定，滞在時間を用いて各領域への関心度を評価する．これらの情報を基に拡散言語モデルを半自己回帰的に用いることで，文長や説明順序を制御しつつ，流暢性の向上を図った．実験の結果，提案手法は自己回帰モデルを含む既存手法より10%以上高い精度を達成し，内容・順序・詳細さの3 観点でユーザの意図を忠実に反映できることを確認した．
P9-13,"Social media platforms like YouTube have become pow-erful tools for shaping public opinion during elections inrecent years. This study examines the sentiments in theYouTube videos concerning three presidential candidatesin the 2024 Indonesian election. We ﬁrst classify the videosinto three categories: candidate’s oﬃcial channel, publicnews, and third-party-created sources. Next, we performsentiment analysis on each video and calculate a metric, theSentiment Impact Score (SIS), to quantify the overall sen-timent dynamics. Our ﬁndings reveal a signiﬁcant shift inpublic sentiment, ultimately favoring the elected candidate,especially among the third-party created videos."
P7-16,大規模言語モデル（LLM）による翻訳の評価に際し，評価に用いるデータが LLM の事前学習データに含まれている場合，適切な評価ができない。本研究では，この問題を回避するために，頻繁に更新されるニュース系のリソースを利用して，英日の文書翻訳評価用データセットを構築した。本データセットは公開されており，不定期に更新される予定である。また，利用者が自ら更新できるよう，データ構築に用いたソースコードも合わせて公開する。
B1-2,本研究は、セマンティックパージングで広く採用されている、Smatch をはじめとするグラフマッチングによる評価指標が、セマンティックパージングの主たる下流タスクのひとつである自然言語推論における性能を必ずしも保証しないということを示すものである。上記を示すために、ファインチューニングおよび In-context learning に基づくパーザを構築し、グラフマッチングによる評価と自然言語推論を志向した評価をそれぞれのパーザに適用した。結果として、グラフマッチングによる評価と自然言語推論への応用可能性との間にはギャップがあるということを報告する。
D2-1,グライス（1913 - 1988）がウィリアム・ジェームス記念講義を行った 1967 年に公にされた「序論」には、かつての「戒め」は「意味と使用は同じものと心得よ」であり今は「意味と使用を混同しないよう注意すべし」という「戒め」へと変わり「手軽な哲学の常套旬」になりかけていると書かれてある.意味使用説へのグライスの姿勢を概観する前の準備として、グライスの環境と幾つかの用語の把握を試みる.特に「効果（eﬀect）」という語に関心を払った.「効果」という語は、グライスの特色であるとともに、グライスの外に出ることも誘引する用語であると思われる.なお著名な「会話の格率」は本稿が関心を持つ「無時間的意味を発話者の意図から説明する」箇所に直接には現れないため割愛した.
P6-4,大規模言語モデル（LLM）をサービスに組み込むとき，外部知識の獲得および推論速度，推論精度は重要である．そこで，本研究では，LLM の推論速度を向上させるために，Hybrid-RAG を改善した外部知識の獲得手法を提案する．従来手法においては，グラフデータベースとベクトルデータベースを並列に接続していたが，提案手法では，各々を直列に接続することにより効率的な外部知識検索を実現した．また，実験において，小説プロットを外部知識として導入したときの性能評価を行った．その結果，従来手法と比較して推論速度が向上することがわかった．
Q9-16,比喩検出は、文字通りには解釈できない比喩表現を検出するタスクであり、文脈情報が重要である。過去の研究では、ChatGPT を用いて生成した補助文をターゲット文の前に追加する手法が提案され、精度向上が示されたものの、十分ではなかった。本論文では、ターゲット文の前後に補助文を追加する手法を提案し、比喩検出の精度向上を図った。複数のデータセットを用いた実験では、補助文の追加により精度、適合率、F1 スコアが過去の研究より向上したことが確認された。本研究は補助文生成の有効性を示しており、今後はより多様な文脈構成や最新の生成モデルを活用する可能性を探る必要がある。
A8-6,言語モデルの言語獲得能力は人間とどのように異なるかという問いに対して，人間にとって不自然な言語（不可能言語）を人工的に生成し，言語モデルの学習のしやすさを分析した研究がある．先行研究では，GPT-2 モデルにおいて不可能言語は可能言語よりも学習しにくいという結果が報告されているが，言語に共通する性質は単一ではなく，不可能言語についても様々な種類が存在するため，言語モデルがどのような不可能言語においても学習が難しいのかという問題については，依然として多くの疑問が残されている．本研究では，「最下層の従属節は他の節によって分断されない」という言語に共通する性質に着目し，従属節の間に主節の一部を混ぜた不可能言語を作成した．作成した不可能言語を用いて GPT-2 モデルを学習し，可能言語と同様に不可能言語を学習できるかどうか分析を行った．GPT-2 モデルにおいて可能言語と比較して不可能言語の学習は困難であるという結果となり，先行研究と同様の傾向を示した．
Q9-3,"本研究では,文学作品のテキストデータを用いた年次予測の可能性を検討した.まず,芥川龍之介の作品を対象に, TF-IDF を特徴量として複数の回帰モデルを用い,初出年の予測を行った.その後,青空文庫に収録された大量の作品に対象を拡大し,同様に年次予測を試みた.いずれの場合も,予測は一定の精度で可能であることが示され,使用される語彙のパタンが年次の推定に有効であることがわかった.特に,ランダムフォレスト回帰が他のモデルと比較して優れた予測性能を示した."
Q7-13,本研究では，実世界における日本語対話の曖昧性解消を目的として，マルチモーダル参照解析の性能向上に寄与する要素を検討し，またモデルに組み込む．具体的には，メンション間およびメンション・物体間の参照関係を統合的に解析するフレームワークを提案する．実験では，共参照解析や照応解析といったメンション間の学習がメンション・物体間の解析に与える利得を明らかにした．
P4-6,"This study explores eﬃcient, parsing-free methods forencoding word structure by comparing regular 𝑛-grams,skippy 𝑛-grams, and extended skippy 𝑛-grams in the con-text of inﬂectional classiﬁcation tasks for noun gender,plurality, and case. The classiﬁcation was tested on thenouns of four languages: Czech, French, German, andIrish. While the outcomes were mixed and complex, theﬁndings suggest that extended skippy 𝑛-grams (with orwithout boundary marking) outperform skippy 𝑛-grams,and skippy 𝑛-grams perform better than regular 𝑛-grams interms of classiﬁcation eﬃciency. This study provides evi-dence that (extended) skippy 𝑛-grams oﬀer a more eﬀectiveapproach for encoding word structure."
P4-7,自由語順と項省略という統語現象には相関関係がみられる。つまり、言語ごとに、両方の現象が観察されるか、どちらも観察されないか、という傾向がある。では、なぜそのような文法相関が存在するのだろうか。本研究では、自由語順と項省略がみられる日本語に注目し、処理の効率性がこれらの特徴を形作っているのか検証する。具体的には、日本語のコーパスから、自由語順、項省略、またはその両方がないバージョンを作成し、現実のコーパスと比較する。その結果、自由語順かつ項省略が存在する言語は、記憶と予測の負荷を抑制する点で有利だと示された。
B3-1,本研究は，大規模言語モデル（LLM）を用いた価格交渉シミュレーションにおいて，アンカリング効果が交渉結果や満足度に与える影響を検証した．売り手エージェントにアンカリング効果を用いるよう指示した場合，売り手の効用が向上し，買い手の効用は減少するものの，両者の主観的満足度が高まることが確認された．また，アンカリング効果の使用が買い手に事前に知らされても，その有効性が概ね維持されることが分かった．これらの結果は，人間を対象とする研究の知見と一致し，LLM が表面的な結果のみに捉われず心理的な面においても認知バイアスを再現可能であることを示唆している．
Q7-12,"令和 5 年度の介護労働安定センターの調査[1]によると,介護施設において 29 歳以下の若い介護職員が離職率が高く,これは新人職員の指導が十分でないことが原因と考えられている.特に,利用者の困りごとへの対応に苦慮することが多いという問題がある.このような問題を解決するため,本研究ではPython と Flask を用いて困りごとに対する適切な対応方法候補を提示する Web アプリケーションの開発を行った.これにより,作業効率の向上および離職率の低減に貢献が期待できる."
Q9-2,自然言語はインクリメンタルに読み書きされるが、異なる言語でも、インクリメンタルな処理の仕組みは言語普遍的なのだろうか？本研究では、系列・構造の両方をインクリメンタルに予測する統語的言語モデルが「系列の背後にある統語構造をどの程度投機的に予測するか」をパラメタとし、次トークン予測や構文解析において最適なパラメタが言語共通かを分析する。実験の結果、最適な戦略の言語共通性はタスクやビームサイズにより異なることが観察され、人間と言語モデルの処理メカニズムの違いに関する示唆が得られた。
A10-6,"本研究では,逆翻訳を用いて少資源言語であるアイヌ語と日本語の機械翻訳の精度向上を目指した.元の対訳コーパスのみを利用して,反復的逆翻訳手法とランダムサンプリングによる疑似対訳文生成手法を用い,さらに,外部の日本語の単言語データを活用した.結果として,外部の日本語の単言語データを利用するよりも元の対訳コーパスのみを利用して逆翻訳を行った方が良い結果となった."
Q9-17,LLM（Large Language Model、大規模言語モデル）の発展に伴い、多くの言語処理タスクで LLM が高い性能を発揮している。しかし、深層格で表現されるような複雑な事物の関係を正確に捉えられているかは不明である。我々は独自に定義した深層格とその付与ルール群に基づき、ルールベースの深層格自動付与システムを構築した。その出力と LLM を組み合わせることで、言語処理タスクの性能が一般に向上しうると期待する。本研究では性能検証として、JNLI データセットを用いて含意関係認識を行った。その結果、GPT-4o との組み合わせで正解率が2.67 ポイント向上し 84.75 の SoTA 評価値を達成し、我々の自動深層格付与システムの有効性を示した。
P6-5,ヒトが行うような自然言語による推論では，観測した事象を言語で表現することで認識を行い，その事象に関する知識を取り込んだ推論を多段に繰り返していくことにより最終的な帰結となる自然言語文を生成していると考える．本研究では，自然言語文入力に対して知識を介在させ，新たな自然言語文を生成する形で結論を導くための多段の多岐にわたる推論過程過程の中から，自然言語文を生成する際の尤度を最大化する過程を抽出する手法を提案する．実験には多段推論のデータセットである MuSiQueを利用した．結果として，提案手法はチャンスレベルを上回る性能であることを検証した．
B1-3,自然言語理解の研究において，大規模言語モデル(LLM)とは対照的なアプローチとして，合理主義自然科学のパラダイムに基づく言語学的パイプラインの研究が進展している．これは理論言語学に基づく統語解析，意味合成，自動証明のモジュールを接続したものであり，仮説検証を通じてモデルを改善する点で、経験主義的な LLM と相補的な関係にある．本論文では，CCG に基づく統語解析器 lightblueと，DTS のための定理証明器 wani を組み合わせた自然言語推論システムを用いて，JSeM 日本語テストセットの Verb セクションの推論問題を解くことを試みた．この試みは、システムの評価，エラー分析，理論へのフィードバックを含む，合理主義的計算言語学の実践例の一つである．
P7-17,"Evaluating the performance of large language models(LLMs) remains a crucial research topic, and conductinga comprehensive and accurate evaluation of LLM perfor-mance eﬃciently is challenging. This challenge is par-ticularly acute for non-English languages. GPT-4-basedautomated evaluation has proven eﬀective, demonstratinghigh consistency with human preference. However, GPT-4-based evaluation still has several limitations, includingits closed-source nature and general preference. This paperproposes an approach to construct an open-source JapaneseLLM evaluator, which has demonstrated robust consistencyon the Japanese Vicuna benchmark. We present a methodfor rapidly generating score r ubrics that refer to speciﬁc in-structions, enabling more diverse evaluation criteria whenevaluating LLMs. Our Japanese LLM evaluator trainingdata and models are available here.1）2）"
P9-12,アスペクトベースの感情分析は，文中の複数のアスペクト語に対する感情極性を特定するタスクである．近年の研究では極性の推定をするために係り受け木を用いてアスペクト語に対するオピニオン語を特定する手法が提案されているが，この手法は英語においてのみ実験されており，日本語における研究では，係り受け木を用いたものはない．そこで本研究では，日本語において係り受け木を用いてアスペクトベースの感情分析を行う手法を提案する．日本語データセットでの感情分析実験により，我々の提案手法が既存の手法よりも優れていることを示す．
Q3-9,インターネット広告市場の拡大に伴い，バナー広告の需要が急増している．バナー広告は視覚的に訴求する画像と，商品の価値や特徴を伝える広告コピーで構成され，その組み合わせの「相応しさ」は広告効果に影響するとされる．しかし，この相応しさを評価する研究はこれまで行われていない．本研究では，相応しさを評価するため，「コピーがバナー画像の内容を再現しているか」および「バナー画像がコピーの内容を再現しているか」に基づくバナー画像とコピーの表現再現性評価タスクを提案し，ベンチマークを構築する．また，表現再現性とバナー広告としての相応しさの関係を調査する．そして，既存手法による表現再現性の評価実験を行い，評価の課題を明らかにする．
B7-5,本研究は、技術分野における動向把握の効率化と精度向上を目的としている。従来の技術動向分析手法は、専門家の評価に依存し、高コストであるとともに迅速性や説明可能性に課題を抱えていた。これらの課題を解決するために、本研究では大規模言語モデル（LLM）を活用し、技術観点の自動検出による技術動向マップの構築手法を提案する。本手法により、膨大な技術情報を効率的かつ体系的に整理し、的確な技術動向の分析とその活用を支援する基盤を提供することが可能となる。
P5-12,医療現場での利活用の需要が高まる中，医療事故が起こった際，その原因を突き止め，迅速に対策を講じるための大規模言語モデルは有用だと考えられる．医療現場で利用可能な大規模言語モデルを考えるうえで，その能力を評価するベンチマークは必要不可欠だが，現状は十分とは言えない．このような背景のもと，本研究では，日本医療機能評価機構による医療事故情報収集等事業によって収集，提供されている事故・ヒヤリハット事例のデータからデータセットを構築し，医療事故の内容から，背景・要因，改善策の生成を評価するためのベンチマークを提案する．
E9-3,計算に使うメモリ資源を制限すると，言語モデルは人間の読み時間をより正確に予測する．本研究は，この知見は言語理解ストラテジーにも当てはまるのか調べた．具体的には，GPT-4o は，人間と同じように，メモリ資源が制限されると，非妥当な文を妥当な意味で理解するという合理的な言語理解ストラテジーを使用しやすくなるか検証した．メモリ資源の制約のために，“The 2 cocktail + blended 3 =...”のように，計算問題と言語理解を同時に行う二重課題を設計して実行した．結果，このようなストラテジーの変化を観察した．これは，合理的な言語理解ストラテジーへの転換はメモリ資源の制限が原因の一つであることを支持する．
P2-1,本研究では，大規模言語モデル（LLM）の数値時系列解釈能力を測る 16 の評価タスクにおいて，プロンプトの記述言語の影響を検証する．数値時系列は，マルチモーダル言語生成や時系列予測などの多くの問題で重要な入力情報となっている．従来，LLM の数値理解能力を評価するタスクは，非系列データの算術演算や数値を含む表の論理推論が中心であったが，数値時系列に特化した評価タスクの開発が進んでいる．そこで本研究では，1)イベント検出，2)計算，3)比較の 3 つのカテゴリの評価タスクに対し，プロンプトの言語（日本語と英語）の違いによる性能差について考察する．実験より，タスクによってプロンプトの言語選択が数値解釈能力に影響を与えることが明らかとなった．
D6-4,ロボットが人間と遜色なく会話できるかという問題は，人工知能研究における大きな課題の一つである．本稿では，人間とロボットが快適に会話ができるかというプロジェクトで得られた報告を元に，人間とロボットの会話の特性の違いを明らかにする．特に，ロボットは会話を遂行する際に自分の誤りを修正する能力がなく，これが会話分析における他者修復という観点から分析することが可能であり，軌道修正をする力の有無が現在の人工知能と人間の会話を分ける大きな違いであると主張する．
Q5-17,"大規模言語モデルは平易化においても一定の性能を持つことが知られており,平易化コーパスによる学習を行うことでより高性能な平易化モデルが作成できることが期待できるが,日本語平易化データセットは質・量ともに十分ではない.この問題を解決するため,モデルの重みの加減算によりモデルの能力を転移する技術である Task  Arithmetic の応用を検討したが,平易化へ適用した事例は少ない.本研究では日本語平易化コーパス SJNC を用い,平易化における Task  Arithmetic の有効性を検証した.自動評価の結果スコアの向上が確認され, TaskArithmetic が日本語の平易化に対しても有効である可能性が示された."
C8-2,言語モデルの計算量削減を目的とした従来の手法は，1 トークンあたりの計算コストを削減することに焦点を当ててきた．本研究では，文章生成にかかるコストが生成トークン数にも影響されることに注目し，言語モデルの生成文を短縮することで計算量を削減する方法を検討する．これを実現する学習方法として，文章全体に長さに応じた報酬を与える強化学習と短い文章を誘発するトークンを正解データとする教師あり学習の 2 つを検証する．さらに，生成文の短縮率と性能の関係を調査することで，生成文の短縮が言語モデルの性能にどのように影響するかを示す．Phi-3-mini，Zamba2-2.7B における実験の結果，強化学習と教師あり学習の両手法において生成文の短縮に成功した．また，5%以下の性能低下のもとでは，Phi-3-mini は約 15%〜20%，Zamba2-2.7Bは約 30%の短縮が可能であることが示された．
Q2-22,"Self-Correction enables Large Language Models(LLMs) to reﬁne their responses during inference basedon feedback. While prior research mainly examines theimpact of Self-Correction on reasoning tasks such as arith-metic reasoning, its inﬂuence on debiasing remains un-derexplored. In this work, we propose a Self-Correctionframework tailored to bias evaluation task and demonstratethat the approach has potential in debiasing LLMs’ re-sponses more robustly and consistently than the baselines,which are Chain-of-Thought and Self-Consistency. Wealso conﬁrm that factors such as the feedback source, thebias level of the feedback generator, and the social biascategories signiﬁcantly inﬂuence debiasing outcomes."
Q2-20,"Evaluating an LLM’s robustness against numer ical per-turbation is a good way to know if the LLM actually per-forms reasoning or just replicates patterns learned. Wepropose a novel method to augment math word problems(MWPs), producing numerical variations at a large scaleutilizing templates. We also propose an automated errorclassiﬁcation framework for scalable error analysis, distin-guishing calculation errors from reasoning errors. Our ex-periments using the methods show LLMs are weak againstnumerical variations, suggesting they are not fully capableof generating valid reasoning steps, often failing in arith-metic operations."
Q5-15,"専門的な文書の平易化は医療分野を対象としたものが多く,情報科学の分野を対象にしたものは少ない.また,既存の平易化研究では専門用語の意味を大きく削って平易化を行ったり,専門用語を非常に長い文章で平易化したりしている.これは論文の情報を全て簡潔に理解するためには適切とは言えない.本研究では情報科学分野の論文を対象に,専門用語の平易な説明のポップアップを用いて平易化を行うシステムの開発を行った.目標として,内容の理解しやすさの改善,文章量の増加防止,情報量の保持を掲げた.内容の理解しやすさの改善は見られなかったが,先行研究手法と比べ情報量の保持に成功し,文章量の増加防止は達成した."
B5-5,少子高齢化の続く我が国においては知識伝播と技能伝承の刷新が不可欠である。本研究では外務省において生じているそうした問題状況への対処を図るべく、大規模言語モデル（LLM）と検索拡張生成システム（RAG）を用いた業務支援システムを提案する。具体的には日米外交を念頭に、データセットとして党派色の無い米連邦議会調査局（CRS）によるアジア関連レポートの英文テキストを用いてコーパスを作成し、その調書を日英文で作成、両者の比較を通じての改善案作成を行った。その際、日英文で同一内容の質問を行う中、模範となるべき英文での回答の生成に際し生じる深刻な「幻覚」により、実装に際しての負担増が生じ、課題となることが判明した。
P2-3,本研究では，日本語の小論文採点を支援するシステムの開発を目的とし，モデルの解釈可能性向上を図るための手法を提案する．提案手法には，Attention，Masking Token，および Sparse Autoencoderの 3 つを提案する．特に Sparse Autoencoder を用いて特徴量ごとに概念を特定し，モデルの内部構造の解釈を可能にすることで，採点結果の透明性と信頼性を向上させることを目指す．実験結果より，Sparse Autoencoder は概念抽出の精度が高く，解釈可能性の向上に寄与することが確認された．一方で，各特徴量と得点の関連性を明確にする課題が残されており，今後の研究ではこれを解決することで，小論文採点支援システムのさらなる改良を図る．
Q1-9,ニュース記事では，企業などの組織名に関する情報を報じる記事が多く，組織名が頻繁に登場する．企業名は時間と共に変化しやすく，企業名の変化がエンティティリンキングを困難にしている問題がある．本研究は，企業名の変遷に関わる情報をイベントとして抽出することで，歴代の企業名を構造化し，企業名の曖昧性を解消することを目指す．社名の変更や企業の統廃合に関する 5 種類のイベントを定義し，有価証券報告書の企業沿革テキストに各イベントをアノテーションを付与した企業名変化イベント抽出データセットを作成する．作成データセットを使用した評価実験では，LLM によるイベント抽出結果を評価し，一部の企業イベントに対して改善の余地が見られることを確認した．
P2-25,本稿では，言語モデル内の潜在的な概念空間を探索・可視化するための手法である TrendScape 1.0を紹介する．本手法では，自然言語を潜在空間にマッピングして近傍グラフを構築する．グラフ上の経路探索を通じて概念間の関係を調べる．手法の検証として，文学作品間の概念経路を可視化し，得られたネットワークを分析することで，言語モデルの概念理解に関する洞察を提供する．
E9-1,近年、大規模言語モデル（LLM）を活用し、脳活動データから言語表現を直接復元する脳情報デコーディングの手法が注目されている。一方、言語学や認知神経科学では、脳活動と言語表現の間に統語構造などの中間表現が存在することが広く想定されてきた。では、脳情報デコーディングにおいて、言語表現を直接復元するのではなく、統語情報のような中間表現を明示的に利用することで、デコーディング精度が向上する可能性はあるのだろうか。本研究では、脳波データを用いて言語生成を行うBrainLLM を活用し、品詞情報を中間表現として取り入れることで、デコーディング精度が向上するのか検証した。その結果、統語情報の考慮がデコーダーの性能向上に寄与する可能性が示唆された。
P2-19,多言語モデルのプロービングによって言語モデルの多言語性を分析する動きは活発化してきているが，個別言語に依存しない，言語間で共通の処理系統が多言語モデル内に存在するのかについては十分に明らかになっていない．そこで本研究では，第二言語を獲得した言語モデルに焦点を絞り，これらの言語モデルが，第一言語(L1)，第二言語(L2)間で対応する文の意味に関して言語非依存の共通の処理を行っているのかについて，内部表現や発火するニューロンの観点から調査する.実験の結果，言語モデルは，対応する文の意味について個別言語に依存しない共通の処理をしていることが示唆された．
P5-10,一般の文書要約で使われている ROUGE などの自動評価指標は判決書自動要約タスクでも使われている．しかし既存の自動評価指標では判決書要約文に不可欠な要素が，要約文に含まれているかを評価することができない．本研究では，判決書要約文に特化した評価ルーブリックを策定し，それに基づいて法律の専門家による人手評価を行う．そして，その評価データを利用して判決書要約文に特化した自動評価器を構築する．構築した評価器をカッパ係数で評価し，自動評価器と正解データとの一致度が人手評価者の間の一致度を部分的に上回ることを示す．
D4-4,社会科学の分野で研究の蓄積があるポライトネス理論の検証を目的とし，対話コーパス中の発話における発話の丁寧さや，話者間の距離，力関係，発話内容の相手への負荷を大規模言語モデルにより推定した．推定結果を用いてフェイス侵害度と丁寧さを比較したところ実験に用いた 120 対話のうち 100 対話で有意な相関が見られ，これらの対話においてはポライトネス理論が示す通りの結果を確認できた．
P9-10,対話システムのユーザ本人にとって好ましい応答生成に向け，ユーザの嗜好等を発話内容に反映する試みが盛んに行われている．一方，生成する発話のスタイルもシステムへの印象に影響を与える可能性が先行研究で示唆されている．本研究では，ユーザの過去発話に対するシステム発話のスタイル類似度を自動評価する手法を提案し，システム発話のスタイル類似度とユーザによるシステムの主観評価との相関を調査する．両者の間で正の相関を確認し，発話スタイルの類似がユーザ個人にとっての対話の好ましさの一側面となっていることを明らかにした．
P8-8,本論文では，学術論文検索におけるブーリアン型検索クエリの考案を支援するシステムを提案する．大規模言語モデルを活用し，「AND 結合」「OR 結合」「クエリ置換」「クエリ削除」の 4 つの操作パターンに基づくクエリ推薦と，その推薦理由を提示することで，ユーザが効率的にクエリを修正できる機能を提供する．本システムは少量のアノテーションデータを利用しており，ユーザの負担を抑えつつ柔軟なクエリ推薦を実現する．実験では，これらの操作パターンに基づくクエリ推薦において検索結果の再現率を向上させる語を提示できることを示した．
P7-15,LLM の社会的バイアスの評価において，個々の社会的属性だけでなく，複数の属性の組み合わせからなる交差バイアスを社会問題の事例に基づいて評価することの重要性が指摘されている．本研究では，QA タスクで LLM の交差バイアスを評価する日本語ベンチマーク inter-JBBQ を構築する．inter-JBBQを用いて GPT-4o と Swallow を分析した結果，同じ問題でも属性の組み合わせによって回答に変動があり，曖昧な問題に対し GPT-4o は Swallow と比較して答えられないと回答する傾向が強化されていた．一方，曖昧性を解消した問題では Swallow の正答率が GPT-4o の正答率を上回る場合も観測された．注意：本論文には不快な表現が一部含まれます．
D2-2,対話生成 AI の感情表現力や感情理解力を向上させることで、AI がより人間らしいコミュニケーションが可能になり、ユーザーの体験が改善されることがわかっている。本研究では単語ごとの感情情報を登録した単語感情辞書を作成し、日本語学習済みGPT2 モデルにおいて感情情報を付与する層を追加することで感情表現力や感情理解力の向上を目指した。感情付与を行わなかったモデルと感情付与を行ったモデルを、ChatGPT を利用して比較し、感情付与によって感情表現能力が向上することを示した。
B1-1,自然言語の系列において，要素間の相関は距離について冪的に減衰することが知られている．これは，系列中のある要素を変更すると，その影響がどれだけ離れた要素にも及び得ることを意味する．先行研究[1]は，このような特徴的現象を，系列の背後にある階層的な統語構造と結びつけて説明している．しかし，この説明は統語構造に関するいくつかの仮定に依拠しており，それらの仮定が実際に自然言語で成り立つかどうかは検証されていない．そこで，本研究は，ツリーバンクを用いて統語構造の統計的性質を調べ，先行研究の仮定がいずれも成り立たないことを明らかにする．
P6-7,"To investigate polymer biodeg radability information ex-traction, we constructed PolyBD, a manually annotateddataset containing entity annotations of 100 journal ar-ticles. We evaluated the performance of GPT-4o insentence-level entity recognition under a zero-shot settingon PolyBD. While GPT-4o achieved strong overall results,its performance diﬀered markedly between nested entities(those contained within other entities) and non-nested enti-ties (all others). Speciﬁcally, it achieved a recall of 78% fornested entities but only 56% for non-nested entities. Theseresults underscore both the capabilities and limitations ofadvanced large language models in addressing real-worldextraction tasks."
Q10-9,視覚的質問応答は、文書画像から構造化された情報を抽出する上で有望な手法である。しかし、従来の手法では、抽出対象となる各項目を個別に質問応答する方式で実現されることが多く、項目間に内在する依存関係を十分に活用できていない可能性がある。本研究では、関連性のある複数項目を同時に推論する手法を検討し、その有効性を実証する。実世界のデータセットを用いて評価した結果、相互依存性が高い項目群において、同時に推論する手法は従来の手法を大幅に上回る抽出精度を示し、相互依存性が低い項目に対しても同等の水準を維持できることを示した。また、項目数や項目間の関連の強さが抽出精度に及ぼす影響を分析し、視覚的質問応答に基づく情報抽出を効果的に実現するための知見を提示する。
A8-5,近年，大規模言語モデル(Large Language Model，LLM)は様々な言語理解タスクで高精度を達成しつつある．しかし，LLM が文中に現れる事象間の時間関係をどの程度理解できているのかについては，十分に研究が進められていない.本研究では，「パーフェクト相」の一種である「状態パーフェクト」に注目して自然言語推論（Natural Language Inference，NLI）データセットを構築し，LLM の日本語・中国語の状態パーフェクトが表す複数の時点の関係性を正確に把握しているかについて分析を行った.実験の結果，日本語・中国語の状態パーフェクトの表す意味について，LLM の判断は一貫しておらず，人間の判断と一致していない傾向を明らかにした.
Q9-15,"In this paper, we report on preliminary experiments inwhich we attempt to use large language models to com-pare Japanese and English metaphors. More speciﬁcally,we investigate how well GPT is able to translate Japanesemetaphors into English. We ﬁnd that while GPT is able toproduce high quality sentence translations, it is often notsuccessfully able to identify the key metaphorical word ina longer metaphorical phrase. Nevertheless, we ﬁnd thatusing GPT we are able to easily identify several cases ofJapanese metaphor not present in conventional English."
Q7-10,"We introduce knowledge-aware transfer learning with atext-to-text transfer transformer (KAT5) by leveraging atext-to-text transfer transformer (T5) in the Wikipedia do-main. In standard transfer learning like T5, a model is ﬁrstpre-trained on an unsupervised data task with a languagemodel objective before ﬁne-tuning it on a downstreamtask. In this work, we align large-scale alignments be-tween Wikipedia abstract and Wikidata triples to facilitateour pre-training KAT5 model. Experiment result showsthat KAT5 can match or outperform several downstreamtasks, including question answering, entity and relationextraction, summarization and machine translation."
A10-4,"Document alignment is necessary for the hierarchicalmining [1, 2], which aligns documents across source andtarget languages within the same web domain. Severalhigh-precision sentence embedding-based methods havebeen developed, such as TK-PERT [3] and Optimal Trans-port (OT)[4, 5]. However, given the massive scale ofweb mining data, both accuracy and speed must be consid-ered. In this paper, we propose a cross-lingual sentence-level Bidirectional Maxsim score (BiMax) for computingdoc-to-doc similarity, to improve eﬃciency compared tothe OT method. Meanwhile, we also conduct a compre-hensive analysis to investigate the performance of currentstate-of-the-art multilingual sentence embedding models."
B3-3,本研究は、日本母語話者において人名の音象徴がその名主においてどのような性格特性を想起させるかを検証することを目的に、成人日本語母語話者を対象とした音声提示による架空の人物像の性格印象評定実験を実施した。特に子音の調音法（有声阻害音、無声阻害音、共鳴音）の違いと母音の配列の違い（[aiu]、[iua]、[uai]）の効果を比較検証した。実験では、架空の名前を持つ架空の人物の性格特性の描写を音声提示した上で、その人物像を性格特性の5 因子モデルに基づく指標で評価してもらった。得られたデータの線形混合効果モデリングの結果、子音の阻害音は共鳴音に比べ開放性の高さ、すなわち知的で洗練された様子を想起させること、母音[a]は[i][u]に比べ協調性の高さ、すなわち優しさや温かみのある性格を喚起しやすいことが示唆された。
P4-5,"Various measures of dispersion have been proposed topaint a fuller picture of a word’s distribution in a corpus,but only little has been done to validate them externally. Weevaluate a wide range of dispersion measures as predictorsof lexical decision time, word familiarity, and lexical com-plexity in ﬁve diverse languages. We ﬁnd that the logarithmof range is not only a better predictor than log-frequencyacross all tasks and languages, but that it is also the mostpowerful additional variable to log-frequency, consistentlyoutperforming the more complex dispersion measures. Wediscuss the eﬀects of corpus part granularity and logarith-mic transformation, shedding light on contradictory resultsof previous studies."
P4-4,本研究では，Language Faculty Science の手法を基に，日本語の関係節における Weak Crossover 現象に関する仮説の検証を行った．英語での同様の検証では，非構造的要因を排除しても，関係節の WeakCrossover 構文における照応的解釈が容認されるという結果が得られた．しかし，英語の語順により，その結果が構造的要因と先行関係のどちらに依るものか不明であった．本研究では，日本語の語順を使用することで，関係節における Weak Crossover 構文おける照応的解釈が容認されるのは構造的要因に依るものである可能性が高いことが示された．
B3-2,本研究では，被験者が画像観察時に想起する内容（想起文）の脳活動表現を解明するための新たな手法を模索し，fMRI 信号と LLaVA による画像と言語の統合表現を用いたデコーディングプロセスを構築した．特に，LLaVA が生成するトークン表現とfMRI 信号の時間軸不一致問題に対して，滑動平均による信号のノイズ低減とリッジ回帰による関連性学習を組み合わせることで，解読手法の整合性を向上させた．さらに，生成方式の違いがモデル性能に与える影響を検討し，想起文の脳活動表現の初歩的なデコーディングプロセスとその可能性を示す結果を得た．
A10-5,日本語の発話には，性別や性格などの発話者のキャラクター性が現れることが多い．一方，英語の発話は必ずしもそうではない．そのため，英語の小説を日本語に機械翻訳する際に，発話は発話者のキャラクター性に反する表現で翻訳されることがある．これを防ぐ方法として，発話の翻訳の際に，話者の特徴を反映した話者埋め込みを入力に加えることが考えられる．本論文では，その準備として，日本語の発話文における発話者の特徴の現れている部分をマスクし，その部分を当てることで話者埋め込みを訓練することを試みた．その結果，性別などのキャラクター性を話者埋め込みとして抽出できること，また，発話文における発話者の特徴の現れている部分を推測することに話者埋め込みの利用が効果的であることを示す．
Q9-1,自動要約技術は地方議会の議事録やネットニュースなどの情報の処理に有用だが，生成型要約において数値情報の誤りが問題となっている．本研究は，自動要約における数値情報の正確性を向上させるため，松井らが提案した二つの手法であるセグメントの特定による数値探索手法（SSR: SegmentSummaryRevision）と係り受け解析に基づく数値探索手法（DSR: Dependency-basedSummaryRevision）を組み合わせた手法を提案する．提案手法では，まず原文から要約に用いられている数値が含まれる文を特定し，次に用いて特定した文と要約文の数値を文脈に基づき比較する．この一連の処理により，要約文中の数値を識別し，修正する．
Q7-11,LLM の著しい成果により，LLM を用いたエージェント(LLM Agent)研究が近年増加しており，エージェントに重要なプランニングに LLM が用いられる研究が特に多い．本研究は，認知心理学や論理学から着想を得て，人間の問題解決能力を模倣するフレームワークを提案する．具体的には，複雑なゴールに対して，ルールに沿って，下位の簡単なサブゴールに木構造的に分解していく．評価実験の結果，既存手法と比較して提案手法によるプランニングのステップ数が少なくなることを示した．
Q9-14,"本研究では,和歌に特化した埋め込みモデルとそれを応用した本歌推定モデルを構築する.はじめに事前学習済みの言語モデルを対照学習し和歌に特化した埋め込みモデルを構築する.次にこのモデルから得られる埋め込みベクトルおよびそれから抽出した特徴量を用いて,本歌取りをしている和歌の本歌を推定する機械学習モデルを学習する.本歌とその本歌取りとされる歌のペアデータを用いて本歌推定モデルを評価し,一定の精度で本歌の推定が可能であることを示した."
A8-4,先行研究によれば中国系大規模言語モデル(LLM)には政治的に敏感な問題に回答しないように検閲的なファインチューニングが施されている。本稿は中国系 LLM をベースに日本市場向けにファインチューニングされた LLM を対象に、簡体字中国語の敏感質問への反応を検証した。合計 4 モデルを評価した結果、敏感質問への回答回避比率はベースとなった中国系 LLM よりも大幅に低く、ファインチューニングにより検閲的特徴がかなりの程度解消されていることが分かった。ただし一部には回答回避や検閲の形跡が残っていた。日本語での利用では影響は軽微だと考えられるが、それでも元モデルへの介入を十分に認識したうえで取り扱う必要がある。
Q10-8,本研究では，不動産業界におけるプレスリリースからの情報収集業務を効率化するため，大規模言語モデル（LLM）の出力を統合したアンサンブル手法を提案する．LLM による情報抽出は精度が向上しているものの，複雑なタスクでは抽出漏れや誤抽出が依然として課題であり，結果の信頼性を担保するためには人手による確認が必要とされている．提案手法では，複数の LLM の出力をルールベースで統合し，モデル間の出力の一致を活用して人手チェックの優先順位を付けることで，作業を効率化する．実験の結果，提案手法は LLM を単体で利用した場合と比較して抽出精度が向上し，確認作業の負担を大幅に削減できることが示された．
P6-6,"生成的言語モデルを用いた関係抽出(生成的関係抽出)によって関係抽出の精度は大きく向上したが,再現率が依然低いという問題がある.この問題に対し,本論文では任意の生成的関係抽出に適用できる新手法 Anchoring を提案する. Anchoring はあらかじめ 3 つ組(head, relation , tail)の head の候補となるスパン(anchor)を抽出し,各 anchor に対して個別に生成的関係抽出を行う手法である.評価実験では複数の関係抽出データセットにおいて Anchoring が精度および再現率が向上させることを示した上で,特にhead および tail の抽出性能の向上に寄与すること,および文の主題でない head, tail に対しても頑健性が高まることを示す."
D2-3,本研究は，日本語日常会話において参与者が行う頭部動作（頷き）について，発話との共起位置，共起する行為，連続回数などの観点から分析する．頷きは主要な非言語動作として注目されてきたが，発話との共起関係について体系的な検討は十分になされてきていない．本研究では，『日本語日常会話コーパス(CEJC)』を利用し，いくつかのデータに頷きのアノテーションを施し，CEJC において提供されているアノテーション情報を利用した分析を行った．本研究の結果として，頷きは発話との共起タイミングによって付随する発話のタイプが異なることがわかり，それゆえ発話連鎖上の位置によって異なる機能を持つことが示唆された．
P7-14,"大規模言語モデル(Large Language Model, LLM)によるコード生成は，ソフトウェア開発の効率化に寄与する技術として注目されている．しかし LLM の出力にはハルシネーションを含むことが問題となる．ハルシネーションを含む出力コードはエラーを引き起こす可能性があるため，事前にハルシネーションを検知することが重要である．本研究では，自然言語におけるハルシネーション検知手法である SelfCheckGPT をコード生成に適用する．一般的なコード生成の評価手法である実行ベース評価と，SelfCheckGPT によるコードの評価を比較することで，両者の関連性を確認する．実行ベース評価と比較した結果，特に BLEU，ROUGE-L，EditSim を利用した SelfCheckGPT による評価において，実行ベース評価との関連性が見られた．"
P8-9,検索システムの支援の 1 つであるサジェスト機能は，膨大な検索ログを利用して実装されているため，ローカル文書を対象とした検索システムに転用できない．この課題を解決するために，本研究では，検索対象文書内の単語類似性に基づくサジェスト機能について検討する．本稿では，事前分析として，Wikipedia データで学習された Word2Vec モデルと，検索対象文書集合の特定ドメインデータで追加学習した Word2Vec モデルを用いて，特定ドメインデータの追加学習による単語ベクトルの分布や類似性の変化を定量・定性的に分析する．分析の結果，追加学習したモデルは，特定ドメインにおける語彙の関係性を捉えられており，検索対象文書のドメイン特性を活かしたサジェスト機能の実現可能性を確認した．
P9-11,"We study the automatic detection and generation of hu-morous and ironic text, both in short and long range scenar-ios. For the former, we propose a style-transfer approach,which we utilize to generate humorous news headlines byexploiting a combination of classiﬁcation and generativemodels based on medium-sized language models. For thelatter, we introduce a new dataset of full stand-up comedyspecial scripts, which we use as an arena to generate andclassify humorous content using LLMs."
D4-5,本研究は，支援の場で重視される「個別化の原則」の観点から，心理臨床のカウンセラーと ChatGPT の共通点と相違点を予備的に検討した．熟練カウンセラーは主訴に関する専門的見立ての材料となる情報だけでなく，クライエントの価値観や特性などの個人特有の情報も重視する傾向があり，個別化の原則を高度に実践していることが推察された．一方，ChatGPT は，専門的見立ての材料となる情報を一貫して選択したが，個人特有の情報は選択せず，個別化の原則の点で課題があった．本結果に基づき，対話システム設計の方向性について考察した．
B7-6,用語間の関係は、情報検索や文書作成など、さまざまなタスクに活用できる重要な情報源である。従来の関係性解析手法として定型表現による抽出があるが、低コストである一方、抽出精度に課題があった。埋め込み表現を用いた教師あり学習による解析手法も提案されているが、多くは汎用的に使用される用語を対象とするデータセットを利用しており、特許などの専門的な文書に含まれる用語の特徴を十分に捉えることが困難である。そこで本研究では、大規模言語モデル（LLM）を活用した専門用語間の関係性解析手法を提案する。特許用語を対象とした英語データセットである Google Patent PhraseSimilarity Dataset を利用し、専門用語の文脈的意味を捉えた関係性解析を行う。
P2-18,"ニューラルネットワークの学習中に突然損失が発散する現象はロススパイクと呼ばれ，学習が破綻する原因として知られている.モデルの学習には大きなコストがかかるため,ロススパイクの発生を予防する方法が数多く提案されてきた一方で,スパイクがモデルに与える影響については十分に理解されていない.本稿では,ロススパイクのモデルへの影響について, 2 つのモデル間の損失地形における結びつきを表す線形峰接続性の観点から分析する.小規模な言語モデルをロススパイクが発生する設定を含む複数の学習設定で事前学習し,学習中のチェックポイントを用いてスパイクの影響を分析した.その結果,パラメータがスパイクの前後で大きく異なる位置に変化すること,及び線形峰接続性のパターンが変化することがわかった."
P5-11,企業の事業・財務の内容を把握することは、投資や経営の意思決定などビジネスにおいて、さまざまな場面で必要となる。一つの情報を多角的かつ高品質な情報として整理する必要があるが、実際には、多種多様なフォーマットで書かれた開示資料や公開情報などの読取りには、専門的な知識が必要となることもあり、人手で行うことに大きなコストがかかる。本研究では、有価証券報告書や決算説明会の書き起こしなど、これらの企業情報を一定の形式に整理し、事業の概要を説明する文を生成することを試みる。その生成の方式として、多種多様なテキストの特徴や文章量を均すために、テキストを事前に要約し、RAG を行うことで、生成される概要文の品質を高めることを行った。
P2-24,大規模言語モデル(LLM)がどのような知識を記憶しているかを調べるために，しばしばエンティティに基づく質問応答データセットが利用される．しかし，そのような既存のデータセットはエンティティの単一の表層のみに依存しており，LLM がエンティティを記憶しているのか，特定の表層を記憶しているのかを弁別できない．そのため，本研究ではWikipedia のリダイレクト情報を活用し，複数の表層を考慮可能なエンティティベースの質問応答データセット RedirectQA を構築する．本データセットはエンティティの複数の表層と，それらに対応するカテゴリが付与されており，LLM がどのような表層を記憶しているかの調査に適している．
Q1-8,技能者インタビュー対話コーパス(Expert InterviewDialogue Corpus; EIDC)は，技能のコツを含む発話（コツ発話）の性質や，効果的な引き出し方を解明する目的で構築されている．EIDC は園芸・料理ドメインの技能者インタビュー対話を対象とし，映像・音声，書き起こし，各種アノテーションを収録している．EIDC v.2.0 では，コーパスの一部を対象として，対話の相互行為的な特徴に着目した追加アノテーションを行った．本稿では，追加アノテーションの仕様と定量的特徴を報告し，コツ発話の検出に寄与する特徴を分析する．
P2-2,"Entity tracking is essential for complex reasoning. To per-form in-context entity tracking, language models (LMs)must bind an entity to its attribute (e.g., bind a container toits content) to recall attribute for a given entity. For exam-ple, given a context mentioning “The coﬀee is in Box Z,the stone is in Box M, the map is in Box H”, to infer “BoxZ contains the coﬀee” from the context, LMs must bind“Box Z” to “coﬀee”. To explain the binding behaviour ofLMs, Feng and Steinhardt (2023) introduce a Binding IDmechanism and state that LMs use a abstract concept calledBinding ID (BI) to internally mark entity-attribute pairs.However, they have not captured Ordering ID (OI), namelyordering index of entity, from entity activations that directlydetermines the binding behaviour. In this work, we pro-vide a novel view of the BI mechanism by localizing OI andproving the causality between OI and binding behaviour.Speciﬁcally, we discover the OI subspace and reveal causaleﬀect of OI on binding that when editing activations alongthe OI encoding direction, LMs tend to bind a given entityto other attributes (e.g.,“stone” for “Box Z”) accordingly.The code and datasets used in this paper are available athttps://github.com/cl-tohoku/OI-Subspace."
B5-4,大規模言語モデル(LLM)のコスト削減を主な目的として、特定ドメインに特化した小規模言語モデル(SLM)の開発が急速に進んでいる。この論文では、ソースコードの高速化性能を題材として LLMと SLM を比較し、SLM のコードを壊すリスクが低くなる特性が発揮される事例を示した。また、SLMと LLM を組み合わせることで互いの長所を生かしたコード高速化性能を獲得できることも示した。
Q5-14,"自由記述回答から選択肢設問の生成は LLM の発展に伴い注目されており,調査票の改善と回答者や分析者の負担を減らすことができる.本稿では,データ漏洩のリスクを考慮して, Open-source LLMを組み合わせた自由記述回答から選択肢設問を生成するモデルを構築し,その生成設問を多重対応分析(MCA)による参照空間に射影し,解釈を行った.以上を通して,構築したモデルの機能的有効性を確認した.また,類似度が高く,多様性が低いとされる生成設問でも MCA による幾何学的分析によって解釈可能であることを確認できた."
C8-1,近年，Transformer は多様な NLP タスクで卓越した性能を示す一方，大規模化による計算資源コストの増大が深刻な課題となっている．本研究では，リザバー計算の仕組みに着想し，Transformer の Encoderをなす Encoder ブロックの大部分を固定層（リザバー層），残余ブロックを学習層とすると同時に，固定層・学習層それぞれにおける層間完全パラメタ共有を組み合わせた軽量アーキテクチャを提案する．提案手法により，学習パラメタと更新コストを大幅に削減した．独英翻訳タスクでは，15%超のパラメタ削減にもかかわらず BLEU スコアを約 28 に維持し，学習収束レートをを考慮した性能指標においても従来手法を上回る性能を示した．さらに，本アーキテクチャは離散力学系として解釈でき，高次元非線形変換の再帰的適用によって翻訳に有効な特徴が獲得される可能性を示唆する．本成果は，NLP と非線形ダイナミクスの結節点として新たな視点を提供するものであり，言語モデルにおける情報表現の理解や省メモリ設計に寄与することが期待される．
Q2-21,大規模言語モデル(LLM)の多段推論能力を測るタスクとして、算術推論や演繹推論タスクがある.一般にこれらのタスクは必要な推論ステップ数が長い問題ほど解答が難しいとされている.本研究では推論ステップ数だけでなく、LLM の多段推論間の依存関係に着目し、複雑な依存構造が LLM の最終解答精度にどのように影響するかを分析する.結果として、問題の提示順序や推論の依存関係の深さ、完全な対称性が正答率に影響を与えることがわかった.
Q5-10,一般的な自然言語生成は、探索空間を制限し出力品質を低下させる貪欲法やビーム探索に依存している。最小ベイズリスク(MBR)復号は、自動評価尺度とモデルが生成した擬似参照を利用することでこの問題を緩和する。従来研究では、MBR 復号による生成性能の改善を明らかにするための経験的分析が行われ、様々な観察結果が報告されている。その一方で、それらの理論的な背景は不確かである。これに対処するために、本研究ではバイアス-多様性分解の観点から MBR 復号の新しい理論的解釈を提示する。この解釈では、MBR 復号による仮説の品質推定の誤差を、効用関数と人間の評価との近接性を考慮したバイアスと効用関数の品質推定のばらつきを表す多様性の二つの主要な要因に分解する。理論的分析により、バイアスと多様性の両方を同時に改善することの難しさが明らかになり、多様性を高めることによる MBR 復号の性能向上の妥当性が確認された。また、複数の NLP タスクにおける実験により、理論的特性と合致する結果が観測された。
Q2-19,本研究では，クロスリンガル知識編集における言語間転移と誤った知識の上書きがどの程度生じるかを明らかにするため，新たにデータセットを構築し，評価実験を行った．具体的には，Wikidata から多言語の知識トリプルを収集し，反実仮想の目的語を導入することで，モデルがもともと持つ知識に左右されずに編集効果を測定できる仕組みを整えた．さらに，新指標「過剰適応耐性（OF-TOL）」を提案し，編集対象外の主語に対する誤った知識の上書きを定量化した．Llama-3-8B モデルを用いた検証では，述語の種類や更新パラメータによって言語間転移の度合いが大きく変動する一方，既存知識が上書きされる副作用が一貫して生じることが分かった．
Q2-25,本研究では、大規模言語モデル（LLM）による自動評価手法として、議論形式のマルチエージェントの有効性を検証し、評価性能の向上を試みた。2 つの LLM を協調的に動作させるマルチエージェントシステムを導入し、モデル間で議論を行わせることによって、評価精度を高めることを目指した。結果として、単体モデルによる評価に比べて評価精度が低下することが確認されたが、議論形式を導入することで評価精度を向上させられる可能性が示唆された。
C8-5,機械学習と Bloom Filter (BF)を組み合わせることで，BF のメモリ使用量や計算効率を向上させるLearned Bloom Filter (LBF)が注目を集めている．BFとしての特性上，LBF で採用する機械学習モデルは軽量かつ計算効率に優れていることが求められるが，系列データに対する LBF において，どのような機械学習モデルを採用すれば良いかはまだ十分に議論されていない．本研究では，系列データに対する LBF の機械学習モデルとして，Gated RecurrentUnit (GRU)を考える．また，その構造の簡略化も検討し，それが LBF の性能に与える影響を調査する．
P2-6,大規模言語モデル（LLM）は質問応答や要約文生成などで高い性能を示し，企業での実用化が進んでいる．これに伴い，生成文の文体や口調の制御という新たな需要が高まっているが，従来のプロンプトによる工夫では制御に限界があり，モデルの再学習は計算コストが高いという課題が存在する．本研究では，モデル内部の表現を直接操作するアプローチに着目し，特に日本語の特徴的な口調を対象として，スタイルベクトルの抽出とその制御可能性を検証する．さらに，スタイル間の制御性能の違いを内部表現の観点から分析し，スタイルベクトルの理解を深めることで，LLM のスタイル制御技術の発展に貢献する．
D6-3,近年，記号創発ロボティクスでは，ベイズ脳仮説を始めとした統合情報理論に基づいたマルチモーダル処理や環境との相互作用による概念獲得などの様々な研究が進んでいる．中でも言語創発は，近年注目の研究であり，分散的ベイズ学習によるコミュニケーションモデルが提案されている．そこで本提案手法では，深層モデルへの応用を検討するため，ベクトル量子化を拡張した VQCom-VAE を提案し，実験にてコミュニケーションによる相手の発話から予測画像の生成が可能であることを示した．
P5-15,"音声対話システムにおいて発話終了検知は,ユーザ意図の正確な理解とスムーズな対話の実現に不可欠である.従来の沈黙時間ベースの手法は頑健だが,発話末尾での不必要な待機による応答遅延がユーザ体験を損なう.発話の意味的な内容を考慮するアプローチは,よりスムーズな発話終了検知を実現できる可能性がある一方で,特定のドメインや発話スタイルに依存してしまい,汎用性に乏しいという課題がある.そこで,本稿ではタスク指向対話において,大規模言語モデル（LLM）の文脈理解能力を活用することで,柔軟かつ高速な発話終了検知を実現する新しい手法を提案する.社内で収集した電話音声データを用いて検知の遅延時間を評価し,ベースラインよりも約 37.8%短縮できた."
E9-4,LLM の進展は目覚ましく，人間の言語機能に迫る部分もある．伴って，人間の言語使用を理解するための研究の意義も高まっている．本研究では，言語使用に関するシンプルな課題として「しりとり」に注目し，その特徴に関わる認知的要因を明らかにすることを目的とする．このために，認知アーキテクチャの基本的な記憶メカニズムを基盤としてしりとりの遂行をモデル化し，そのパラメータを調整するシミュレーションによって，しりとりの単語系列に現れる特徴を調査する．結果として，語彙の活性化と抑制や意味的な連想の設定によって，特徴の異なるしりとり単語系列が得られた．しりとりの特徴を制御可能なモデルの構築により，HAI 研究や言語獲得支援研究への刺激としての応用が期待される．
P2-20,言語モデルにおいて，注目する知識をエンコードするニューロンの特定は，モデルの解釈性向上や少数のニューロンの操作による出力の制御の実現に貢献し得る．本研究では，スパースプローブを用いて，隠れ状態における文法情報の局在性を調査した．結果，大部分の層において，隠れ状態の特定の1 ％のニューロンはその補集合からランダムにサンプリングされた 6 倍以上の数のニューロンに匹敵する文法情報を有することが明らかになり，各文法情報が隠れ状態に局在的にエンコードされることが示された．また，一部の文法では，学習したプローブが他の文法に汎化することが明らかになった．
B7-2,本研究では、事故事例文書に含まれる事象を階層的ナレッジグラフ(KG)として構造化する手法を提案する。まず、KG のレイヤ構造を定義し、失敗知識データベース[1]を対象に自動取得システムを実装した。その結果、生成された KG の有用性を確認するとともに、応用可能性を検討した。開発したシステムは GitHub にて公開している1）。
D4-1,"Robotic cognition is a eld that in recent times hasmade strides in developing more comprehensive and help-ful embodied agents. One topic in the eld that remainschallenging is that of long-term memory, particularly life-long learning in real-world environments, where a robotmust process large amounts of multimodal, potentially in-complete, frequently uncertain information in or near real-time. Our team has encountered such a challenge as wedevelop Indy, a companion robot that aims to interact andlearn from complex, human-centric environments. Our at-tempt at tackling these challenges is a tiered framework in-spired by cognitive psychology, in which relevant and use-ful knowledge is compiled and retained for progressivelylonger time spans while incidental observations are ‘‘for-gotten’’ using a decay mechanism also inspired by cogni-tive psychology studies. In this work, we show a proof ofconcept for a ‘‘Narrative Memory,’’ in which Indy storesepisodic memory of its conversations with users as rst-person dialog summaries and salient observations; these‘‘narrative memories’’ are ‘‘forgotten’’ through progres-sively shorter summarization. We use Large-LanguageModels (LLMs) to generate such memories and sum-maries, while also demonstrating their use in conversationthrough an LLM-driven dialogue demo in which Indy can‘‘recall’’ its past conversation topics."
P7-10,本研究では，言語生成タスクにおける参照なし自動評価の改善のために，大規模言語モデルの文生成確率に基づく教師なし品質推定の手法を提案する．生成文の品質推定は主に機械翻訳タスクを対象に取り組まれており，先行研究では対訳コーパスで訓練した Transformer や mBART に基づく品質推定が提案されている．先行研究の系列変換モデルよりも大規模なデータで事前訓練した大規模言語モデルは，高性能な品質推定と様々なタスクへの応用が期待できる．機械翻訳およびテキスト平易化における品質推定に関する評価実験の結果，提案手法は機械翻訳では多資源言語対において既存手法の性能を上回り，テキスト平易化では一部の教師あり品質推定の性能を上回ることを確認した．
Q5-8,"With the continuous breakthroughs in the capabilities ofTransformer-based models, NLP research focused on lan-guage style, such as Text Style Transfer (TST), has gradu-ally attracted more attention. Approaches for handling TSTtasks can generally be categorized into two main strategies:disentanglement and entanglement. This paper proposesa method to construct two prompting pipelines based onthese two strategies, utilizing Chain of Thought (CoT) andLarge Language Models (LLMs). We investigate the per-formance of these pipelines on four TST sub-tasks andanalyze their improvements compared to the baseline."
P6-2,大規模言語モデルや基盤モデルの出現に伴い、医療 AI 領域においても言語処理技術の重要性がますます高まっている。その結果、外部の研究者や企業関係者による言語処理学会に対する網羅的調査のニーズという新しい課題が生まれている。我々はこの問題を「知識が少ないドメイン外研究者による、学会の網羅的調査」という新しいタスクとして提案する。また、その解決手法として全論文の共著関係を利用した共著ネットワーク地図の有用性を検討したので報告する。
B1-4,理論言語学における重要な発見の 1 つに，代名詞の特定の解釈が統語構造により制限されるという「交差効果」がある．交差効果は統語構造上の移動操作に基づいて分析されることが標準的であるが，近年，このような統語的な分析では説明しきれない，より一般化された形の交差効果が提唱されている．本研究はこの課題に対して，型理論に基づくアプローチを提案する．具体的には，依存型意味論という枠組みを用いて，意味表示としての型が持つ構造的関係を介して交差効果を分析することにより，従来よりも統一性の高い理論が得られることを主張する．
Q7-15,本研究では，ユーザ属性を考慮した検索拡張生成（RAG）を活用し，学部教育課程に関する質問に応答するチャットボットを構築した．本提案では，学部や入学年度などのユーザ属性に基づき，外部 DBに含まれる全ドキュメントからユーザ属性に合ったドキュメント群を抽出する．そしてこのドキュメント群から質問に適合するパッセージ集合を生成し，質問とともに LLM に入力することで，質問への回答を生成する．提案手法により生成した回答は，全ドキュメントから生成した適合パッセージ集合による回答と比べて，質問内容に関係のない記載を含まない高評価の回答であることを確認した．
Q9-5,"車載ソフト開発を高品質かつ低コストに実現するために，人手による作業をできる限り自動化することが急務となっている．本研究では特に要求仕様書の品質評価(要求インスペクション)において大規模言語モデル(LLM)による自動化が可能であるかを具体的な事例によって分析した．分析対象として過去に人手で行われたインスペクション結果を用いて，どの程度それらの結果を再現することができるかという再現率及び人手では見逃されていた問題箇所がどれくらい漏れなく指摘できるかという適合率を評価し, LLM 活用の有効性と課題を分析した．その結果, LLM 単独では必ずしも十分な精度を得ることができないが,正規表現や形態素解析などのルールベース処理や従来の自然言語処理による前後処理と組合わせることで精度を向上できる示唆を得た."
A10-1,"Neural Machine Translation (NMT) for low-resourcelanguages like Manipur i, a Sino-Tibetan language, is con-strained by limited parallel corpora. This study applies adata augmentation technique, end sentence generation, toimprove Manipuri-English NMT performance by creatingadditional parallel sentence pairs from existing datasets.Experiments on three datasets―the EM corpus, PMIn-dia corpus, and WMT23 corpus ― demonstrate that theproposed method consistently improves translation qual-ity. For the WMT23 dataset, BLEU scores increased from26.7 to 30.0 (Manipuri-to-English) and from 22.5 to 25.1(English-to-Manipuri), with similar gains across other cor-pora.Keywords: Neural Machine Translation, Data Augmen-tation, Low-Resource Language, Manipuri"
Q9-10,時間関係認識は，自然言語理解において必要となる正確な文脈理解のための重要なタスクである．人が用いる常識的な知識を学習させることで，時間関係を捉えることが可能な言語モデルを構築する試みが行われている．本研究では，先行研究[1]の手法に倣って，イベントの生起状態を正規分布で表現し，その位置の相対関係により時間関係識別を行った．その際に大規模言語モデルを用いて，Allen の区間代数[2]の定義に従ってデータセットを新たに生成して学習を行ったところ，モデルの精度向上を確認できた．
D9-6,笑いは人間どうしの対話において多面的なシグナルとして機能するが、これを適切に認識・生成することは、自然な対話の実現を目指す対話システムにとって大きな課題である。本研究では、日本語対話データに対して「笑うことができる文脈（laughable context）」をアノテーションし、さらにその判断の根拠を分類するためのラベルを、大規模言語モデル（LLM）を活用して半自動的に構築した。まず複数のアノテーターにより、対話データの各発話に対して、対話相手が笑うことができるか否かの二値を判定してもらった。次に，LLM を用いてこの二値の判断の根拠を説明する文を生成し、さらにこられを分類する根拠ラベルを生成した。その結果、「共感と親近感」「ユーモアと意外性」「リラックスした雰囲気」などを含む 10 種類のラベルが生成された。また、LLM に上記の二値判断を認識させたところ、 F1 スコアで 43.1%となり、LLM が自然な対話における笑いを認識することの課題と可能性を明らかにした。
P10-9,近年，架空の人物になりきって応答を生成する雑談対話システムの研究が盛んである．多くの研究が「キャラらしさ」の評価を人間による多数決で行っているが，この評価方法がなりきりの正確さを評価できているかは不明である．そこで，本稿では人間同士で「キャラらしさ」のイメージがどのくらい一致しているのかを確認する手法を提案する．具体的には，数名のファンがキャラらしいセリフとキャラらしくないセリフを書き，4 択クイズを作成する．別の人間がクイズを解き，一致率などを分析することでキャライメージの違いを調べる．結果，原作者とファンと作品を知らない人が持つイメージに異なる特徴が見られた．
B3-6,本研究では，心の理論を包括的かつ実応用に近い設定で評価可能なベンチマークである ToMATO を提案する．ToMATO は LLM 同士の情報の非対称性のある対話によって生成される．ToMATO は信念，意図，願望，感情，知識の 5 類型の心的状態及びそれらについての誤信念の理解を包括的に評価できる．さらに対話を入力とし，登場人物の多様な性格特性への頑健性を評価できる点で実応用の設定に近い．実験によって，特に誤信念の理解において最新の LLM でも精度が人間に劣ること等を示す．
P4-1,本研究では『分類語彙表』全項目について単語習得時期を大規模クラウドソーシング調査で収集し、Bayesian Linear Mixed Model でモデリングを行った。同データは https://github.com/masayu-a/WLSP-SchoolGrade にて公開した。
P10-8,対話システムの発展によって，ユーザへのより適応する返答が求められるようになった．この適応する返答を行うために交流分析に注目し，交流分析を用いた対話システム作成を目指している．しかし，交流分析の対話システムには発話単位でのユーザの自我状態と呼ばれる発話者の心の状態の情報が必要になる．本研究では，大規模言語モデルを用いて対話中のテキストから自我状態を推定することを検討する．実験の結果として，プロンプトに文脈情報や自我状態の説明文，分類の例を入力することによって精度向上だけでなく，出力の精度向上も確認した．
Q9-11,複単語表現、すなわちイディオム性を持つ単語の系列の検出は、機械翻訳など様々な下流タスクで重要な役割を果たす。本研究では、これまで複単語表現検出で用いられてこなかった大規模言語モデルのファインチューニングについて検証する。比較対象として、先行研究で優れた性能を示したエンコーダベースのシステムの検証も行う。実験の結果、提案手法が先行手法を大きく上回る性能を見せた。一方、提案手法を含む全手法で、再現率の低さが課題であることも明らかになった。また、モデルサイズを考慮した比較の結果から、メモリ効率の観点ではエンコーダベースの手法に利があることを示唆する。
A8-1,近年，言語モデルの高い性能を実現している仕組みを理解すべく様々な研究が行われているが，これらの研究の中には事前学習によって得られたモデルパラメータを“ニューロン”と見立て，入出力やタスク性能との関連を調べているものがある．本研究では，ニューロンとモデルの学習過程との関係に焦点を当て，ある単語に反応するニューロンが学習中にどのように形成されるのかを，その単語が持つ意味の側面と合わせて分析した．その結果，ある単語のニューロンの形成過程は，その単語と意味的に同類関係にある単語のニューロンの形成過程と類似する傾向が観察された．また，同類関係にある単語間では形成後のニューロンも共通する傾向が見られた．
Q9-4,同時通訳や字幕生成などの音声言語システムに対して，音声入力の途中で随時，構文情報を提供することを目的に，文節が入力されるごとに係り受け構造を同定し出力するという漸進的係り受け解析手法が提案されている．本稿では，さらに豊かな情報を後段のシステムに提供するため，漸進的係り受け解析と未入力文節主辞トークン予測を同時実行する手法を提案する．また，提案手法と人間の漸進的係り受け解析結果を比較し考察する．
Q7-14,本研究では，農業の技術継承にも用いられる長崎県農林業基準技術の文書を基に，各ツールの表構造認識の精度を検証するための正解データセットを作成し，さらに評価ベンチマークである Technical Obtainment and Interpretation of Tables inAgricultural document (TOITA)を構築した．
B1-5,自然言語と言語モデルの一致度合いを定量的に評価するためには，事前準備として自然言語のデータ点に付随する統計的不定性を正確に評価しておくことが前提となる．本研究では，日本語話し言葉における形態素の出現数に対する不定性（修正誤差）を評価した．そして，修正誤差とポアソン誤差をデータに付与した場合の Zipf 則との一致度合いについて，𝜒2検定と KS (Kolmogorov-Smirnov)検定で定量的に比較した．
P6-3,大規模言語モデル（LLM）は多くの自然言語処理タスクで顕著な性能を実現しているが，知識推論のようなタスクでは依然として性能に課題があり，知識トリプルを用いた適応により知識間の関係性を明示的に学習させるアプローチが注目されている．大規模・高精度な学習用トリプルの獲得に有効なのが記号的知識蒸留である．これは LLM の持つ膨大な知識をトリプルとして出力し，知識推論モデルの学習に使用する手法である．この手法ではトリプルの一部に人手評価を行い，フィルタモデルの学習を行っている．本研究では，敵対的な学習を導入することにより，人手評価を必要としない，自動的な記号的知識蒸留を実現する手法を提案し評価する．
Q5-9,本研究では、画像異常検モデルと大規模言語モデル（LLM）と組み合わせることで、より解釈しやすくする新しいアプローチを提案する．異常検知は、製造業や医療分野で不可欠であり、迅速かつ正確な判断が求められるが、その出力が抽象的で理解しづらいことがある．そこで画像処理アルゴリズムによって検知された異常を、LLM を用いて自然言語で説明する言語駆動型説明可能 AI（Language-DrivenExplainable AI）を提案し、異常検知結果の信頼性と透明性の向上を図るまた、その出力が実業務に有用であるかも検証する．
P9-14,本研究では，評価対象抽出を対象とし，その対象タスクと関連したタスクを利用した効果的なfew-shot 選択手法を提案する．評価対象抽出は，テキストから評価の対象となる特定の要素を抽出するタスクであり，データセットの不足が課題となっている．提案手法では，関連タスクとして極性分類のデータを活用し，Information Gain（IG）を用いて few-shot を選択することで，評価対象抽出の訓練データ不足の問題を補いながらモデルの性能向上を目指す．実験では 5 分割交差検証を実施し，ベースラインを上回る精度を達成した．
P7-11,大規模言語モデル(LLM)を多言語対応するためには、あらゆる入力言語において社会的バイアスを抑制することが求められるが、全言語を対象としたラベル付き学習・評価データを整備するのは容易ではない。本研究では、非英語言語へのバイアス抑制における英語のラベル付きデータが担う役割を検証する。日本語を含むアジア圏言語を対象とした評価実験では、英語のラベル付きデータを学習データとして単に流用するだけでは、多言語バイアス抑制効果は限定的であることを示す。追加分析と併せて、ラベル付き学習データが対象言語の表層や文化を反映したものであることの必要性を示唆する。注意:本論文には不快な表現が一部含まれます。
B7-3,法律の改正は国会にて、改正する条や改正内容が告示されるため、新旧対応に関しても国会の告示が正しいと考えられている。しかし、国会が告示した新旧対応の妥当性についての検証がされることは少ない。本研究では国会が告示した法律の新旧対応の妥当性を検証する。検証対象は昭和 22 年に改正された民法の家族法とし、「対応する条文の有無を推定」「対応する条文の推定」の 2 段階に分けて推定を実施する。推定結果を法学的な視点を用いて考察する。
E9-5,音声想起時脳波から想起言語を識別する研究が進められている．音声認識とは異なり，脳波による音声言語識別の研究では，想起区間が明確ではないため，広範囲に想起区間を対象としている．そのため，想起していない区間から言語情報を検出することになるため，識別精度の劣化が考えられる．そこで本稿では，想起言語の識別精度向上を目標に，5 母音を対象とした音声想起時脳波における想起区間検出について報告する．本報告では，定 Q 変換による時間周波数特性とコヒーレンス解析による位相同期を用いて想起と無想起の差異を測るとともに，それらの特徴をもとに 3DCNN により想起区間検出を行った．その結果，位相同期では，最大約 80%の精度で想起区間推定に成功したが，個人差が大きく生じていることが分かった．一方，時間周波数特性を用いた想起区間検出は，約 70%の精度を得た．
P2-21,"大規模言語モデルは文脈内学習(ICL)が可能であることが知られているが,その内部メカニズムについては未だ統一的な見解が存在しない.争点の一つに, ICL によってパラメータを更新することなく未知のタスクに適応可能か,すなわち外挿可能かどうかという点がある.そこで本研究では,二変数一次関数𝑧 =𝑎𝑥+ 𝑏𝑦に基づく算術データセットを構築し,ICL による内挿・外挿能力を定量的に評価した.その結果, ICL によって部分的に未学習のタスクでも解決可能であること,文脈内の例を増加させることで,内挿時と外挿時の内部表現が類似する傾向にあること,学習データ内のタスクの多様性が ICL 能力の創発に重要であることが示唆された."
P5-14,深層学習により高い性能を発揮している汎用音声認識モデルは，ドメインに適応した出力を行うにはファインチューニングによる追加学習を必要としている．先行研究では大規模言語モデルと制御音声合成を用いたデータ拡張による音声認識モデルのファインチューニング手法が提案されているが，コストと未知語の学習の面で課題が残る．本研究では単語のみの制御音声合成を結合した音声データを用いた低コストかつ，高品質なファインチューニング手法を提案する．実験では既存手法と比較して，提案手法によるファインチューニングは 1/3 程度の学習コストでより多くの未知語を学習することができることを示した．
D6-2,記号創発現象をモデル化するために，複数のエージェントが同じ対象を観測し，それを表現する共有されたサインを推論する，集合的予測符号化仮説が提唱されている．その推論方法として，我々は変分ベイズ法に基づく手法を提案し，複数のエージェント間で共有されたサインが形成可能であることを示している．変分ベイズ法は一般的にサンプリングを用いた手法に比べて学習効率が高いことが知られている．本稿では，1 エージェントが得る観測データのみでは正確な名付けが困難な設定や，エージェント数・データ数を増加させた設定を用いて，サンプリングを用いた従来手法との比較実験を行った．実験の結果，従来手法に比べて，より難しい課題に対しても学習が可能であり，大規模な設定でも収束性が高いことが確認された．
B5-1,本研究では，Point-of-Interest (POI)推薦タスクのための少数ショット事例選択手法を提案する．POI 推薦はユーザの移動履歴を元に次にユーザが興味を示す地点(POI)を推薦するタスクである．従来，蓄積された過去の移動履歴から予測モデルを教師あり学習する手法が研究されてきた．本研究では，蓄積された移動履歴に含まれる有益な知識をプロンプトに含める少数ショット事例選択手法を提案する．実験より，事例数が制限されている設定において，無作為に事例を選択するベースライン手法よりも提案手法が ACC@1 を 13.6%向上させることを確認した．
P2-7,本研究では，大規模言語モデル（LLM）の内部において，言語非依存な思考の領域が一般的な言語領域よりもどれほど・どのように切り分けられているのかを調査する．特に算術計算問題をとりあげ，これらのデータの内部表現空間における分布を分析する．実験結果から，算術計算など言語一般とは異なるデータは入力層付近でただちに分離され，また計算式と算数文章題のように似た思考を要する問題同士ですら，どこかの層で同じ領域を占めることはないことが示唆された．すなわち，算術計算と言語の領域は分離されているものの，計算のための普遍的領域が存在するわけではなく，異なるタスク用に異なる数値計算領域が存在する，ある種冗長な様相であることが想定される．
C8-4,大規模言語モデルの実応用では，7B，13B，70Bといったパラメータ数の異なる複数のモデル（モデル系列）を提供することが一般的である．モデル系列の構築は，素朴には各サイズのモデルを個別に構築する必要があり，計算コストは加算的に増加する．本研究では，小さなモデルから段階的に学習を進め，サイズを拡張させながら，モデル系列を構築する手法を提案する．実験では，提案手法が計算コストを削減しつつ，個別にモデル系列を学習する場合と比較して同等以上の性能を達成できることを示す．
Q2-24,"大規模言語モデル（LLM）は,質疑応答等の定性的な推論や数学等の定量的な推論が可能である.一方で,定性的な推論と定量的な推論を組み合わせることが必要な CSV データのような数値データを,統計知識に基づいて自然言語で説明できるかは明らかでない.本研究では,数値データの統計知識に基づいた説明において,説明能力を向上させる効果が高くコストの低い手法を,次の 3 種類の LLM への指示で検証した.すなわち, 1)例も補足もない指示, 2)基本的な統計量等の例示, 3) LLM の役割や分析の目的等の補足,である.その結果,例示よりも補足の方が説明能力を向上させる効果は同等でもコストは低く,数値データを統計知識に基づいて説明できた."
Q5-11,大規模言語モデルによる競技プログラミングのような入力に対し出力が一意に定まるコード生成においては、タスクを小タスクの連続に分割し、それぞれを解決するアプローチが取られている。本研究ではコード内定義関数を利用しタスクの細分化を行うCodeChain と呼ばれる機構について、高難易度の問題における精度向上に向け、関数内関数を利用しさらなる細分化を行うようプロンプトの改修および関数内関数の抽出、評価を追加した。結果、一部のデータ、モデルでは精度の向上が確認できた。
Q2-18,"日本語大規模言語モデルの開発競争が活発化する中、日本の文化や風習に特化した難度の高い評価用ベンチマークが必要になっている。本稿では、現在構築している日本語の多肢選択式質問応答ベンチマーク JamC-QA について述べる。JamC-QA は日本の文化や風習といった国内独自の知識を問う問題を既存のベンチマークの翻訳でなく、1 から作成しており、問題数は 2024 年 12 月現在、1,045 問である。評価実験では、JamC-QA を用いることで、日本固有の知識問題に関するモデル性能の差を確認できた。これは既存の日本語ベンチマークでは見えなかったものである。またスコア向上の余地もあり、解くべき難しさもまだ十分に含むことがわかった。"
Q5-13,ソフトウェアシステムの品質向上には，可読性が高いプログラムが必要不可欠である．特に，処理内容や要素の説明が記述されているコメントやドキュメントは可読性の向上に役立つ．しかし内容の一貫性や明確さ，正確さがの保証が困難であり，高品質なドキュメントの作成には多くの課題がある．またドキュメントが未記載のコード資源も大量に存在しており，コード資源の可用性向上にはドキュメントの整備が必要となる．そこで本稿では，大規模言語モデル(LLM)が可読性の高いドキュメントを生成する能力があるか，Python の関数データからドキュメンテーション文字列である Docstring を LLM で生成し調査する．複数の観点による分析の結果，LLMは概ね形式的であり可読性が高い Docstring が生成可能な一方で，可読性が低いコードに対しては意図しない書き換えなどを行うことが明らかとなった．
C8-6,本稿では，大規模言語モデル（LLMs）の推論能力，特に仮説推論能力を向上させるため，モンテカルロ・マルコフ連鎖（MCMC）を活用した新しいアルゴリズムパイプラインをを提案する．観察を最も適切に説明する仮説と，それを支持する関連前提を効率的かつ計算コストを抑えて探索するため，完全教師なしの MCMC アルゴリズムを導入した．本手法は，関連性の高い前提の順序を優先することで，LLMs における正当な仮説を効果的に構築し，生成文の精度と前提知識の再現率の向上を確認し，仮説推論能力を向上させることを実証している．
P2-5,"In-context Learning (ICL) is a promising few-shot learn-ing paradigm with unclear mechanisms. Existing explana-tions heavily rely on Induction Heads, which fail to accountfor out-of-domain ICL, where query labels are absent indemonstrations. To address this, we model ICL as attributeresolution, where queries are mixtures of some attributes,and ICL identiﬁes and resolves relevant attributes for pre-dictions. In this paper, we propose a mechanistic prototypeusing toy models trained on synthetic data, and observe:(1) even 1-layer Transformers achieve non-trivial accuracy,with limited beneﬁt from additional demonstrations,(2)scaling models eﬀectively improve accuracy, and (3) in-ference operations can be decomposed into label spaceidentiﬁcation and generalized induction, warranting fur-ther exploration."
B5-3,生成系 AI を活用した自動音声認識技術（Automatic Speech Recognition：ASR）は飛躍的に進歩しているが，頻繁に言語コードが切り替わる自然発話（Code-switching：CS）の認識は依然として課題が残る．筆者らは，Whisper large-v3 を用いた多人数CS 発話のテキスト転写技術に基づき，より操作性に優れた多言語対応音声テキスト化アプリ（Multilingual Voice-to-Text App）を開発した．本アプリを使用することで，習得目標言語（Ｌ2）と母語（Ｌ1）が混じる外国語授業の発話を，授業実施者や学習者自身が随時可視化できる．本稿では APP の開発経緯と，日本語と中国語が切り替わる授業発話に APP を用い，認識精度が向上した結果を示す．さらに，ChatGPT を用いた発話内容の質的分析を通じて，簡便に授業を振り返る手法を提案する．
P5-16,"This paper explores emotion-aware speech-to-text trans-lation (ST) using generative error correction (GER) bylarge language models (LLMs). Despite recent advance-ments in ST, the impact of the emotional content has beenoverlooked. First, we enhance the translation of emotionalspeech by adopting the GER paradigm: Finetuned an LLMto generate the translation based on the decoded 𝑁-besthypotheses. Next, we combine the emotion labels into theLLM ﬁnetuning process to enable the model to considerthe emotion content. Experiments show that GER and theintegration of emotion labels are eﬀective on the English-Japanese language pair. This research lays the foundationfor more sophisticated models that consider emotional nu-ances in speech."
P2-23,事前学習済み言語モデルの Feed Forward 層に含まれるニューロンは知識や言語スキルを捉えることが知られている．本研究では，ニューロンの活性値に注目し，ニューロン活性値と出力トークン確率との間に線形関係が存在することを明らかにする．次に，この線形関係の勾配（以降，経験勾配）を効率的に計算する手法 NeurGrad を提案する．さらに，新たに構築した MCEval8K データセットを用いたskill neuron probing を通して NeurGrad で計算した経験勾配に基づく分類器を評価し，ニューロン経験勾配が多様な言語タスクを解ける情報量を有することを示す．
D4-2,購買意欲を向上させるセールス対話システムを実現するためには多面的なユーザの意欲を考慮したデータセットが必要だが、既存データセットにはシステムの想定運用環境で収集された信頼性の高いユーザの意欲に関するデータが含まれていない。本研究では、想定運用環境に基づいた対話データ収集環境を開発し、3 種類のユーザ意欲データを含む日本語セールス対話データセットを構築した。ユーザ評価実験では、発話レベルでユーザの意欲を考慮し、さらにデータセット分析で得られたセールス対話戦略の知見を組み込むことが対話システムによる対話成功率の向上につながることが示唆された。
B7-1,本研究では，大規模言語モデル（Large  LanguageModel: LLM）を活用した日本語固有表現抽出（Named Entity Recognition: NER）の精度向上手法として Self-Reflection の有効性を検証した．Self-Reflectionは，モデルが自身のタスク結果を評価し，反省点を考慮した再試行を行うことで精度を向上させる枠組みである．GPT-4o を対象とした実験では，Few-Shot 学習と組み合わせることで F1-Scoreが 1.6 ポイント向上した．しかし，一部の条件下では精度の低下や評価結果の不正確性が観察され，今後は Few-Shot 設計の最適化が課題となる．本研究の結果は，LLM ベースの日本語 NER 精度向上の指針として，実応用への貢献が期待される．
P7-13,大規模言語モデル(LLM)は目覚ましい発展を遂げているが，その高い性能がどのように獲得されていくのかについての理解は不十分である．本稿では，日本語を多く含む大規模テキストを用いて学習された LLM-jp-3 モデルを対象に，様々なモデルサイズ・下流タスクにおけるモデルの学習過程を分析し，日本語 LLM の内部メカニズムの洞察を深める．分析の結果，LLM の学習過程の下流タスクのスコアの軌跡は，タスクの種類によっていくつかの典型的なパターンに分類できることが示唆された．
P9-16,本研究では，日本語における大規模言語モデルのスタイル変換性能を広く調査する．まず，英語において研究されてきた 11 種類のスタイル変換を対象に，それぞれ 120 件の日本語文対を人手で作成し，日本語スタイル変換の評価用データセットを構築した．そして，12 種類の日本語大規模言語モデルを対象に，0-shot および 20-shot の文脈内学習によるスタイル変換の性能を評価した．評価実験の結果，指示チューニング済みのモデルは指示チューニング前のモデルよりもスタイル変換の性能が大幅に改善されること，パラメータ数の多いモデルの方が few-shot文脈内学習によって性能がより改善されること，factual → romance および oﬀensive → non-oﬀensive のスタイル変換が難しいことが明らかになった．
P6-1,医学研究における自由記述テキストデータは，患者・家族や医療従事者の声を直接反映し，新たな知見の発見や意思決定，施策立案において重要な役割を果たす．しかし，これらのデータを対象とした質的データ分析は，膨大な人的労力を要する.本研究では，希少・難治性疾患患者が新型コロナウイルス感染症の流行期間中に経験した困難を分析対象とし，大規模言語モデル（Large Language Model; LLM）を活用して質的データ分析の自動化を試みた．具体的には，患者・家族の自由記述テキストの各文に対してタグを生成し，タグ間の類似性に基づいて段階的に統合を行う手法を提案した．結果として，提案手法は分析時間を大幅に削減しつつ，人手による分析結果との一定の一致を示した．本研究の成果は，LLM を活用することで，自由記述テキストの効率的な分析手法の実現に向けた基盤を構築するものである．
D2-4,本稿は大規模言語モデル(Large Language Model;LLM)を用いて，時々刻々変化する実世界を考慮したタスク指向対話を実現する手法について述べる．近年，LLM は人間に近い品質の対話生成ができるまでに発展してきているが，対話モデルは汎用利用を想定して構築されており，個別のユーザの状況に応じた対話ができるわけではない．たとえば，自動走行車との対話を想定したとき，車の位置が時々刻々と変化するにつれ，最寄りのコンビニやガソリンスタンド，道路の混雑状況が変化するため，個別の状況に整合した対話を生成する必要がある．BingChat など検索エンジンを組み込んだ LLM も存在するが，個別のユーザが存在している実世界と LLM がリアルタイムにリンクされているわけではない．そこで本研究では，実世界知識をプロンプトに組み込むことにより実世界対話を実現する手法を提案する．また，KVRET 対話データセットを用いて，GPT-4o や Llama  3 を含む各種 LLM におけるファインチューニングおよび ICL の効果を比較する．
A10-2,近年，大規模言語モデルを使った機械翻訳が注目を集めている．しかし，そのモデルの多くは英語中心の言語対のみを対象としており，英語を含まない非英語言語対の翻訳がサポートされておらず，性能が低い問題が残されている．この問題に対して本論文では，対象言語の訓練状況に応じて 3 つに場合分けして，英語中心の翻訳モデルにおいて非英語言語対の翻訳を実現する方法について体系的に検討する．
Q9-6,大規模言語モデル(LLM)は言語生成のみならず，さまざまな NLP タスクにおいて良好な結果を残している．本稿では，談話構造解析の一つである修辞構造解析において顕著な結果を残した，LLM によるシフト還元型解析法を拡張した句構造解析法を提案する．提案法は，シフト還元型解析でありながら，明示的にスタックとキューを持たず，解析位置をあらわすタグとその左右のテキストでそれを代替する．提案手法を，Penn Treebank (PTB)を用いて訓練し，PTB，Multi-domain Constituent Treebank(MCTB)を用いて評価した結果，従来の LLM を用いた seq2seq モデルによる解析法よりもドメインの違いに頑健であり，どのような文長に対しても安定して高い性能であることを確認した．
Q7-16,実店舗での顧客行動シミュレーションは物理的な制約やコストから難しく，WEB のような A/B テストが不可能なため需要が高い．本研究では顧客の店内行動をシミュレートするフレームワーク LISSを提案する．店内をエリア区分し，隣接する棚や商品，滞在時間を LLM で埋め込み化することで，新商品の追加やレイアウト変更が購入率や滞在時間に与える影響を推定する．手法は過去の店舗行動ログを用いて学習し，変更時の行動変化を推論する．EZOHUB TOKYO における実データを用いて商品追加や配置変更の影響，情報拡張による推論安定化，柔軟な条件の設定が可能であることを確認した．実運用向けの推論アプリケーションも開発した．
Q9-13,自然言語の曖昧性の解消は、システムとユーザ間の意味の一致を達成する上で解決すべき重大な課題である。そのためには、実世界での視覚情報と自然言語の統合処理が鍵となる。本研究では、既存のVision & Language Model を対象に、視覚情報を利用した曖昧性理解能力を評価するためのデータセットの検討を行った。さらに、試験的に収集したデータを用いて、曖昧性が解消された文と画像の識別能力を測定することで VLM が視覚情報を活用して曖昧性を解消する能力を評価した。実験結果に基づき、既存モデルの曖昧性解消能力の可能性を探求するとともに、エラーケースの分析を行った。この分析から、モデルが持つ曖昧性に対する弱点と、ベンチマークやデータセットの今後の課題について考察を行った。
A8-3,大規模言語モデル(LLM)に対する心理測定テストにおいて、LLM に内在するメタ知識が測定結果に与える影響を検証するため、ビッグファイブ理論に基づく IPIP-NEO に関するケーススタディを行う。本論文では、LLM に対する IPIP-NEO テストの実施、LLM の訓練時における IPIP-NEO データセットの混入の検証、LLM の IPIP-NEO に関するメタ知識の理解度の検証を行う。検証した 3 種のモデルに関して、性格の指示に対する敏感さが明らかになり、データセットの混入も確認された。また、3 種のモデルのメタ知識への理解度の傾向が確認された。
P4-3,本研究では，ニューラル単語アライメントを用いて言い換え辞書の品質を改善する．大規模な言い換え知識獲得には，対訳コーパス上での単語アライメントに基づく Bilingual Pivoting と呼ばれる手法が用いられてきた．そのため，Bilingual Pivoting で得られる言い換えの品質は単語アライメントの品質に依存する．既存の言い換え辞書は，統計的な単語アライメントに基づく Bilingual Pivoting によって構築されており，単語の意味を考慮せずに言い換えを抽出しているため，獲得できる言い換えの品質に改善の余地がある．本研究では，ニューラル単語アライメントに基づく Bilingual Pivoting を用いて，より高品質な言い換え知識獲得に取り組む．評価実験の結果，本研究で構築した言い換え辞書が適合率と再現率の両方で既存の日本語言い換え辞書を上回った．
Q7-9,質問応答における RAG では，質問文と回答が必ずしも類似関係にないため，回答を含む文脈（チャンク）が検索できない場合がある．我々はこの問題を，質問文から回答をピンポイントに検索する機能（回答検索）を用いて従来の検索結果をリランキングすることで解決する．具体的には生成言語モデルによる質問文のエンコード結果から得られる質問ベクトルを検索キーとし，同じく検索対象のエンコード結果から得られるベクトル列に対し最大内積検索（MIPS）を行う．これらベクトルは次トークン予測用に最適化されているため，MIPS 用に変換する必要がある．このベクトル変換の対照学習を効果的にするため，適応型負例選択と呼ぶ提案手法を用いる．実験では，回答検索によるリランキングにより一貫して検索精度が向上した．
B3-5,"Personality is a fundamental psychological trait thatshapes an individual’s behavior patterns. This paperproposes a novel approach to personality simulation,which aims to simulate some predeﬁned personalitytraits using large language models. We conduct rep-resentation engineer ing and construct a set of person-ality control vectors to enable ﬁne-grained control ofthe strength of personality traits. Additionally, we usea linear model to capture the interdependencies amongpersonality traits. Evaluation based on a real-worldpersonality dataset shows that our proposed personal-ity simulation method outperforms the prompt-basedbaseline method."
B3-4,Flesch-Kincaid 式は，英語の可読性指標として古典的だが代表的であり，近年の大規模言語モデルの出力評価においても用いられている．これらの式は単語あたりの平均文長と音節あたりの平均単語長の線形和であり，この線形和には数十年の長期の使用に耐える，人間の認知に基づく何らかの理論的要因の存在が示唆される．本研究では，これらの式の理論的解析を行いこの理論的要因を明らかにした．先行研究とは異なり，これらの式が「1 文あたりの平均音節数」として解釈できることを示した．学年が上がるにつれて語彙の範囲は拡大する可能性があるが，音節の範囲は学年や年齢に関係なく一定に保たれる．これが，長期に使われ続ける要因であろう．評価実験では，BNC を用いて本理論枠組みの妥当性を確認し，他言語版 FKGL の提案も行う．
Q7-8,多くの文書は表が含まれているため，質問応答において文書内の表に対する質問に正確に回答することは重要である．本研究では，回答の根拠となる表の検索と表に対する推論を必要とする質問応答タスクに取り組んだ．まず，従来手法の比較実験を行い，SQL Agent の回答性能が良いこと，SQL Agent に表画像を入力に加えた手法(SQL Agent-V)が表記揺れに対して頑健である可能性が示唆された．表記揺れに対する頑健性を向上させるために，LangGraphを利用して SQL Agent と SQL Agent-V を質問に応じて動的に切り替える手法を提案し，表記揺れを発生させたデータセットで実験を行うことで提案手法の有効性を確認した．
P4-2,本研究の目的は、意味・テキスト理論で定義されている語彙関数が、大規模言語モデルにおいてどの程度習得されているかを評価することである。複数のオープンソース大規模言語モデルを対象に、特定の語彙関数に関連するデータセットを用いたタスクを実行し、それらの正確率を統計的に分析した。実験結果から、大規模言語モデルは異なる語彙関数に対して正確率に明確な差があることを示した。このことは、モデルが異なる意味関係を理解する能力に違いがあることを示唆している。また、大規模言語モデルのサイズと正確率には強い相関関係が見られることも明らかになった。
A8-2,大規模言語モデル(LLM)は膨大なテキストから学習され，実世界の知識を内包する一方で，幻覚など知識の運用に問題があることが知られている．そのため，LLM の知識評価を行うことが重要である．本研究では，多様なプロンプトを持つデータセット MyriadLAMA を構築し，それを用いた知識評価フレームワーク BELIEF を提案する．In-contextlearning (ICL)を用いて，LLM が有する知識を精度，一貫性，信頼性の観点から多角的な評価を可能にする．実験では，パラメタ数，事前学習コーパス，指示学習の有無などが異なる複数の LLM を対象に知識評価を行い，LLM における事実知識の想起において重要な要素を明らかにする．
Q9-12,否定スコープ認識とは否定要素の影響が及ぶ範囲である否定スコープを特定するタスクである．このタスクはヒューリスティックなルールに基づく手法やニューラルモデルに基づく手法など様々なアプローチで取り組まれている．しかし，言語理論に基づいて否定スコープを求める研究はあまり行われていない．本論文では，否定スコープを言語理論に基づいて求めるアプローチの一つとして CCGに基づく手法を提案する．本手法では，意味表現としてラムダ式を採用し，否定要素とそのスコープの関係を，ラムダ式の関数と引数の関係に関する一つの原理で説明する．否定スコープデータセットを用いて本手法の性能を評価し，手法の課題を明らかにする．
Q7-17,視覚言語モデルは高い画像認識能力を有しており、広告画像理解への応用に注目が集まっている。しかし、既存研究は広告画像単体を対象にしたものに限られている。そのため広告される対象である商材との関係を捉えた広告画像への視覚言語モデルの理解能力は明らかにすることで、自動生成された広告の推薦システム開発の支援に繋がる。そこで本研究では、モデルと人間との解釈の相関を測る評価用フレームワークを広告分野へ応用することでこの能力を明らかにする。実験結果より、視覚言語モデルは広告画像のランキング生成において関係性を十分に考慮できない場合が多かったが、一部のモデルで購買意欲を刺激するという観点を与えた場合に商材と広告画像の関係性を考慮し、ランキングに変化をもたらす可能性が示唆された。
A10-3,"Machine translation (MT) systems often struggle withhandling gender distinctions in languages with grammati-cal gender. In this paper, we evaluate the performance of10 large language models (LLMs) in translating sentencesfrom English, using a dataset of sentences structured as “Iam [demonym].,” into masculine/feminine/neuter forms inGerman, French, Italian, and Spanish. Our results indi-cate that while most models demonstrated the ability togenerate gender-speciﬁc translations, they tend to producemasculine forms more frequently than feminine. For en-tries with non-existing oﬃcial demonyms models eitherapply linguistic rules to generate non-standard forms orrely on alternative constructions."
Q9-7,同時通訳のようなリアルタイム言語処理システムでは，文を構成する要素が順次入力される状況において，その入力に即応した出力が求められる．このようなシステムで構文情報を利用できるようにするために，漸進的係り受け解析の研究が行われている．本論文では，深層学習モデルを用いて，End-to-End で漸進的係り受け解析を行う手法を提案する．本手法では，未入力の係り先文節の主辞予測を同時に実行し，漸進的係り受け解析の精度向上を図る．実験により提案手法の解析性能を評価した．
D2-5,本稿では ChatGPT (GPT-4o)と人間が日本語のジョークをどのように評価するかを比較する．人間が考えたジョークと ChatGPT が生成したジョーク各 9個（1 つを除き全て対話形式）について，「面白さ」「不快さ」「わかりやすさ」の 3 つの観点での評価を調べた．その結果，ChatGPT の評価は人間より「面白さ」「わかりやすさ」において甘く，「不快さ」において厳しめであること，英語ジョークに関する類似研究とは逆に，ChatGPT の生成した日本語ジョークの評価は人間によるものより低くなることが分かった．その背景には人間にはないレベルの客観性，構成的意味計算能力の不十分さがあると主張する．
B1-6,自動形式化とは、自然言語で書かれた数学証明を機械検証可能な形式証明に自動翻訳する技術のことである。この技術は近年の大規模言語モデルの発展に伴って盛んに研究されているが、学習に用いる自然言語証明-形式証明ペアデータの不足が課題となっている。本研究では LLM の逆形式化能力を活用した形式証明の自然言語翻訳手法を提案する。また、自然言語証明の表現に沿って作成した形式証明データに対して本手法を適用し、生成された自然言語証明の品質を分析及び評価する。
P9-17,本研究では，教師有り学習モデルと大規模言語モデルを組み合わせた，レビュー文書の評価値推定に取り組む．低評価なレビュー文書は，高評価なレビュー文書に比べて少数派であることが考えられる．そのような場合，教師有り学習モデルによる分類では，特に少数派のクラスの精度が悪化する傾向がある．そこで，低評価レビュー文書の推定にのみ，追加学習無くタスクを解ける大規模言語モデルを導入する．実験の結果から，教師有り学習モデルやデータ拡張手法よりも少数派クラスの精度が改善したことを確認した．また，大規模言語モデルのみの推定よりも，全体の精度バランスが良いことも確認した．
P7-12,多言語大規模言語モデルでタスクを解く際，非英語のデータを扱う場合であっても，英語指示文が対象言語指示文より効果的である傾向が報告されている．しかし，それらの研究では英語から翻訳されたデータセットや指示文が用いられていることが多く，翻訳特有のバイアス（Translationese）が指示文の言語間の公平な比較を妨げている可能性がある．この問題に対して，本研究では Translationese の影響を排除し，指示文の公平な比較を実現する．結果として，先行研究と異なり，どちらの指示文がより効果的であるかはタスクや分類ラベルによって異なることを示す．また，各指示文を用いる際の生成テキストの特徴や活性化ニューロンの違いを分析する．
D4-3,継続的にユーザと関わる非タスク指向型対話システム実現のため，対話中にシステムが第三者情報をうわさとして共有する手法が注目されている．この手法によりシステムへの満足度を向上させるためには，第三者情報を共有する際に，ユーザにとってより興味深い内容を選択することが重要であると考えられる．本研究では，ユーザにとって興味度の高い情報を共有する対話システム実現の第一歩として，様々な第三者情報に対するユーザの興味度を推定するモデルの構築を目指す．我々は，独自に作成した第三者情報の興味度データセット1）を用いて，GPT-4o をファインチューニングし，また，推定精度を高めるために多段階推定手法，ユーザ属性を考慮する手法を組み合わせることで，第三者情報についての興味度の推定精度をベースモデルよりも 45.4%向上させたモデルを構築した．
P2-22,単語の意味や関連性を低次元のベクトルなどで表現することを単語埋め込みと呼ぶ．単語埋め込みの次元（軸）は，各次元の値が上位の単語から類推されるカテゴリを人手で判断することで解釈できる．本研究では，このカテゴリが解釈できる次元の割合を単語埋め込みの軸の解釈性と定義する．単語埋め込みの軸の解釈性は，独立成分分析による変換を行うと向上することが先行研究で示されている．しかし，その研究の中では単語埋め込みの次元数と同じ次元数で独立成分分析を実施しており，独立成分の粒度を変化させた場合にどの程度の次元が解釈できるかは明らかではない．そこで，本研究では独立成分分析の次元数を変えた際に解釈できる粒度がどの程度かを調査する．実験結果より，独立成分の粒度が大きいほど解釈性が低下することを示した．
E9-6,近年，発話したときの脳波を言語に変換する Brainto Text の研究が進められている．このシステムには，舌や口唇などの調音器官の障害により明瞭な発音が困難である人々への意思伝達支援が期待されている．しかし，脳波は信号雑音比が低い上，調音器官の運動，すなわち調音運動による筋電図信号が重畳されるなど，雑音の重畳が課題である．そこで本研究は，雑音の少ない調音運動前の脳波から日本語 5 母音を認識することを目的とする．特に，言語を音声として出力するための準備を担うブローカ野とウェルニッケ野の2 つの言語中枢に着目する．調音運動前の言語中枢間の位相同期を用いることで，日本語 5 母音の認識精度が 69.6%を達成した．
P5-17,音声翻訳は原言語の音声を目的言語の音声やテキストへ変換する技術であり，近年では原言語の音声を直接目的言語のテキストへ翻訳する End-to-end音声翻訳の研究が進んでいる．本研究では，より音声認識出力の曖昧性を考慮した損失関数を用いた Multi-task 音声翻訳モデルの学習方法を提案し，Hybrid CTC/Attention loss の仕組みへの適用を試みた．実験と分析により，従来モデルと比較し，提案モデルにおける翻訳性能の向上が見られ，曖昧性をある程度多く含む音声入力に対する頑健性の向上が見られることを確認した．
B5-2,近年、大規模言語モデル(LLM)のコード生成能力は飛躍的に上昇し、ソフトウェアエンジニアリングタスクを LLM に適用する研究が多く行われている。本研究では、LLM の並列処理能力に着目し、LLMエージェントを用いないリポジトリレベルでのバグ修正手法を提案する。リポジトリ内から修正が必要なファイルと関数を特定し、各関数を LLM で独立に修正し、統合する。これらを複数のモデルを用いてアンサンブルする。SWE-bench Lite を用いた評価の結果、ファイルの検索と関数の特定は高精度だったが、バグ修正の精度は他のシステムと比べて大きな改善は見られなかった。
D6-1,進化言語学は，動物コミュニケーションシステムと比較しながら，人間言語の普遍的性質や文法一般の起源・進化・創発を説明しようとする．中には，同世代内でのコミュニケーションや，親の発話と子の学習が繰り返す世代間継承を対象とした文化進化研究がある．本研究では，同一状況を言語使用者の概念化によって表現の仕方を変える構文交替現象が世代間継承で創発する条件をシミュレーションにより示す．ここでは親が事象を概念化して発話し，子が概念化された意味を推論し発話と事象の関係を学習する状況を世代間継承と見做す．推論成功の確率が非常に高い場合のみ構文交替が生じた．
P2-4,本研究では，回転行列による位置符号化 RoPE がウェーブレット変換（WT）の一種として解釈できることを示す．しかし，RoPE は WT の利点を十分に活用できていない．そこで本研究では，正弦波のみに集中していた位置符号化の理論的基盤を拡張し，WT の特性を活かした理論的基盤と新しい位置符号化手法を提案する．提案手法は，従来の手法では難しかった最大系列長を超えた符号化を可能にすることを示す．
Q5-12,退院サマリは，退院後の患者のケアを引き継ぐ医療関係者や医療機関に対して，診断結果や入院中の治療に関して正確な情報を共有するのに重要な役割を果たす．その一方で，退院サマリの作成には大量のデータから必要な情報を取捨選択する必要から多くの時間と労力がかかり，多忙な医師にとっては削減したい作業の一つである．本研究では，大規模言語モデルの一つである GPT を用いて，患者情報及び看護記録等のデータから退院サマリを自動生成することを目指す．具体的には，患者基本情報及び看護記録等から引用元を明らかにしつつ，退院サマリを自動生成し，医師が作成した退院サマリと比較することで，生成された退院サマリの評価を行う．検証の結果，GPTが生成する退院サマリは比較的簡素に生成され，データ全体から満遍なく情報を抽出するセクションに関しては精度が低いことが確認された．
