UID,title,authors,keywords,sessions
A1-1,LLMのアテンションヘッドに着目したジェイルブレイク攻撃の分析と防御手法の提案,新井雅稀|芝原俊樹|千葉大紀|秋山満昭|内田真人,,A1:NLPモデルの評価・安全性・信頼性(1)
A1-2,Decoding the Mind of Large Language Models: A Quantitative Analysis of Thought Processes and Biases,廣瀬万響|内田真人,,A1:NLPモデルの評価・安全性・信頼性(1)
A1-3,有害性評価と巻き戻しによる LLM の有害コンテンツ生成回避,山下智也|岡佑依|山中友貴|山田真徳,,A1:NLPモデルの評価・安全性・信頼性(1)
A1-4,大規模言語モデルによる自己説明の忠実性は改善するか？,土井智暉|磯沼大|谷中瞳,,A1:NLPモデルの評価・安全性・信頼性(1)
A1-5,検索拡張生成が信頼度に及ぼす影響：医療分野における分析,尾崎慎太郎|加藤優汰|馮思遠|富田雅代|林和樹|小原涼馬|小山田昌史|林克彦|上垣外英剛|渡辺太郎,,A1:NLPモデルの評価・安全性・信頼性(1)
A1-6,手動設計の敵対的プロンプト手法の体系的分類,佐々木佑|関谷勇司,,A1:NLPモデルの評価・安全性・信頼性(1)
B1-1,自然言語における冪則と統語構造の関係の再考,中石海|吉田遼|梶川康平|福島孝治|大関洋平,,B1:計算・形式言語学(1)
B1-2,自然言語推論への応用を志向したセマンティックパージングの性能評価,船蔵颯|峯島宏次,,B1:計算・形式言語学(1)
B1-3,CCG 統語解析器 lightblue と定理証明器 wani によるJSeM Verbs データセットの自動推論,松原舞|富田朝|戸次大介,,B1:計算・形式言語学(1)
B1-4,一般化交差効果に対する型理論的アプローチ,松岡大樹|戸次大介|谷中瞳,,B1:計算・形式言語学(1)
B1-5,日本語話し言葉における形態素の出現数に対する統計的不定性の評価,田窪洋介|浅原正幸|山崎誠,,B1:計算・形式言語学(1)
B1-6,証明ステップの逆形式化とステップ間の構造解析を通じた形式証明の自然言語翻訳,服部清志|松崎拓也|藤原誠,,B1:計算・形式言語学(1)
C1-1,Toward Argument Structure Parsing in German: A Rule-Based Approach with Linguistic Annotations,HiroyukiMiyashita|JulianMichaelStawecki,,C1:言語資源・アノテーションと評価
C1-2,日本語創造性ベンチマークの構築,福田創|小川隼斗|堀尾海斗|河原大輔|柴田知秀,,C1:言語資源・アノテーションと評価
C1-3,The KISTEC: 日本の大学生の発話データに基づく英語学習者話し言葉コーパスの構築,神澤克徳|瀬戸口彩花|田中悠介|近大志|小林雄一郎|光永悠彦|森真幸|李在鎬,,C1:言語資源・アノテーションと評価
C1-4,SNSからの重要意見抽出のためのデータセット構築及びLLMによる分類検証,矢口一晟|櫻井恵里子|櫻井義尚,,C1:言語資源・アノテーションと評価
C1-5,Swallowコーパスv2: 教育的な日本語ウェブコーパスの構築,服部翔|岡崎直観|水木栄|藤井一喜|中村泰士|大井聖也|塩谷泰平|齋藤幸史郎|YoumiMa|前田航希|岡本拓己|石田茂樹|横田理央|高村大也,,C1:言語資源・アノテーションと評価
C1-6,『日本経済新聞記事オープンコーパス』と『日本語話し言葉コーパス』語義と読みの対応表の作成,大井恵奈|古宮嘉那子|柏野和佳子|浅原正幸,,C1:言語資源・アノテーションと評価
D1-1,ガウス過程による埋め込み点集合の時間遷移のモデル化,相田太一|小町守|小木曽智信|高村大也|持橋大地,,D1:機械学習
D1-2,Transformerデコーダモデルを利用した日本語意味役割において，特徴量抽出位置およびAttention Maskの形状が与える影響,曽和晃太郎|竹内孔一,,D1:機械学習
D1-3,Enhancing Fake News Detection through Consistency Contrastive Learning with MLP-Mixer,ShaodongCui|WenMa|HiroyukiShinnou,,D1:機械学習
D1-4,ベイズ教師なし文境界認識,内海慶|持橋大地,,D1:機械学習
D1-5,テキストの埋め込み表現に基づくデータ増強を用いた X（旧 Twitter）における日本語の皮肉検出,中井紫音|宮本友樹|内海彰,,D1:機械学習
D1-6,大規模言語モデルに対するチューニング手法の調査：内部のアクセス性に基づく分類と比較,中島京太郎|金輝燦|平澤寅庄|榎本大晟|陳宙斯|小町守,,D1:機械学習
E1-1,クレオールは計量的に峻別できるか？,川崎義史|永田亮|高村大也|大谷直輝,,E1:テーマセッション6: 人文学と言語処理(1)
E1-2,対象言語・対象単語を選ばない汎用的な文法化度の定量化手法,永田亮|持橋大地|井戸美里|窪田悠介|高村大也|川崎義史|大谷直輝,,E1:テーマセッション6: 人文学と言語処理(1)
E1-3,文書筆記過程の分析に関わる墨跡の濃淡変化箇所推定手法の性能評価,ゴーチュイリン|中尾泰士,,E1:テーマセッション6: 人文学と言語処理(1)
E1-4,大規模言語モデルを用いた発掘調査報告書からの考古学情報抽出,山本湧大|武内樹治|大内啓樹|高田祐一,,E1:テーマセッション6: 人文学と言語処理(1)
E1-5,近世・近代・現代日本語テキストに対する場所参照表現抽出,片山歩希|東山翔平|大内啓樹|坂井優介|竹内綾乃|坂東諒|橋本雄太|小木曽智信|渡辺太郎,,E1:テーマセッション6: 人文学と言語処理(1)
E1-6,スタイロメトリによるコプト語文献の著者帰属の再検討,宮川創|Eliese-SophiaLincke|HeikeBehlmer,,E1:テーマセッション6: 人文学と言語処理(1)
P1-1,訳出の同時性に特化した評価データを用いた同時音声翻訳モデルの評価と分析,蒔苗茉那|坂井優介|上垣外英剛|渡辺太郎,,P1:ポスター
P1-2,大規模反応データベースを用いた文字列化した化学反応の基盤モデル構築,佐川達也|小島諒介,,P1:ポスター
P1-3,情報抽出による質の高い新規用途アイデアの獲得,谷口友紀|高橋拓誠|大熊智子,,P1:ポスター
P1-4,大規模言語モデルを用いた電子カルテのSOAP作成支援システムの開発,斉藤翼|山中稜斗|北岡教英,,P1:ポスター
P1-5,大規模言語モデルの非対称的意思決定特性：プロスペクト理論要素の実証分析,吉川克正|大萩雅也|高山隼矢,,P1:ポスター
P1-6,BERTを用いた誤訳検出とLLMを用いた誤訳訂正による特許翻訳の自動後編集,武馬光星|西村柾人|宇津呂武仁|永田昌明,,P1:ポスター
P1-7,テキスト生成における最小ベイズリスク復号の理論的な理解に向けて,市原有生希|陣内佑|蟻生開人|森村哲郎|内部英治,,P1:ポスター
P1-8,Domain-Aware Adaptation for Unsupervised Machine Translation,YouyuanLin|RuiWang|ChenhuiChu,,P1:ポスター
P1-9,JParaCrawl Chinese v2.0: クラウドソーシングを用いた日中対訳コーパスの構築,永田昌明|帖佐克己|安田宜仁,,P1:ポスター
P1-10,Towards Modular Fine-tuning of LLM-based Multilingual Neural Machine Translation,ZheCao|YusukeOda|AkikoAizawa|TaroWatanabe,,P1:ポスター
P1-11,順送り訳データに基づく英日同時機械翻訳の評価,土肥康輔|胡尤佳|蒔苗茉那|須藤克仁|中村哲|渡辺太郎,,P1:ポスター
P1-12,Towards Scene Text Translation for Complex Writing Systems,HourKaing|宋海越|丁塵辰|毛剣楠|田中英輝|内山将夫,,P1:ポスター
P1-13,翻訳と言い換え ''（ソース）入力文:（ターゲット）入力文''の学習の有効性,村上仁一,,P1:ポスター
P1-14,Adapting Multilingual Models for Specialized Translation through Mixed Fine-tuning,LiyanWang|HaotongWang|YvesLepage,,P1:ポスター
P1-15,フィールドワークデータによるジンポー語機械翻訳,田口智大|倉部慶太|坂井優介|RitaSengMaiNbanpa,,P1:ポスター
P1-16,BART 文章校正モデルにおけるコピー機構の有用性の検証,北岡佑一|真嘉比愛,,P1:ポスター
P1-17,複数のLLMを活用した機械翻訳のための協力デコーディング,白井尚登|衣川和尭|伊藤均|美野秀弥|河合吉彦,,P1:ポスター
P1-18,mBART for Supervised Gloss-Free Sign Language Translation: Integrating RGB and Facial Keypoint Images,毛剣楠|丁塵辰|KaingHour|田中英輝|内山将夫|松本忠博,,P1:ポスター
P1-19,ニューラルかな漢字変換システム Zenzai,三輪敬太|高橋直希,,P1:ポスター
P1-20,低資源言語のニュース機械翻訳のためのLLM を用いた合成対訳データの生成,伊藤均|白井尚登|衣川和尭|美野秀弥|河合吉彦,,P1:ポスター
P1-21,対訳データを用いた大規模言語モデルの継続事前訓練による特許請求項翻訳,浅見遥斗|近藤海夏斗|宇津呂武仁|永田昌明,,P1:ポスター
P1-22,AoGu: A Japanese-English literary parallel corpus from Aozora Bunko and Project Gutenberg,GuanyuOuyang|XiaotianWang|TakehitoUtsuro|MasaakiNagata,,P1:ポスター
P1-23,修辞構造に基づく分割統治型LLM翻訳,田中邦朋|帖佐克己|平尾努|笹野遼平,,P1:ポスター
P1-24,"Word order of subject, object, oblique, and verb",江原暉将,,P1:ポスター
Q1-1,書き手の孤独感を予測できるか？,藤川直也|伊藤和浩|若宮翔子|荒牧英治,,Q1:ポスター
Q1-2,BCCWJ-WLSP-LUW:『現代日本語書き言葉均衡コーパス』に対する長単位語義情報アノテーション,加藤祥|浅原正幸,,Q1:ポスター
Q1-3,JETHICS: 日本語道徳理解度評価用データセット,竹下昌志|ジェプカラファウ,,Q1:ポスター
Q1-4,説得力および納得度の推定に向けたWebディベートデータセットの構築,大杉康仁|吉田明弘|中辻真,,Q1:ポスター
Q1-5,改正後法令文翻訳のための疑似三つ組コーパスの構築,山腰貴大|小川泰弘|外山勝彦,,Q1:ポスター
Q1-6,Fine-Grained Error Annotations for Sentence Simplification by Large Language Models,XuanxinWU|YukiArase,,Q1:ポスター
Q1-7,小説テキストに対する登場人物アノテーション,大島一海|小川浩平|佐藤理史,,Q1:ポスター
Q1-8,技能者インタビュー対話コーパス (EIDC) v.2.0: コツ発話の同定に向けた相互行為アノテーション,近大志|岡久太郎|YinJouHuang|樽谷洋希|松田思鵬|村脇有吾|黒橋禎夫,,Q1:ポスター
Q1-9,沿革情報を用いた企業名変遷の構造化,澤田悠冶|大内啓樹|安井雄一郎|寺西裕紀|松本裕治|渡辺太郎|石井昌之,,Q1:ポスター
Q1-10,タンパク質立体構造データと紐づけたコーパス作成の試み,佐久間航也|丹羽智美,,Q1:ポスター
Q1-11,BCCWJ-Metaphorにおける比喩表現認定と情報付与作業手順,加藤祥|菊地礼|浅原正幸,,Q1:ポスター
Q1-12,Evaluating Large Language Models in Mongolian,DorjnyamTumur-Ochir|FeiCheng|村脇有吾|ChenhuiChu,,Q1:ポスター
Q1-13,短単位版「関西弁コーパス」の構築と予備的分析,尹熙洙|王竣磊|岡田純子|小木曽智信,,Q1:ポスター
Q1-14,日英対訳ジオパージングデータセット ATD-Para,東山翔平|大内啓樹|藤田篤|内山将夫,,Q1:ポスター
Q1-15,大規模言語モデルを用いた物語分析データセットの効率的構築：日本語物語の話者推定を例として,郷原聖士|上垣外英剛|渡辺太郎,,Q1:ポスター
Q1-16,Zero pronoun annotation in Malay and beyond,野元裕樹|FarhanAthirahbintiAbdulRazak|藤田航平,,Q1:ポスター
Q1-17,ゲーム内テキスト抽出におけるOCRの性能評価―レイアウトと解像度の影響に着目して―,麻子軒,,Q1:ポスター
Q1-18,Tabidachi: 旅行代理店タスク対話コーパス,稲葉通将|千葉祐弥|斉志揚|東中竜一郎|駒谷和範|宮尾祐介|長井隆行,,Q1:ポスター
Q1-19,大規模画像言語モデルは物体の裏側を認識できるか？物体の見えない部分の認識を問うタスクの提案,竹中誠|谷中瞳,,Q1:ポスター
Q1-20,「現代日本語書き言葉均衡コーパス」の拡張―BCCWJ2の構築―,山崎誠|高橋雄太|小木曽智信,,Q1:ポスター
Q1-21,SciGA: 学術論文における Graphical Abstract 設計支援のための統合データセット,川田拓朗|根本颯汰|北田俊輔|彌冨仁,,Q1:ポスター
Q1-22,否定の観点からみた日本語言語理解ベンチマークの評価,湯浅令子|吉田朝飛|加藤芳秀|松原茂樹,,Q1:ポスター
Q1-23,オンライン誹謗中傷検出に向けた裁判例データセット,久田祥平|若宮翔子|荒牧英治,,Q1:ポスター
Q1-24,MATCHA：専門家が平易化した記事を用いたやさしい日本語パラレルコーパス,宮田莉奈|惟高日向|山内洋輝|柳本大輝|梶原智之|二宮崇|西脇靖紘,,Q1:ポスター
A2-1,大規模言語モデルにおける複数の指示追従成功率を個々の指示追従成功率から推定する,原田憲旺|山崎友大|谷口仁慈|小島武|岩澤有祐|松尾豊,,A2:NLPモデルの評価・安全性・信頼性(2)
A2-2,オープン日本語LLMリーダーボードの構築と評価結果の分析,NamgiHan|岡本拓己|石田茂樹|林俊宏|AkimMousterou|BowenChen|宮尾祐介,,A2:NLPモデルの評価・安全性・信頼性(2)
A2-3,pfgen-bench: 日本語事前学習モデルのための文章生成性能評価ベンチマーク,今城健太郎|平野正徳|鈴木脩司|三上裕明,,A2:NLPモデルの評価・安全性・信頼性(2)
A2-4,固有表現抽出におけるタスク特化型BERTと大規模言語モデルの性能比較と実用性評価,黒澤研二|市川聖|原口昌也|狭間美祐希|桜井駿,,A2:NLPモデルの評価・安全性・信頼性(2)
A2-5,大規模言語モデルの規範的推論能力の評価: 論理とリーズニングの観点から,小関健太郎|安東里沙子|森下貴允|阿部裕彦|峯島宏次|岡田光弘,,A2:NLPモデルの評価・安全性・信頼性(2)
A2-6,JaSocial：LLM の社会的知能を評価するための日本語敬語使用フレームワーク,MuxuanLiu|石垣達也|宮尾祐介|高村大也|小林一郎,,A2:NLPモデルの評価・安全性・信頼性(2)
B2-1,Modal DTSによる様相従属化の分析,飯村葵|水野輝之|戸次大介,,B2:計算・形式言語学(2)
B2-2,二重目的語構文，与格構文におけるWeak Crossover現象の分析と検証実験,藤田琴海|DanielPlesniak|福島遥|戸次大介,,B2:計算・形式言語学(2)
B2-3,日本語推論システムlightblueの開発環境構築に向けて,佐伯小遥|富田朝|戸次大介,,B2:計算・形式言語学(2)
B2-4,日本語比較表現のための論理推論システムの構築,三上燿輔|松岡大樹|谷中瞳,,B2:計算・形式言語学(2)
B2-5,自然言語推論システムNeural DTSの学習アルゴリズムの実装,飯沼瑞稀|戸次大介,,B2:計算・形式言語学(2)
B2-6,情報構造の類型論に向けた談話データのコーディング,児倉徳和|中川奈津子|佐藤久美子|吉村大樹,,B2:計算・形式言語学(2)
C2-1,ドメイン特化疑似データを用いたXの感情分析による日経平均株価騰落予測の精度比較,今本竜樹|櫻井義尚,,C2:評判・感情分析，スタイル分析
C2-2,否定語の影響と単語の重要度を考慮した近似VADスコアによる感情認識チャットシステムの開発,徐恃源|尾関智子,,C2:評判・感情分析，スタイル分析
C2-3,BERTに基づいたRussell円環モデルの感情分析,古泳欣|小林一郎,,C2:評判・感情分析，スタイル分析
C2-4,ビジネス文書を対象とした大規模言語モデルを用いた読み手にストレスを与える文章の検出,松永剛之進|野島瞳|森下洋平|青木輝勝,,C2:評判・感情分析，スタイル分析
C2-5,自動プロンプト最適化は個人的選好の予測精度を向上させるか?,劉弘毅|谷中瞳,,C2:評判・感情分析，スタイル分析
C2-6,大規模言語モデルによる感情分析を用いたデータの品質検証と文章校正,内田大貴|一木輝久,,C2:評判・感情分析，スタイル分析
D2-1,グライスの環境とグライスの外,高橋速巳,,D2:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(1)
D2-2,GPT2モデルを用いた感情を考慮する日本語対話生成,竹原和輝|全昌勤,,D2:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(1)
D2-3,日本語日常二人会話における参与者の頷きと共起する発話,臼田泰如|中西菜束萌,,D2:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(1)
D2-4,大規模言語モデルを用いた実世界タスク指向対話におけるICL・ファインチューニングの効果の検証,佐々木裕,,D2:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(1)
D2-5,ChatGPTが考える日本語ジョークの面白さ：人間との比較,中川隼三郎|野元裕樹,,D2:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(1)
E2-1,イノベーティブな言語使用は集団的アイデンティティの指標になりうるか？,伊藤和浩|矢田竣太郎|若宮翔子|荒牧英治,,E2:テーマセッション6: 人文学と言語処理(2)
E2-2,文献レビューにおける構造トピックモデルの活用―　心理学概念セルフ・コンパッションを題材として―,岡野裕仁|村上遥|有海春輝|野村理朗,,E2:テーマセッション6: 人文学と言語処理(2)
E2-3,社会学理論と言語処理技術の接続：ブルデュー理論に基づく言語処理「界」の分析を事例に,高橋祐貴|塚越柚季,,E2:テーマセッション6: 人文学と言語処理(2)
E2-4,大規模言語モデルを用いたサンスクリット辞書の横断的意味探索と意味提示,塚越柚季|大向一輝,,E2:テーマセッション6: 人文学と言語処理(2)
E2-5,語形のベクトル化による最適な言語地図の描画,近藤泰弘|持橋大地,,E2:テーマセッション6: 人文学と言語処理(2)
P2-1,プロンプトの言語による数値時系列解釈能力の変化,新井深月|石垣達也|宮尾祐介|高村大也|小林一郎,,P2:ポスター
P2-2,Representational Analysis of Binding in Language Models,代勤|BenjaminHeinzerling|乾健太郎,,P2:ポスター
P2-3,解釈可能性の高い自動採点モデルを用いた小論文採点支援システムの構築,水野友暉|竹内孔一,,P2:ポスター
P2-4,ウェーブレット位置符号化,岡佑依|長谷川拓|西田京介|齋藤邦子,,P2:ポスター
P2-5,Beyond the Induction Circuit: A Mechanistic Prototype for Out-of-domain In-context Learning,趙羽風|井之上直也,,P2:ポスター
P2-6,LLMにおける内部表現を用いた日本語スタイル制御メカニズムの分析,高橋良允|矢野一樹|成瀬健太|武井美緒|梶佑輔|鈴木潤,,P2:ポスター
P2-7,大規模言語モデル内部における言語と計算領域の区分,木迫璃玖|栗林樹生|笹野遼平,,P2:ポスター
P2-8,Transformer LLMにおける層単位のFFN層の重要度検証,池田航|矢野一樹|高橋良允|李宰成|柴田圭悟|鈴木潤,,P2:ポスター
P2-9,言語モデルのパラメータから探るDetokenizationメカニズム,鴨田豪|BenjaminHeinzerling|稲葉達郎|工藤慧音|坂口慶祐|乾健太郎,,P2:ポスター
P2-10,埋め込み表現の内在次元を測る,片岩拓也|趙羽風|大木哲史,,P2:ポスター
P2-11,誤字に対するTransformerベースLLMのニューロンおよびヘッドの役割調査,辻航平|平岡達也|鄭育昌|荒牧英治|岩倉友哉,,P2:ポスター
P2-12,部分空間の擬似直交性によるTransformer言語モデルの内部表現の解釈,前田晃弘|鳥居拓馬|日髙昇平|井之上直也|大関洋平,,P2:ポスター
P2-13,「数」に着目したLLMの多言語能力の検証,羽根田賢和|岸波洋介|藤井諒|森下睦,,P2:ポスター
P2-14,言語モデルが有する時間的推論に関する事実知識の分析,中屋和樹|松田源立,,P2:ポスター
P2-15,独立成分分析による事前学習済み多言語モデルの層を横断した単語埋め込み表現の分析,北野雄士|西田悠人|坂上温紀|上垣外英剛|渡辺太郎,,P2:ポスター
P2-16,事前学習言語モデルのドメイン適応能力に関する分析：ドメイン特有ニューロンの検出と分析,鈴木雅弘|高柳剛弘|坂地泰紀|和泉潔,,P2:ポスター
P2-17,文脈の記憶と想起を行う状態空間モデルによる状態遷移の分析,山本悠士|松崎拓也,,P2:ポスター
P2-18,ロススパイクの影響分析,杉浦一瑳|栗田修平|小田悠介,,P2:ポスター
P2-19,多言語モデルには言語非依存の処理系統が存在するか,手塚陽大|井之上直也,,P2:ポスター
P2-20,言語モデルの内部表現における文法情報の局所性について,佐藤宏亮|鴨田豪|BenjaminHeinzerling|坂口慶祐,,P2:ポスター
P2-21,算術タスクを用いた文脈内学習による外挿能力の分析,進藤稜真|竹下昌志|ジェプカラファウ|伊藤敏彦,,P2:ポスター
P2-22,単語埋め込みの独立成分分析の軸が解釈できる粒度はどれくらいか？,佐藤祥太|木山朔|中島秀太|小町守|唐堂由其,,P2:ポスター
P2-23,ニューロン経験勾配によるモデル出力の制御と言語知識表現の統合,趙信|江澤輝|吉永直樹,,P2:ポスター
P2-24,Wikipediaリダイレクト情報を活用したエンティティベース質問応答データセットの構築,西田悠人|志子田直輝|岸波洋介|藤井諒|森下睦|上垣外英剛|渡辺太郎,,P2:ポスター
P2-25,TrendScape 1.0: 言語モデルの潜在空間上の概念探索,本田純也|坂本航太郎|高木志郎|林祐輔|小川修平|松尾豊,,P2:ポスター
P2-26,紙とデジタルの違いが書く活動に及ぼす影響：漢字・熟語・慣用表現・四字熟語を対象に,西内沙恵|西川竜矢|嶋田善行|大橋賢一,,P2:ポスター
Q2-1,JHACE: Human-AI Collaborationの評価法の提案，及び，対人スキルの影響の調査,西岡竜生|若宮翔子|清水伸幸|藤田澄男|荒牧英治,,Q2:ポスター
Q2-2,LLMの安全性における大規模人手評価,高橋哲朗|鈴木久美|関根聡,,Q2:ポスター
Q2-3,AnswerCarefully: 日本語LLM安全性向上のためのデータセット,鈴木久美|勝又智|児玉貴志|高橋哲朗|中山功太|関根聡,,Q2:ポスター
Q2-4,llm-jp-judge: 日本語LLM-as-a-Judge評価ツール,中山功太|児玉貴志|鈴木久美|宮尾祐介|関根聡,,Q2:ポスター
Q2-5,アドオン型のLLMアライメント,宮岡佑弥|井上正樹,,Q2:ポスター
Q2-6,英語母語話者と生成AIの文法性判断の差異調査,吉村理一|陳曦|伊藤薫|森部想水,,Q2:ポスター
Q2-7,システム発話を起点とした雑談会話におけるパーソナリティを考慮した話題推薦の検討,藤本裕之|島田陽介|大野実,,Q2:ポスター
Q2-8,ソーシャルメディアからの偽・誤情報データセットとLLM正確性ベンチマークの提案,中里朋楓|大西正輝|鈴木久美|澁谷遊野|高木聡一郎,,Q2:ポスター
Q2-9,An in-depth human study of the mathematical reasoning abilities in Large Language Models,CarolinaDias-Alexiou|EdisonMarrese-Taylor|YutakaMatsuo,,Q2:ポスター
Q2-10,Cultural Adaptability of Multilingual Large Language Models: A Comparative Study in Japanese Workplace Contexts,ZhiweiGao|清水伸幸|藤田澄男|ShaowenPeng|若宮翔子|荒牧英治,,Q2:ポスター
Q2-11,Code LLM 事前学習時の評価データ混入への対策,金山博|大湖卓也|村岡雅康|吉田一星,,Q2:ポスター
Q2-12,大規模言語モデルの分布予測における常識に基づいた割合予測能力の評価,鈴木刀磨|片山歩希|郷原聖士|辻本陵|中谷響|林和樹|坂井優介|上垣外英剛|渡辺太郎,,Q2:ポスター
Q2-13,架空語に対する LLM の知ったかぶりの自動評価,岩本蘭|金山博|村岡雅康|吉田一星,,Q2:ポスター
Q2-14,評価結果の予測確率を用いたLLMによるLLMの相対評価,森田隼功|大林弘明|田村晃裕|濱田充男|加藤恒夫,,Q2:ポスター
Q2-15,Fact-checkingのための補足コンテキストによる情報の拡充,籾井裕貴|滝口哲也|有木康雄,,Q2:ポスター
Q2-16,復号手法が大規模言語モデルにおける不確実性推定に与える影響の調査,橋本航|上垣外英剛|渡辺太郎,,Q2:ポスター
Q2-17,JHARS: RAG設定における日本語Hallucination評価ベンチマークの構築と分析,亀井遼平|坂田将樹|邊土名朝飛|栗原健太郎|乾健太郎,,Q2:ポスター
Q2-18,JamC-QA: 日本固有の知識を問う多肢選択式質問応答ベンチマークの構築,岡照晃|柴田知秀|吉田奈央,,Q2:ポスター
Q2-19,LLMのクロスリンガル知識編集に関する分析,友成光|森下皓文|角掛正弥|今一修|十河泰弘,,Q2:ポスター
Q2-20,Evaluating Robustness of LLMs to Numerical Variations in Mathematical Reasoning,YangYuli|山田寛章|徳永健伸,,Q2:ポスター
Q2-21,大規模言語モデルにおける多段推論の依存構造と推論能力の関係検証,榎本倫太郎|新妻巧朗|栗田修平|河原大輔,,Q2:ポスター
Q2-22,Mitigating Social Bias in Large Language Models by Self-Correction,PanatchakornAnantaprayoon|金子正弘|岡崎直観,,Q2:ポスター
Q2-23,LLM は日本の民話を知っているか？ 妖怪知識評価データセットの構築へ向けて,堤歩斗|陣内佑,,Q2:ポスター
Q2-24,大規模言語モデルの数値データ説明における例示と補足の効果,江部正周|青山敦,,Q2:ポスター
Q2-25,議論形式のマルチエージェント自動評価の詳細分析,内藤悠|佐藤魁|佐々木翔大|鈴木潤,,Q2:ポスター
A3-1,大規模言語モデルはデータ漏洩を隠蔽できるのか,高橋侑成|YoumiMa|金子正弘|岡崎直観,,A3:NLPモデルの評価・安全性・信頼性(3)
A3-2,LLMマルチエージェント間の相互作用の分析,平野皓己|何子軒|清水勇喜|陳曄|土井智暉|谷中瞳,,A3:NLPモデルの評価・安全性・信頼性(3)
A3-3,実用的な品質観点に基づくRAG性能評価用QAデータセットの自動生成,寺井孝則|田原英一|大石悠河|湯浅晃,,A3:NLPモデルの評価・安全性・信頼性(3)
A3-4,日本語論文に特化したPDF文書解析器の構築と性能評価,嘉本名晋|梅澤悠河|長尾浩良|桂井麻里衣,,A3:NLPモデルの評価・安全性・信頼性(3)
A3-5,事前学習データに含まれる社会的バイアスの分析と軽減,宇田川拓真|趙陽|金山博|BishwaranjanBhattacharjee,,A3:NLPモデルの評価・安全性・信頼性(3)
A3-6,ローカルLLMとRAGを用いたPSU診療支援対話システムの検討,林海斗|桐山知彦|尾崎理沙|目黒巧巳|多屋優人|本庄勝|小林七彩|治徳大介|内田真人,,A3:NLPモデルの評価・安全性・信頼性(3)
B3-1,LLM による価格交渉シミュレーションにおけるアンカリング効果の検証,武並佳輝|YinJouHuang|村脇有吾|ChenhuiChu,,B3:心理言語学・認知モデリング(1)
B3-2,「心の中の言葉」はどのように予測できるか？ ―複数のモダリティの特徴に基づく脳活動デコーディングプロセスの構築―,MuxuanLiu|西田知史|小林一郎,,B3:心理言語学・認知モデリング(1)
B3-3,日本語母語話者において人名の音象徴がその人の性格特性の想起に与える影響,平野舜|木山幸子,,B3:心理言語学・認知モデリング(1)
B3-4,英文リーダビリティ指標FKGLはほぼ平均文中音節数である,江原遥,,B3:心理言語学・認知モデリング(1)
B3-5,Shaping Personality of Large Language Models: An Approach Based on Representation Engineering,YinJouHuang|PrakharSaxena|ZiChengZhao,,B3:心理言語学・認知モデリング(1)
B3-6,ToMATO: 心の理論ベンチマークのためのロールプレイングLLMの心的状態の言語化,篠田一聡|北条伸克|西田京介|水野沙希|鈴木啓太|増村亮|杉山弘晃|斎藤邦子,,B3:心理言語学・認知モデリング(1)
C3-1,大規模マルチモーダルモデルにおけるビジョンエンコーダーの付け替えと、日本語に強いモデル作成へ向けて,佐藤諒|木下彰|中田乙一|金箱裕介|麻場直喜,,C3:マルチモーダル(1)
C3-2,物体検出モデルの信頼値を利用したVQAモデルによるぬいぐるみ画像分類,尾関迅|佐藤伶耶|鈴木秀佳|船田眞帆|仲宗根太郎|櫻井義尚,,C3:マルチモーダル(1)
C3-3,Large Vision-Language Modelを用いた非構造ドキュメント画像向け情報抽出,江上尚志|中田百科|福地鈴佳|久保田茉莉花|山根大輝|薬師寺政和,,C3:マルチモーダル(1)
C3-4,複数タスク・複数項目に跨ったマルチモーダル自動評価手法,大井聖也|金子正弘|岡崎直観|井上中順,,C3:マルチモーダル(1)
C3-5,マルチモーダル大規模言語モデルはジェスチャーをどこまで理解しているのか：指標性・図像性・象徴性を問う,西田典起|井上昂治|中山英樹|坊農真弓|高梨克也,,C3:マルチモーダル(1)
C3-6,CLIPのModality Gapを考慮したRAG検索手法の改良,山下修平|白藤大幹|斉藤辰彦,,C3:マルチモーダル(1)
D3-1,日本語日常会話における他者開始修復の分析,坪倉和哉|入部百合絵|北岡教英,,D3:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(2)
D3-2,音声対話システムのための意味的類似度を考慮した予測信頼度モデル,森清忠|河野誠也|アンケルガルシアコントレラス|吉野幸一郎,,D3:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(2)
D3-3,Exploring User Feedback: A Thematic and Sentiment Analysis of User Interactions with LLM-Based Dialogue Robots,MuhammadYezaBaihaqi|AngelGarciaContreras|河野誠也|吉野幸一郎,,D3:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(2)
D3-4,生成AIと俳句創作―「対話」による学習支援はどのように可能か,松永典子,,D3:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(2)
D3-5,非流暢な合成音声,モクタリ明子|波多野博顕|新井潤|キャンベルニック|定延利之,,D3:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(2)
D3-6,採血ロボットに求められるコミュニケーションスタイル,西川寛之,,D3:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(2)
E3-1,日本語長単位語における語彙素推定,尾崎太亮|古宮嘉那子|浅原正幸|小木曽智信,,E3:テーマセッション6: 人文学と言語処理(3)
E3-2,場所表現の地理的曖昧性を解消するための質問内容生成,清水美緒奈|林純子|久田祥平|若宮翔子|荒牧英治|大内啓樹,,E3:テーマセッション6: 人文学と言語処理(3)
E3-3,満洲語古典語における母音調和の計算言語学的考察,坂上温紀|坂井優介|上垣外英剛|渡辺太郎,,E3:テーマセッション6: 人文学と言語処理(3)
E3-4,言語学からみた記号接地，問題？,川原功司,,E3:テーマセッション6: 人文学と言語処理(3)
E3-5,地理的言及に対するエンティティ・リンキングにおける住所階層の利用,三森尊|乾孝司,,E3:テーマセッション6: 人文学と言語処理(3)
E3-6,BERTによる辞書推定システムを用いた近代以前の日本語文書の形態素解析の精度向上,臼井久生|古宮嘉那子|小木曽智信,,E3:テーマセッション6: 人文学と言語処理(3)
P3-1,RoBERTaとT5を用いた2段階モデルによる国語答案の文字認識誤り訂正,鈴木里菜|臼井久生|尾崎太亮|NguyenTuanHung|古宮嘉那子|石岡恒憲|中川正樹,,P3:ポスター
P3-2,自動アノテーションを導入したG-Eval による英文要約課題評価,藤田晃輔|山田寛章|徳永健伸|石井雄隆|澤木泰代,,P3:ポスター
P3-3,IMPARA-GED：言語モデルの文法誤り検出能力に着目した文法誤り訂正の参照文なし自動評価,坂井優介|五藤巧|渡辺太郎,,P3:ポスター
P3-4,生成AIによる多肢選択式語彙問題および錯乱肢の生成と訂正,内田諭|畔元里沙子|吉村理一|伊藤薫,,P3:ポスター
P3-5,言語モデルを用いた看護師国家試験問題の誤答選択肢自動生成,城戸祐世|山田寛章|徳永健伸|木村理加|三浦友理子|佐居由美|林直子,,P3:ポスター
P3-6,統語的複雑性指標を用いたL2日本語学習者エッセイ評価,小畑文佳|田川拓海|小野雄一,,P3:ポスター
P3-7,Incorporating Rule-Based Methods with Prompt-Based Techniques for Indigenous Language Generation,JustinVasselli|ArturoMartínezPeguero|渡辺太郎,,P3:ポスター
P3-8,LLMとDocker環境を統合した対話型言語処理教育プラットフォームの設計と実装,長谷部陽一郎,,P3:ポスター
P3-9,文法誤り訂正における人手評価と自動評価の乖離とその解決,五藤巧|坂井優介|渡辺太郎,,P3:ポスター
P3-10,文法誤り検出/訂正における訓練データと評価データのドメイン不一致による性能向上現象,木村学|永田亮,,P3:ポスター
P3-11,Attention機構を用いた授業発話分析に基づく教員発話に対するアドバイス生成とLLMによる自動評価,大西朔永|児嶋祥成|椎名広光|保森智彦,,P3:ポスター
P3-12,LLM を用いた複数レシピに対する調理計画手法の検討,山口泰弘,,P3:ポスター
P3-13,動的な Few-shot の事例選択を用いた商品属性情報の正規化,岡崎真治|伊東賢二|浅野孝平|稲田和明|張信鵬,,P3:ポスター
P3-14,大規模言語モデルと患者表現辞書を用いた病名診断の精度検証,宇都宮和希|坂野遼平,,P3:ポスター
P3-15,自己教師あり学習を用いた 自由会話音声からの早期アルツハイマー病の予測,桑山芳明|坪倉和哉|入部百合絵|横井克典|中村昭範|北岡教英|勝野雅央,,P3:ポスター
P3-16,CloudArchitectBuddy 構造的状態制御に基づくシステム主導型設計支援,小比田涼介|春日瑛,,P3:ポスター
P3-17,国語科共通テスト試行調査を用いたRAGによる答案生成の評価と再検索RAGの提案,一柳壮綱|古宮嘉那子|石岡恒憲|中川正樹,,P3:ポスター
P3-18,大規模言語モデルを用いた講義振り返りテキストからの学生の成績推定,青野広太郎|笹野遼平,,P3:ポスター
P3-19,診療データベースを用いたカルテスクリーニング,柴田大作|辻川剛範|渋谷恵|森田智子|久保雅洋|中川敦寛|重田昌吾|島田宗昭,,P3:ポスター
P3-20,大阪大学SEEDSプログラム受講生によるライティング成果の「科学的にダメな点」調査と分析,東山愛|堀一成,,P3:ポスター
P3-21,学生によるプロンプトチューニングを用いた謝罪するロボットのもたらす教育効果,酒造正樹|小野田凌也,,P3:ポスター
P3-22,生成AIによるセリフ文章を利用したタイピングゲーム,鈴木里彩|松吉俊,,P3:ポスター
P3-23,Policy-Value Monte-Carlo 木探索を用いた将棋の解説文に出現する手順の予測,池田大雅|鶴岡慶雅,,P3:ポスター
Q3-1,移動軌跡に関する質問応答データセット,浅野輝|大内啓樹|春日瑛|米谷竜,,Q3:ポスター
Q3-2,LLM-jp-3 VILA: 日本語マルチモーダルデータセット及び強力な日本語マルチモーダルモデルの構築,笹川慶人|前田航希|杉浦一瑳|栗田修平|岡崎直観|河原大輔,,Q3:ポスター
Q3-3,Vision Language Modelを用いた走行画像認識性能の検証,表野理人|針屋慶吾|福田有輝也|米陀佳祐|菅沼直樹,,Q3:ポスター
Q3-4,視覚言語モデルの識別性能に関する評価用ベンチマークの構築,村岡雅康|岡崎直観,,Q3:ポスター
Q3-5,Asagi: 合成データセットを活用した大規模日本語VLM,上原康平|黒瀬優介|安道健一郎|JialiChen|FanGao|金澤爽太郎|坂本拓彌|竹田悠哉|BomingYang|XinjieZhao|村尾晃平|吉田浩|田村孝之|合田憲人|喜連川優|原田達也,,Q3:ポスター
Q3-6,Data Augmentation for Open-Domain Live Commentary Generation,EricaK.Shimomoto|EdisonMarrese-Taylor|小林一郎|高村大也|宮尾祐介,,Q3:ポスター
Q3-7,大規模言語モデルによるセリフを含む物語の可視化手法,瀧本隼矢|竹内孔一,,Q3:ポスター
Q3-8,半自己回帰的に拡散モデルを活用するトレースベースの意図反映キャプション生成,平野理子|小林一郎,,Q3:ポスター
Q3-9,バナー広告における画像と広告コピーの評価ベンチマーク構築,遠藤洸亮|脇本宏平|宮西洋輔|岡崎直観,,Q3:ポスター
Q3-10,高精度な日本語マルチモーダル大規模言語モデルの構築にむけたデータセットの検討,田中幹大|朱佩菲|横尾修平,,Q3:ポスター
Q3-11,ロールプレイングゲームの画面情報分析による選択可能テキストの抽出,狩野竜示|森友亮|荒牧岳志,,Q3:ポスター
Q3-12,大規模視覚言語モデルにおける言語タスクに対する視覚情報の影響,吉田大城|林和樹|坂井優介|上垣外英剛|林克彦|渡辺太郎,,Q3:ポスター
Q3-13,Large Vision Language Modelへの文書画像内テキスト埋め込みの検証,會田勇斗|陳実|森長誠|近江崇宏|有馬幸介,,Q3:ポスター
Q3-14,漫画話者認識における VLM の有効性,呂博軒|能地宏,,Q3:ポスター
Q3-15,How Much Can Large Language Models Guide Body Movements of 3D Digital Human Agents?,KunhangLi|JasonNaradowsky|YansongFeng|YusukeMiyao,,Q3:ポスター
Q3-16,A Study on Multi-modal Interaction in Vision Large Language Models,魏厚静|趙羽風|石鈺亭|井之上直也,,Q3:ポスター
Q3-17,Classifying the Relation Between Images and Text on Social Media Using Vision-Language Models,EdisonMarrese-Taylor|MatissRikters,,Q3:ポスター
Q3-18,Stable Diffusion を利用したシンボルマーク画像の生成,藤本竜也|竹内孔一,,Q3:ポスター
Q3-19,動画データと画像キャプション生成を用いた音とテキストペアの自動生成,石川裕地|齋藤主裕|青木義満,,Q3:ポスター
Q3-20,Open-source Human Evaluation Framework for Video-to-Text and Video-to-Audio Systems,GoranTopic|GrahamNeubig|KatsuhitoSudoh|YukiSaito|ShinnosukeTakamichi|RyosukeMatsushita|KotaIura|HiroyaTakamura|TatsuyaIshigaki,,Q3:ポスター
Q3-21,日本語小論文自動採点システムに関する画像データの活用,森本仁|竹内孔一,,Q3:ポスター
Q3-22,Paper2Poster: LLMを用いた学術ポスターの生成,増田大河|田中翔平|平澤寅庄|牛久祥孝,,Q3:ポスター
Q3-23,llm-jp-eval-mm: 日本語視覚言語モデルの自動評価基盤,前田航希|杉浦一瑳|小田悠介|栗田修平|岡崎直観,,Q3:ポスター
Q3-24,動画キャプション生成におけるマルチモーダル LLM のハルシネーション分析,仲田勝太|近藤雅芳,,Q3:ポスター
Q3-25,VLMによるソフトウェア図表の理解に関する予備調査,高橋舞衣|小原有以|中澤初穂|秋信有花|倉林利行|倉光君郎,,Q3:ポスター
A4-1,大規模言語モデルのための日本語安全性境界テスト,黒澤友哉|高山隼矢|綿岡晃輝|小林滉河|浅原正幸|西内沙恵,,A4:NLPモデルの評価・安全性・信頼性(4)
A4-2,SIPeN: パーソナルナラティブから構築された尺度推意ベンチマーク,佐野朗人|土井智暉|綿引周|谷中瞳,,A4:NLPモデルの評価・安全性・信頼性(4)
A4-3,敵対的事例に対する日本語処理モデルの頑健性向上の試み,秋本一樹|森本文哉|小野智司,,A4:NLPモデルの評価・安全性・信頼性(4)
A4-4,大規模言語モデルにおける社会的バイアスの抑制と文化的常識の理解のトレードオフの分析,山本泰成|九門涼真|DanushkaBollegala|谷中瞳,,A4:NLPモデルの評価・安全性・信頼性(4)
A4-5,コーパスの逆蒸留,盧慧敏|磯沼大|森純一郎|坂田一郎,,A4:NLPモデルの評価・安全性・信頼性(4)
A4-6,大規模言語モデルの法廷通訳への導入可能性の検証,山岸聖子|神藤駿介|宮尾祐介,,A4:NLPモデルの評価・安全性・信頼性(4)
B4-1,アテンションが記憶想起の認知モデルたりうるならば、記憶の表現としては何が妥当か？,吉田遼|磯野真之介|梶川康平|染谷大河|杉本侑嗣|大関洋平,,B4:心理言語学・認知モデリング(2)
B4-2,大規模マルチモーダル言語モデルによる認知症の言語症状の再現,山越貴耀|青山龍平|荒牧英治|大関洋平,,B4:心理言語学・認知モデリング(2)
B4-3,大規模言語モデルによる失語症の単語産出シミュレーション,森田早織|原田宥都|直江大河|沖村宰|大関洋平,,B4:心理言語学・認知モデリング(2)
B4-4,失語症者向け意思疎通支援者の会話方略の評価,嶋﨑百音|森田亜由美|葛西有代|木山幸子,,B4:心理言語学・認知モデリング(2)
B4-5,言語モデルの事前学習におけるバリエーションセットの効果,芳賀あかり|深津聡世|大羽未悠|AriannaBisazza|大関洋平,,B4:心理言語学・認知モデリング(2)
B4-6,作業記憶の発達的特性が言語獲得の臨界期を形成する,三田雅人|吉田遼|深津聡世|大関洋平,,B4:心理言語学・認知モデリング(2)
C4-1,早期うつ状態検出のためのマルチモーダル対話データセットに基づくうつ状態検出モデルの性能評価,柏原功太郎|高鍋俊樹|木内敬太|梅原英裕|入澤航史|中瀧理仁|沼田周助|康シン|吉田稔|松本和幸,,C4:マルチモーダル(2)
C4-2,A Survey of MultiModal Large Language Models,YahanYu|DuzhenZhang|ChenhuiChu,,C4:マルチモーダル(2)
C4-3,VLMを用いたドメイン特化生成画像の定量評価,岡部健太|遠藤隆夫|石上将太郎|中村光貴|仁平雅也|乙村浩太郎|羽藤淳平,,C4:マルチモーダル(2)
C4-4,画像言語モデルにおけるハルシネーションの発生とVisual Attention精度の関係の調査,富田雅代|林克彦|金子知適,,C4:マルチモーダル(2)
C4-5,マルチモーダル大規模言語モデルにおける工業製品画像の認識性能調査,遠藤隆夫|岡部健太|石上将太郎|中村光貴|仁平雅也|乙村浩太郎|羽藤淳平,,C4:マルチモーダル(2)
C4-6,オープンLLMによる翻訳を活用した日本語CLIPの開発,杉浦一瑳|栗田修平|小田悠介|河原大輔|岡崎直観,,C4:マルチモーダル(2)
D4-1,Improving an Assistive Robot's Conversations using Large-Language Model-driven Episodic Memory,AngelFernandoGarciaContreras|Wen-YuChang|河野誠也|Yun-NunCheng|吉野幸一郎,,D4:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(3)
D4-2,多面的なユーザ意欲を考慮したセールス対話データセットおよび対話システムの構築と評価,邊土名朝飛|馬場惇|佐藤志貴|赤間怜奈,,D4:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(3)
D4-3,対話システムが共有する第三者情報に対するユーザの興味度推定モデルの構築,金山凜吾|三野星弥|石黒浩|吉川雄一郎,,D4:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(3)
D4-4,大規模言語モデルによるポライトネス理論の検証,高橋哲朗|宇佐美まゆみ,,D4:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(3)
D4-5,心理臨床のカウンセラーと対話システムの比較：支援における「個別化の原則」に基づく予備的検討,長岡千賀,,D4:テーマセッション2: 人とAIの共生に向けた対話システム・言語使用の研究(3)
E4-1,線形判別分析の PU 学習による朝日歌壇短歌の分析,加藤真大|浦川通|田口雄哉|新妻巧朗|田森秀明|羽根田賢和|坂口慶祐|持橋大地,,E4:テーマセッション6: 人文学と言語処理(4)
E4-2,データドリブンな文章構造と情報伝達の抽出手法,本那真一|村山太一|松井暉,,E4:テーマセッション6: 人文学と言語処理(4)
E4-3,古事類苑の知識グラフ化と言語リソースとしての活用,上松大輝|武田英明|山田奨治|相田満,,E4:テーマセッション6: 人文学と言語処理(4)
E4-4,エイゼンシュテインのモンタージュに含まれる要素,高橋速巳,,E4:テーマセッション6: 人文学と言語処理(4)
P4-1,Bayesian Linear Mixed Model を用いた単語習得時期推定,浅原正幸,,P4:ポスター
P4-2,大規模言語モデルにおける語彙関数知識の類推推論による検討,楊宇軒|郭凱|河野優輝|ルパージュイヴ,,P4:ポスター
P4-3,ニューラル単語アライメントに基づく言い換え知識獲得,近藤里咲|梶原智之|二宮崇,,P4:ポスター
P4-4,日本語の関係節におけるWeak Crossover現象の非構造的要因を制御した経験的検証,福島遥|DanielPlesniak|戸次大介,,P4:ポスター
P4-5,"Dispersion Measures as Predictors of Lexical Decision Time, Word Familiarity, and Lexical Complexity",AdamNohejl|渡辺太郎,,P4:ポスター
P4-6,"In search of efficient, parsing-free encodings of word structure: efficacy comparison among n-grams, skippy n-grams and extended skippy n-grams against on noun classification tasks",黒田航,,P4:ポスター
P4-7,認知負荷の最適化戦略としての自由語順と項省略,梶川康平|磯野真之介|窪田悠介|大関洋平,,P4:ポスター
P4-8,固有名詞の音象徴の機械学習による検討ーポケモンの名前を材料にしてー,新田直弘|久野雅樹,,P4:ポスター
P4-9,認知言語学的イメージスキーマの生成と解釈における大規模言語モデルと画像生成モデルの評価,本田恭平|松﨑孝介|吉田遥音|坂口慶祐,,P4:ポスター
P4-10,自閉スペクトラム症の眼球運動による言語モデルのファインチューニング,前田ありさ|大関洋平,,P4:ポスター
P4-11,LLMはASD小児と定型発達小児が作成したストーリーを識別できるか？,河野真有香|平尾悠太朗|MonicaPerusquía-Hernández|内山英昭|上垣外英剛|清川清,,P4:ポスター
P4-12,社会的承認によって定義された心があるAI：評価方法と有効性の基礎検討,飯田愛結|大澤正彦,,P4:ポスター
P4-13,埋め込みベクトルを用いた動詞の意味の粒度分析と共起関係,森下裕三,,P4:ポスター
P4-14,アジア地域における英語学習者の英語使用の特徴,藤野沙也加|久野雅樹,,P4:ポスター
P4-15,行為要求発話の修辞機能分析－親子会話におけるやり取りに着目して－,田中弥生|居關友里子,,P4:ポスター
P4-16,フレーム意味論に基づく言及先情報を含むSNS投稿の事実忠実度のアノテーション,遠田哲史|吉永直樹|豊田正史,,P4:ポスター
P4-17,大規模言語モデルとISAアプローチ,荒井柚月|津川翔,,P4:ポスター
P4-18,系列ラベリングを用いた日本語の比喩表現抽出,GanbatNaranbuuvei|尾崎太亮|古宮嘉那子|浅原正幸,,P4:ポスター
P4-19,BERT ベクトルを用いたオノマトペ由来の新動詞の検出,古宮嘉那子|宇野良子|浅原正幸,,P4:ポスター
P4-20,LLMのふるまいの理解における理想化された科学モデルの有用性について,平岡太郎|菅原朔,,P4:ポスター
P4-21,言語モデルのふるまいと多重実現,坪井祥吾|菅原朔,,P4:ポスター
P4-22,分類語彙表の基本義を利用した日本語メタファー検出,ZHUHANG|古宮嘉那子|浅原正幸,,P4:ポスター
P4-23,言語一般の計測を目指して: サブワードと分散意味論に基づく言語の複雑性計測,中山拓人,,P4:ポスター
P4-24,言語研究における科学的理解と言語モデル,鈴木陽登|菅原朔,,P4:ポスター
P4-25,文学批評から大規模言語モデルへ―単語埋め込みの組み換えによる文学テクスト解釈の試み,橋本健広,,P4:ポスター
Q4-1,Semantic feature engineering for in-context AutoML,AfonsoLourenço|寛彰金月|司睦田原|GoretiMarreiros,,Q4:ポスター
Q4-2,大規模言語モデルのタスク特化ドメイン適応における知識獲得効率に関する初期検討,小林和馬|相澤彰子,,Q4:ポスター
Q4-3,Ruri: 日本語に特化した汎用テキスト埋め込みモデル,塚越駿|笹野遼平,,Q4:ポスター
Q4-4,医療分野に特化した日本語の小規模言語モデルの開発,渡辺翔吾|連乃駿|今岡幸弘|飯原弘二,,Q4:ポスター
Q4-5,疎なパラメータを用いて大規模言語モデルを効率よくFine-Tuneする手法の提案,原田慎太朗|山崎智弘|吉田尚水,,Q4:ポスター
Q4-6,LLM事前学習の効率化と性質改善： 埋め込み層および出力層のパラメータ固定による再利用,李宰成|矢野一樹|高橋良允|柴田圭悟|池田航|鈴木潤,,Q4:ポスター
Q4-7,LoRAを活用した言語モデルの中間層蒸留,鈴木偉士|山田寛章|徳永健伸,,Q4:ポスター
Q4-8,大規模言語モデルを利用したnetlistによる回路生成,島田優斗|竹内孔一,,Q4:ポスター
Q4-9,Mixture-of-Expertsの悲観的な統合による頑健な自然言語理解,本多右京|岡達志|張培楠|三田雅人,,Q4:ポスター
Q4-10,モデル拡張によるパラメータ効率的な LLM の事前学習,矢野一樹|伊藤拓海|鈴木潤,,Q4:ポスター
Q4-11,大規模言語モデルのためのアライメントデータ合成手法の実験的評価,坂本充生|陣内佑|森村哲郎|阿部拳之|蟻生開人,,Q4:ポスター
Q4-12,対訳構造の指示調整は言語間転移を促進するのか？,佐藤美唯|西潟優羽|秋信有花|倉林利行|倉光君郎,,Q4:ポスター
Q4-13,言語構造の数理分析のための代数統計的アプローチ試論,前田晃弘|鳥居拓馬|日髙昇平,,Q4:ポスター
Q4-14,LLM間と問題間の類似度制約を加えたLLMの性能推定,田村拓也|矢野太郎|榎本昌文|小山田昌史,,Q4:ポスター
Q4-15,真面目 LLM と不真面目 LLM で推論能力は変わるか？,堀尾海斗|河原大輔,,Q4:ポスター
Q4-16,いくつかの意味論的なタスクにおける単一事例規範と対照学習規範の併用,小早川健|塩田雄大|望月貴裕,,Q4:ポスター
Q4-17,Padding vs. Packing: 大規模言語モデルのファインチューニングにおける学習効果の検証,塩野大輝|田中涼太|宮脇峻平|工藤慧音|鈴木潤,,Q4:ポスター
Q4-18,Transformer LLMの内部挙動改善：隠れ状態ベクトルの数値的収束性の向上,柴田圭悟|高橋良允|矢野一樹|李宰成|池田航|鈴木潤,,Q4:ポスター
Q4-19,日本語大規模言語モデルの有用性と安全性の両立に向けたチューニング手法の検証,勝又智|児玉貴志|宮尾祐介,,Q4:ポスター
Q4-20,低資源言語のための辞書を用いた言語間語彙転移,坂上温紀|JustinVasselli|井手佑翼|坂井優介|YingtaoTian|上垣外英剛|渡辺太郎,,Q4:ポスター
Q4-21,情報圧縮を用いた訓練データの重複削減,堤田恭太|村瀬文彦|三谷陽,,Q4:ポスター
Q4-22,話者スタイル抽出と対話フロー生成に基づく対話データ拡張手法,斉志揚|稲葉通将,,Q4:ポスター
Q4-23,Jellyfish: データ前処理のためのLLM,張皓辰|董于洋|肖川|小山田昌史,,Q4:ポスター
Q4-24,トークン・次元・層の3つの観点とクロスファインチューンによるBERTモデル冗長性の解明,福畠汐音|狩野芳伸,,Q4:ポスター
Q4-25,Leveraging Sentiment Adjectives in Instruction Tuning of LLMs for Zero-Shot Sentiment Classification,趙陽|村岡雅康|吉田一星|BishwaranjanBhattacharjee|金山博,,Q4:ポスター
A5-1,層の冗長性と層同士の独立性に基づく言語モデルの層交換の成否の特徴づけ,小林春斗|原知正|鴨田豪|横井祥,,A5:NLPモデルの解釈可能性・分析(1)
A5-2,束縛変項照応を用いた大規模言語モデルのプロービング,松岡大樹|盧捷|小林純一朗|川崎義史|大関洋平|谷中瞳,,A5:NLPモデルの解釈可能性・分析(1)
A5-3,"Tracing the Roots of Facts in Multilingual Language Models: Independent, Shared, and Transferred Knowledge",趙信|吉永直樹|大葉大輔,,A5:NLPモデルの解釈可能性・分析(1)
A5-4,プロンプトに基づくテキスト埋め込みのタスクによる冗長性の違い,塚越駿|笹野遼平,,A5:NLPモデルの解釈可能性・分析(1)
A5-5,定数精度浮動小数点 Transformer Decoder が認識する言語の有限性・余有限性,根岸直生|谷口雅弥|坂口慶祐|乾健太郎,,A5:NLPモデルの解釈可能性・分析(1)
A5-6,知識編集が confidence calibration へ与える影響,長谷川遼|坂井優介|上垣外英剛|渡辺太郎,,A5:NLPモデルの解釈可能性・分析(1)
B5-1,Point-of-Interest 推薦ための少数事例選択,西田遼|川原田将之|高村大也|大西正輝|石垣達也,,B5:言語処理応用
B5-2,関数単位の修正箇所特定によるリポジトリレベルのバグ修正,近藤瑞希|河原大輔|倉林利行,,B5:言語処理応用
B5-3,多言語音声転写アプリとAIによる外国語授業の自己分析―Multilingual Voice-to-Text Appの開発,砂岡和子|徐勤,,B5:言語処理応用
B5-4,ソフトウェア高速化を対象としたLLMとSLMの言語処理特性,飯塚康太|吉藤尚生,,B5:言語処理応用
B5-5,大規模言語モデルを用いた我が国の対米外交における調書作成支援システム,原田武夫,,B5:言語処理応用
B5-6,ChatGPTを活用した高知県観光支援システムの構築,廣瀬水咲|井佐原均,,B5:言語処理応用
C5-1,トラッキングデータからのサッカー実況生成,染谷大河|石垣達也|高村大也,,C5:テキスト生成
C5-2,拡散モデルを用いたテキスト生成における「崩壊問題」と時刻埋め込みの影響,野坂瞭太|松崎拓也,,C5:テキスト生成
C5-3,製造業で取り扱う実データを対象としたRAGの改善,柴田健吾|梶田久貴|杉本崚|森田克明,,C5:テキスト生成
C5-4,大規模言語モデルによる時系列行動セグメンテーションの精度向上,捧蓮|曲佳|三輪祥太郎,,C5:テキスト生成
C5-5,ChatGPTを用いた教育的ノベルゲーム,赤田直弥|村田真樹,,C5:テキスト生成
C5-6,LLM as a Debate Judge: 学習者ディベーターへの自動フィードバック生成,尾崎大晟|市野敬介|松田拓|久保健治|内藤昭一|山口健史|天野祥太朗|井之上直也|中川智皓|新谷篤彦,,C5:テキスト生成
D5-1,構成性の度合いはカオスの縁で最も高くなる ---ESNモデルとTopSim指標を用いたケーススタディ---,上田亮,,D5:テーマセッション5: 言語とコミュニケーションの創発(1)
D5-2,メッセージの階層構造を把握するための parsing action がランダムではないのはなぜか？,加藤大地|上田亮|宮尾祐介,,D5:テーマセッション5: 言語とコミュニケーションの創発(1)
D5-3,音声信号から文字記号を創り出す ―深層ベイズに基づく教師なし表現学習によるアプローチ―,髙橋舜|金崎朝子|須田仁志|SaktiSakriani,,D5:テーマセッション5: 言語とコミュニケーションの創発(1)
D5-4,RNNの回帰行列を凍結しても統語構造の獲得は損なわれない,上田亮|栗林樹生|神藤駿介|乾健太郎,,D5:テーマセッション5: 言語とコミュニケーションの創発(1)
D5-5,キャプション生成ゲームを通じた複数の視覚言語モデルのベイズ的統合,松井悠太|山木良輔|上田亮|品川政太朗|谷口忠大,,D5:テーマセッション5: 言語とコミュニケーションの創発(1)
D5-6,共通基盤の構築に寄与する認知機能:モジュラー生成モデルによるシミュレーション,馬場龍之介|森田純哉|天谷武琉|東中竜一郎|竹内勇剛,,D5:テーマセッション5: 言語とコミュニケーションの創発(1)
E5-1,決算短信における見通し文と結果文のアラインメント,平松悠太|小川泰弘|外山勝彦,,E5:テーマセッション1: 金融・経済ドメインのための言語処理(1)
E5-2,Decoding Sentiment: Predicting Stock Returns from Japanese 10-K Reports with Advanced Large Language Models,山崎高弘|中筋萌|岡田克彦|月岡靖智,,E5:テーマセッション1: 金融・経済ドメインのための言語処理(1)
E5-3,Word-level Polarity is All You Need?: 解釈可能なニューラルネットワークモデルを利用した単語極性変換による効率的な金融センチメント適合,伊藤友貴,,E5:テーマセッション1: 金融・経済ドメインのための言語処理(1)
E5-4,銘柄テキスト情報と銘柄数値情報をハイブリッド活用した企業間類似度の獲得,平松賢士|伊藤友貴,,E5:テーマセッション1: 金融・経済ドメインのための言語処理(1)
E5-5,バリューモデルを活用したサステナビリティ情報抽出： LLMにおける未抽出情報の検証,中尾悠利子|石野亜耶|國部克彦|須貝フィリップ,,E5:テーマセッション1: 金融・経済ドメインのための言語処理(1)
E5-6,エネルギー関連コモディティ先物市場におけるベージュブックテキストの実証分析,市川佳彦|高野海斗|中川慧,,E5:テーマセッション1: 金融・経済ドメインのための言語処理(1)
P5-1,読みにくい日本語文に対する係り受け解析・語順整序・読点挿入の同時実行とその評価,荒木駿介|大野誠寛|松原茂樹,,P5:ポスター
P5-2,レビュー情報を用いた LLM による観光地比較表生成,辻本陵|坪内孝太|山下達雄|松田裕貴|諏訪博彦|大内啓樹,,P5:ポスター
P5-3,Attention スコアの分布類似性を用いた大規模言語モデルの動作効率化および省メモリ化,谷口令|肖川|董于洋|小山田昌史|鬼塚真,,P5:ポスター
P5-4,意味、言語構造、言語の優位性を考慮した多言語文脈内学習,金子正弘|AjiAlhamFikri|TimothyBaldwin,,P5:ポスター
P5-5,二つの時系列データの関係を記述する自然言語文生成手法の実測データ適用への取り組み,中野由加子|小林一郎,,P5:ポスター
P5-6,ASCII CHALLENGE−LLMは画家になれるか−,吉田遥音|羽根田賢和|斉藤いつみ|坂口慶祐,,P5:ポスター
P5-7,文法を基いた逐次選択アプローチによるゲーム記述生成,田中恒彦|シモセラエドガー,,P5:ポスター
P5-8,正解保証を伴う思考プロセス付き合成データ生成による日本語大規模言語モデルの数学推論能力向上,岡田龍樹|平川雅人|大葉大輔,,P5:ポスター
P5-9,生成系タスクの自動評価においてチェックリストの使用は有効なのか？,古橋萌々香|中山功太|児玉貴志|菅原朔,,P5:ポスター
P5-10,判決書要約文の自動評価,新保彰人|山田寛章|徳永健伸,,P5:ポスター
P5-11,クエリ対応の事前要約を伴う大規模言語モデルによる企業事業概要生成,田村光太郎,,P5:ポスター
P5-12,医療事故・ヒヤリハットに関する要因・対策案生成ベンチマークの提案,長谷山優菜|伊藤友貴|坂地泰紀|野田五十樹,,P5:ポスター
P5-13,大規模音声認識モデルに基づく韻律・言語情報を考慮した音声感情認識,福田りょう|叶高朋|安藤厚志|小川厚徳,,P5:ポスター
P5-14,合成単語データを用いた低コスト高品質な音声認識のドメイン適応,小松秀輔|大西一誉|田中康紀|金道鉉|吉野幸一郎,,P5:ポスター
P5-15,タスク指向音声対話における大規模言語モデルを活用した柔軟な発話終了検知の検討,大竹真太|東佑樹|杉山雅和,,P5:ポスター
P5-16,Emotion-aware Speech-to-text Translation with Generative Error Correction,ZhengdongYang|ChenhuiChu,,P5:ポスター
P5-17,音声認識出力の曖昧性を考慮したMulti-task End-to-end音声翻訳と曖昧性の高い音声入力に対する頑健性の分析,胡尤佳|須藤克仁|中村哲|SakrianiSakti,,P5:ポスター
P5-18,対話履歴の LLM 埋め込みを用いた音声合成のスタイル制御,小島淳嗣|藤田雄介|水本智也|吉川克正,,P5:ポスター
P5-19,音声トークナイズが音声言語モデルの性能に与える影響の調査,神藤駿介|宮尾祐介|高道慎之介,,P5:ポスター
P5-20,ReShape Attentionによる音声と言語の基盤モデルの統合,叶高朋|小川厚徳|デルクロアマーク|チェンウィリアム|福田りょう|松浦孝平|芦原孝典|渡部晋治,,P5:ポスター
P5-21,二重分節構造モデルを用いた連続音声からの教師なし音素・単語・文法獲得,落合翔馬|齋藤一誠|長野匡隼|中村友昭,,P5:ポスター
P5-22,大規模言語モデルによるイベント知識グラフからのマルチターンfew-shot実況生成手法の検討,辻村有輝|江上周作|浅田真生|石垣達也|福田賢一郎|高村大也,,P5:ポスター
P5-23,LLM偽針混入テスト：誤抽出を考慮した情報抽出時の評価フレームワーク,叶内晨|深澤祐援|角野為耶|林翔太|小原正大,,P5:ポスター
Q5-1,Low-Overhead Disambiguation for Generative Linguistic Steganography via Tokenization Consistency,RuiyiYan|村脇有吾,,Q5:ポスター
Q5-2,訓練・推論時の不一致を解消する離散拡散テキスト生成モデル,浅田真生|三輪誠,,Q5:ポスター
Q5-3,Generating Explanations of Stereotypical Biases with Large Language Model,YangLiu|ChenhuiChu,,Q5:ポスター
Q5-4,Open Weight LLMs in Out-of-Distribution Setting: Search Ad Title Generation,TolmachevArseny|ForanJoseph|星野智紀|森川裕介,,Q5:ポスター
Q5-5,ClaimBrush: 特許審査官の選好を考慮した選好最適化に基づいた特許請求の範囲の自動補正モデル,河野誠也|野中尋史|吉野幸一郎,,Q5:ポスター
Q5-6,Loss as a Data Introspection Method: Looking into Japanese Advertising Text Generation,JosephForan|ArsenyTolmachev,,Q5:ポスター
Q5-7,タスクベクトル演算を用いた感情表現テキスト生成モデル合成手法,天野椋太|目良和也|黒澤義明|竹澤寿幸,,Q5:ポスター
Q5-8,"Disentanglement or Entanglement, which is Better for TST",徐勝|鈴木良弥|福本文代,,Q5:ポスター
Q5-9,自然言語での異常解釈：LLMを用いたAI説明モデルの提案,山科勇輔|須賀圭一|白井祐典|市川佳彦,,Q5:ポスター
Q5-10,最小ベイズリスク復号におけるバイアスと多様性の分解,上垣外英剛|出口祥之|坂井優介|林克彦|渡辺太郎,,Q5:ポスター
Q5-11,Multi-modularizing CodeChainによるコード生成タスクの細分化が精度に与える影響,井上貴之|鶴岡慶雅,,Q5:ポスター
Q5-12,GPTを用いた退院サマリの自動生成に関する性能評価について,中谷亮太|廣淵亮太|佐藤貴俊|篠原恵美子|岡本康宏|有田悠人|有田隼也|佐藤敏紀|河添悦昌|大江和彦,,Q5:ポスター
Q5-13,大規模言語モデルを用いたソースコードからのドキュメント生成能力調査,杉山咲|蒔苗茉那|片山歩希|坂井優介|山口賢一|渡辺太郎,,Q5:ポスター
Q5-14,自由記述回答から選択肢設問を生成するモデルの構築とMCA参照空間への射影による生成内容の解釈,根本颯汰|土井智暉|花田智洋|谷中瞳|彌冨仁|藤本一男,,Q5:ポスター
Q5-15,情報科学論文の情報量と文章量を維持した自動平易化の試み,大西耕介|菊池英明|藤倉将平,,Q5:ポスター
Q5-16,任意の題目に対する多様な視点の獲得を目的としたラップバトル形式のディベート生成システムの提案,三林亮太|浦川通|高梨大|諸星智也|山岸奏大|関川龍宝|西村保彦|竹内祐太|田森秀明|山本岳洋|大島裕明,,Q5:ポスター
Q5-17,日本語平易化へのTask Arithmeticの応用とその検証,小西修平,,Q5:ポスター
Q5-18,難解な入力単語を用いた日本語 CommonGen タスクによる LLM の文生成能力評価,鈴木雅人|新納浩幸,,Q5:ポスター
Q5-19,係り受け情報と残存文長を考慮した講演テキストへの逐次的な改行挿入,高橋晨成|大野誠寛|松原茂樹,,Q5:ポスター
Q5-20,Iterative Graph-to-Text Generation with Contextualization for Scientific Abstracts,HaotongWang|LiyanWang|YvesLepage,,Q5:ポスター
Q5-21,テキスト埋め込みからのテキスト復元における予測制御の援用の効果検証,三好優輝|宮岡祐弥|井上正樹,,Q5:ポスター
Q5-22,LLMを用いた発話生成のキャラクター性付与におけるプロンプトとファインチューニングの効果比較,中路侑里|狩野芳伸,,Q5:ポスター
Q5-23,Faissを用いたデータ拡張によるポジティブテキストリフレーミングの精度向上,松田龍之介|徐勝|福本文代|鈴木良弥,,Q5:ポスター
Q5-24,日本語ニュース記事要約支援に向けたドメイン特化事前学習済みモデルの構築と活用,石原祥太郎|村田栄樹|高橋寛武|中間康文,,Q5:ポスター
Q5-25,Bidirectional Transformer Reranker for Grammatical Error Correction,YingZhang|上垣外英剛|奥村学,,Q5:ポスター
A6-1,スパースオートエンコーダーを用いた大規模言語モデルのチェックポイント横断分析,稲葉達郎|乾健太郎|宮尾祐介|大関洋平|BenjaminHeinzerling|高木優,,A6:NLPモデルの解釈可能性・分析(2)
A6-2,大規模言語モデルにおいて数値属性間で共有されるスケーリングベクトルの解析とその応用,峰岸剛基|高木洋羽|木澤翔太|助田一晟|谷中瞳,,A6:NLPモデルの解釈可能性・分析(2)
A6-3,競技クイズにおけるLLMと人間の誤答傾向の分析と比較,杉浦尚弥|小川泰弘|外山勝彦|山田康輔|笹野遼平,,A6:NLPモデルの解釈可能性・分析(2)
A6-4,専門ドメインを対象とした事前学習データと精度の関係分析,緒方陸|岡野将大|大曽根宏幸|大久保順一|藤井純一郎,,A6:NLPモデルの解釈可能性・分析(2)
A6-5,Derivational Probing：言語モデルにおける統語構造構築の解明,染谷大河|吉田遼|谷中瞳|大関洋平,,A6:NLPモデルの解釈可能性・分析(2)
A6-6,対照損失による追加学習がBERTのファインチューニングにもたらす効果,竹中誠|瀧雅人,,A6:NLPモデルの解釈可能性・分析(2)
B6-1,医学生物学文献からのオントロジー構築のためのメンション非依存型情報抽出,西田典起|OumaimaElKhettari|ShanshanLiu|RumanaFerdousMunne|山縣友紀|古崎晃司|SolenQuiniou|SamuelChaffron|松本裕治,,B6:知識獲得・情報抽出(1)
B6-2,情報抽出パイプラインにおけるエラー伝播抑制手法の提案：オーバーサンプリング、フィルタリング指向学習、概念対応,西田典起|ShanshanLiu|RumanaFerdousMunne|徳永なるみ|山縣友紀|古崎晃司|松本裕治,,B6:知識獲得・情報抽出(1)
B6-3,多様な言い換え生成と自己学習手法の統合による大規模言語モデルへの新規知識の追加学習,山本貴之|河原大輔,,B6:知識獲得・情報抽出(1)
B6-4,故障解析における事前学習済みSentence-DeBERTaによる拡張ナレッジグラフとクエリ分解を用いたGraphRAG,小島湧太|坂地泰紀|鈴木雅弘|中村格士|坂田大晃|関和也|勅使河原優|山下雅己|青山和浩,,B6:知識獲得・情報抽出(1)
B6-5,法令文の可読性向上のための定義規定・略称規定における文型定義及びパターンベースの正式名称・略称抽出手法,北野尚樹|西山大輝,,B6:知識獲得・情報抽出(1)
B6-6,学術情報のテキスト解析と生成 AI を用いた専門用語抽出,庄金鳴|張馨雲|成凱,,B6:知識獲得・情報抽出(1)
C6-1,Evaluating the Impact of Continual Pre-Training on Japanese Essay Scoring Tasks,BoagoOkgetheng|KoichiTakeuchi,,C6:教育応用
C6-2,強化学習に基づくデータ選別を通した問題横断型小論文自動採点の精度向上,柴田拓海|宇都雅輝,,C6:教育応用
C6-3,難易度調整可能な多枝選択式読解問題自動生成手法とDirect Preference Optimizationによる難易度調整精度の向上,富川雄斗|宇都雅輝,,C6:教育応用
C6-4,LLM を用いた質問生成による児童の作文の詳述化支援の検討,横野光|成家雅史|宮城信,,C6:教育応用
C6-5,Elaborative Text Simplification via Target Estimation using Large Language Models,MartynaGruszka|荒瀬由紀,,C6:教育応用
C6-6,言語指標を用いた日本語文章の難易度の可視化と教育への応用,劉婧怡|内田諭,,C6:教育応用
D6-1,二者関係の概念化に基づく構文交替の文化進化,岩村入吹|橋本敬,,D6:テーマセッション5: 言語とコミュニケーションの創発(2)
D6-2,変分ベイズ名付けゲームに基づく多エージェントによる記号創発の評価,福岡慶太|長野匡隼|中村友昭|谷口彰|谷口忠大,,D6:テーマセッション5: 言語とコミュニケーションの創発(2)
D6-3,Vector Quantizationに基づく離散系列の発話による分散型深層モデルの提案,三好遼|栗田修平,,D6:テーマセッション5: 言語とコミュニケーションの創発(2)
D6-4,AIは人間らしく話ができるか：ロボットと仲良くなるために,川原功司|大道麻由|高橋英之,,D6:テーマセッション5: 言語とコミュニケーションの創発(2)
D6-5,音素の合成性を仮定した連続信号をサインとした分散的ベイズ推論に基づく記号創発,齋藤一誠|劉智優|長野匡隼|中村友昭|谷口彰|谷口忠大,,D6:テーマセッション5: 言語とコミュニケーションの創発(2)
E6-1,金融分野に特化した複数ターン日本語生成ベンチマークの構築,平野正徳|今城健太郎,,E6:テーマセッション1: 金融・経済ドメインのための言語処理(2)
E6-2,大規模言語モデルを用いた有価証券報告書の表質問応答,司龍|張引|王小天|宇津呂武仁,,E6:テーマセッション1: 金融・経済ドメインのための言語処理(2)
E6-3,東京証券取引所におけるティックサイズ変更に関するパブリックコメントの影響分析,丸山博之,,E6:テーマセッション1: 金融・経済ドメインのための言語処理(2)
E6-4,株式掲示板テキストを活用したリターン予測における独立成分分析を利用した解釈性の向上,中島秀太|欅惇志|渡部敏明|小町守,,E6:テーマセッション1: 金融・経済ドメインのための言語処理(2)
E6-5,独立成分分析とFisherの線形判別による内閣府景気ウォッチャー調査データの分析,椎名唯圭|加藤真大|井口亮,,E6:テーマセッション1: 金融・経済ドメインのための言語処理(2)
E6-6,株価変動要因情報を手がかりとする株価変動記事生成へのLLMの適用,西田隼輔|宇津呂武仁,,E6:テーマセッション1: 金融・経済ドメインのための言語処理(2)
P6-1,質的研究の自動化:患者自由記述テキストからの潜在的トピックの発見,橋本清斗|清水聖司|工藤紀子|矢田竣太郎|若宮翔子|江本駿|西村由希子|荒牧英治,,P6:ポスター
P6-2,言語処理学会を外部から調査するための共著者ネットワークを用いた発表予稿の自動地図作成の試み,中原龍一|竹内孔一|片岡裕雄|品川政太朗|高橋康|笠井聡|長谷井嬢|二川摩周|大戸彰三|加藤直人|鎌倉英嗣,,P6:ポスター
P6-3,記号的知識蒸留における敵対的学習の利用とその評価,日浦隆博|河野誠也|AngelGarciaContreras|吉野幸一郎,,P6:ポスター
P6-4,言語モデルの外部知識獲得に関する高速化と小説プロットによる性能評価,近藤碧|小田幹雄,,P6:ポスター
P6-5,尤度最大化に基づく自然言語による多段推論過程の抽出への取り組み,張辰聖子|持橋大地|小林一郎,,P6:ポスター
P6-6,Anchoring を行う生成的関係抽出,広田航|高橋洸丞|BenjaminHeinzerling|QinDai|近江崇宏|乾健太郎,,P6:ポスター
P6-7,Zero-shot Entity Recognition for Polymer Biodegradability Information: GPT-4o on PolyBD,ShanshanLiu|MasashiIshii|YujiMatsumoto,,P6:ポスター
P6-8,From NLI to Classification: Entailment Learning for Low-Resource Text Classification,RumanaFerdousMunne|NorikiNishida|ShanshanLiu|NarumiTokunaga|YukiYamagata|KoujiKozaki|YujiMatsumoto,,P6:ポスター
P6-9,大規模言語モデルを用いた生成による企業の業種体系の拡張,山岸駿秀|貞光九月,,P6:ポスター
P6-10,質問応答によるメールからの送信者情報抽出,大田尾匠|橋本航,,P6:ポスター
P6-11,複数データセットで情報を共有する固有表現抽出,大井拓|三輪誠,,P6:ポスター
P6-12,文献からの有機合成手順の自動抽出と専門家によるその結果の編集作業を支援する枠組み,町光二郎|秋山世治|長田裕也|吉岡真治,,P6:ポスター
P6-13,コミュニティ特有のハッシュタグ空間を考慮したマルチラベル候補生成器を用いる二段階推薦,深澤祐援,,P6:ポスター
P6-14,自己修正に基づく固有表現抽出モデルの指示学習,高橋拓誠|谷口友紀|大熊智子,,P6:ポスター
P6-15,複数エンティティがまとめて記述される可能性を考慮したWikipedia記事のクラス分類,鈴木希望|吉岡真治,,P6:ポスター
P6-16,大規模言語モデルの Zero-Shot トリプル抽出性能の評価,乙村浩太郎|中村光佑|金井美岬|羽藤淳平,,P6:ポスター
P6-17,検索クエリログを用いない自然な質問のマイニングの検討,大村和正|石原祥太郎,,P6:ポスター
P6-18,LLM から抽出した日本文化知識のデータベース構築と活用,大橋巧|彌冨仁,,P6:ポスター
P6-19,日本語継続事前学習モデルを対象とした暗記の定量化,高橋寛武|石原祥太郎,,P6:ポスター
P6-20,災害時のソーシャルメディアを対象とした場所参照表現の抽出における過去事例の適用,六瀬聡宏|宇津圭祐|内田理,,P6:ポスター
P6-21,LLMを用いたクロールデータからの人物略歴文抽出,中野佑哉|猪野麻巳子|二葉知泰|丸山翼|岸本耀平|永井隆広,,P6:ポスター
P6-22,URL引用の要否判定において学習データの品質とドメインが与える影響の分析,和田和浩|角掛正弥|松原茂樹,,P6:ポスター
P6-23,時相論理を用いた物語のエンティティ状態検索,佐藤浩輔|頼展韜,,P6:ポスター
P6-24,シソーラスの階層的構造を利用した弱教師あり固有表現抽出,芝原隆善|山田育矢|西田典起|寺西裕紀|古崎晃司|松本裕治,,P6:ポスター
P6-25,未知の知識に対する事前学習済み言語モデルが持つ推論能力の調査,坂井優介|上垣外英剛|林克彦|渡辺太郎,,P6:ポスター
Q6-1,行動分類のためのコーパス構築と行動分析への応用,中岡明義|若宮翔子|荒牧英治,,Q6:ポスター
Q6-2,JAMSE：日本語LLM評価用の高品質な少サンプル日本語ベンチマークの作成および評価−GENIAC LLM開発コンペティションからの知見−,山崎友大|谷口仁慈|山際愛実|原田憲旺|小島武|岩澤有祐|松尾豊,,Q6:ポスター
Q6-3,複数のLLMを用いた法令QAタスクのGround Truth Curation,植松幸生|大杉直也,,Q6:ポスター
Q6-4,キャッチコピー共同作成対話コーパスにおける第三者評価と自己評価の関係分析,周旭琳|市川拓茉|東中竜一郎,,Q6:ポスター
Q6-5,Enhancing the JNLI Dataset and Evaluating Model Performance on Improved Data,梁俊|藤本博昭|福寄雅洋,,Q6:ポスター
Q6-6,データペーパー:各都道府県が提供する農業関係オープンデータ,大友将宏|石原潤一|橋本祥|桂樹哲雄|二宮芳継|小林暁雄|坂地泰紀|川村隆浩,,Q6:ポスター
Q6-7,オーダーメイド対話管理：商用チャットボットに向けた対話管理学習データ自動作成,馬春鵬,,Q6:ポスター
Q6-8,日本語文章の可読性評価のための項省略判断モデル,久保田智天|石月由紀子|松林優一郎,,Q6:ポスター
Q6-9,日本語によるコード生成能力の正確な評価に向けて,種口暁人|藤井諒|森下睦|鈴木潤,,Q6:ポスター
Q6-10,否定理解能力を評価するための日本語言語推論データセットの構築,吉田朝飛|加藤芳秀|小川泰弘|松原茂樹,,Q6:ポスター
Q6-11,日本語自然言語処理リポジトリに対する研究分野マルチラベルの付与,池田大志|QuanHoangDanh|長野紘士朗|早田啓介,,Q6:ポスター
Q6-12,ルーブリックに基づいたタグを付与した日本語小論文データの構築と自動採点への効果,成岡智也|竹内孔一,,Q6:ポスター
Q6-13,BCCWJ-MEG：日本語脳磁図データの構築,杉本侑嗣|吉田遼|鄭嫣婷|菅野彰剛|小泉政利|大関洋平,,Q6:ポスター
Q6-14,大規模視覚言語モデルの質感知覚能力の分析,松田陵佑|塩野大輝|AnaBrassard|鈴木潤,,Q6:ポスター
Q6-15,Wikidataに基づく大規模ジオコーディングデータセット,中谷響|安井雄一郎|若本亮佑|石井昌之|大内啓樹|渡辺太郎,,Q6:ポスター
Q6-16,根拠に基づいたレビュー生成のための LLM を用いた自動アノテーションの検討,田中翔平|平澤寅庄|牛久祥孝,,Q6:ポスター
Q6-17,Towards Automated Detection of Hype in Biomedical Research,BojanBatalo|EricaK.Shimomoto|NeilMillar,,Q6:ポスター
Q6-18,FaithCAMERA: 広告文生成タスクのための忠実性を担保した評価データセットの構築,加藤明彦|三田雅人|村上聡一朗|本多右京|星野翔|張培楠,,Q6:ポスター
Q6-19,Towards Formalizing Socratic Questions for Explainable Socratic Question Generation,SurawatPothong|PaulReisert|NaoyaInoue|MachiShimmei|WenzhiWang|ShoichiNaito|JungminChoi|KentaroInui,,Q6:ポスター
Q6-20,whole-NWJC: 『国語研日本語ウェブコーパス』全データ,浅原正幸,,Q6:ポスター
Q6-21,パラ言語情報に着目したSpeech-to-Text対話ベンチマークデータセットの提案,中畔彪雅|河野誠也|CanasaiKruengkrai|AngelGarciaContreras|千葉祐弥|杉山弘晃|吉野幸一郎,,Q6:ポスター
Q6-22,ソーシャルメディアテキストを用いた摂食障害の文化差比較,栗生紗希帆|DayeonKim|Hyuk-YoonKwon|若宮翔子|荒牧英治,,Q6:ポスター
Q6-23,LLM を用いたキーワードに基づく文書分類ためのデータ拡張の試みと評価,小野寺優|新納浩幸,,Q6:ポスター
Q6-24,時事情報に関する日本語QAベンチマーク『ニュースQ』,植木快|川畑輝|田口雄哉|新妻巧朗|浦川通|田森秀明|岡崎直観|乾健太郎,,Q6:ポスター
Q6-25,意思決定を指標とする生成テキスト評価：アマチュアと専門家への影響分析,高柳剛弘|高村大也|和泉潔|Chung-ChiChen,,Q6:ポスター
A7-1,What Language Do Japanese-specialized Large Language Models Think in?,鐘承志|程飛|劉倩瑩|江俊锋|万振|褚晨翚|村脇有吾|黒橋禎夫,,A7:NLPモデルの解釈可能性・分析(3)
A7-2,埋め込み表現の独立成分の言語内・言語間一貫性の分析,飯森栄治|松田孟留|谷中瞳,,A7:NLPモデルの解釈可能性・分析(3)
A7-3,構成的汎化におけるTransformerの内部機序の分析,九門涼真|谷中瞳,,A7:NLPモデルの解釈可能性・分析(3)
A7-4,大規模言語モデルにおけるIn-context Learningの推論回路,趙羽風|加藤万理子|坂井吉弘|井之上直也,,A7:NLPモデルの解釈可能性・分析(3)
A7-5,LM は日本の時系列構造をどうエンコードするか,佐々木睦史|鴨田豪|高橋良允|BenjaminHeinzerling|坂口慶祐,,A7:NLPモデルの解釈可能性・分析(3)
A7-6,大規模言語モデルにおけるペルソナの役割と内部動作の理解,尾崎慎太郎|平岡達也|大竹啓永|大内啓樹|渡辺太郎|宮尾祐介|大関洋平|高木優,,A7:NLPモデルの解釈可能性・分析(3)
B7-1,大規模言語モデルベースの日本語固有表現抽出におけるSelf-ReflectionとFew-Shot学習による精度改善,久保田崇文,,B7:知識獲得・情報抽出(2)
B7-2,階層的ナレッジグラフを用いた事故事例文書の述語中心の構造化手法,林瑛勲|森辰則,,B7:知識獲得・情報抽出(2)
B7-3,国会が告示する改正民法における新旧対応の整合性の検証,前原太陽|竹中要一|佐野智也,,B7:知識獲得・情報抽出(2)
B7-4,多言語での判例事実概要からの法的関係性のグラフ可視化,大南英理|宮西大樹|前田航希|栗田修平,,B7:知識獲得・情報抽出(2)
B7-5,技術観点の自動検出による技術動向マップ自動生成,蜂須賀笙太|任晶|福田悟志|難波英嗣|庄司裕子,,B7:知識獲得・情報抽出(2)
B7-6,大規模言語モデルを用いた専門用語間の関係性解析,岩熊耕平|難波英嗣|福田悟志,,B7:知識獲得・情報抽出(2)
C7-1,SOMO: 音声認識出力の可読性向上を目的とした整文手法の提案,杉野かおり|山野陽祐|河崎真琴|田森秀明|岡崎直観|乾健太郎,,C7:音声言語処理
C7-2,音声・音響・音楽を扱うオープン基盤モデルの構築に向けたデータセット策定,高道慎之介|和田仰|小川諒|山岡洸瑛|中田亘|淺井航平|関健太郎|岡本悠希|齋藤佑樹|小川哲司|猿渡洋|中村友彦|深山覚,,C7:音声言語処理
C7-3,傾聴態度を示す応答の生成における表出可能な応答種類の推定とその利用,田中涼雅|村田匡輝,,C7:音声言語処理
C7-4,音声モデルにおけるCritical Period仮説の検証,古賀友里愛|神藤駿介|宮尾祐介,,C7:音声言語処理
C7-5,日本民謡における旋律と方言アクセントの一致関係の比較分析,青山拓生|河瀬彰宏|沈力,,C7:音声言語処理
C7-6,量子計算を用いたダイレクトモデル,三輪拓真|小田悠介|河野誠也|吉野幸一郎,,C7:音声言語処理
D7-1,人狼知能コンテスト2024冬季国内大会自然言語部門の概要,狩野芳伸|渡邉嶺王|佐橋優人|坂根亜美|鳥海不二夫|稲葉通将|大澤博隆|片上大輔|大槻恭士|アランニャクラウス|原田慧|伊藤毅志,,D7:テーマセッション4: 人狼知能：噓を見破り説得する会話ゲームとLLM
D7-2,プレイヤー間の論理的情報を与えたLLMによる人狼ゲーム対話エージェントの構築,渡邉嶺王|狩野芳伸,,D7:テーマセッション4: 人狼知能：噓を見破り説得する会話ゲームとLLM
D7-3,大規模言語モデルに基づく人狼ゲームエージェントにおける戦略の自動適応,中盛楓也|YinJouHuang|FeiCheng,,D7:テーマセッション4: 人狼知能：噓を見破り説得する会話ゲームとLLM
D7-4,戦略的発話の多様な生成を目指した人狼エージェントの構築,佐藤岳大|尾崎慎太郎|横山大作,,D7:テーマセッション4: 人狼知能：噓を見破り説得する会話ゲームとLLM
E7-1,表現の置換による業績要因文の同義文・対義文生成,小川紀寧|酒井浩之,,E7:テーマセッション1: 金融・経済ドメインのための言語処理(3)
E7-2,大規模言語モデルを用いたFew-ShotプロンプティングによるJ-REITの投資物件に関する表構造認識,土井惟成|田中麻由梨,,E7:テーマセッション1: 金融・経済ドメインのための言語処理(3)
E7-3,取締役推薦理由文を用いた取締役のスキル・マトリックス分類モデルの開発,山脇大|野中賢也|田村光太郎|高野海斗|中川慧,,E7:テーマセッション1: 金融・経済ドメインのための言語処理(3)
E7-4,会計ドメインにおける質問応答のためのLLM を用いた解説ページ順位付け,飯田頌平|古俣槙山|三田寺聖|長谷川遼|宇津呂武仁|林友超|宍戸里絵,,E7:テーマセッション1: 金融・経済ドメインのための言語処理(3)
E7-5,金融テキストにおけるセンチメント分析の課題整理,高野海斗,,E7:テーマセッション1: 金融・経済ドメインのための言語処理(3)
P7-1,対照学習を用いたhallucination検出手法,山田美優|荒瀬由紀,,P7:ポスター
P7-2,科学文書における「間接的」引用についてのハルシネーション検出の評価,桒原龍生|杉山弘晃|堂坂浩二|平博順,,P7:ポスター
P7-3,大規模言語モデルにおけるICL バイアスの選択的補正,酒井祐介|NatthawutKertkeidkachorn|白井清昭,,P7:ポスター
P7-4,SocialStigmaQA-JA: 社会的バイアス評価用日本語データセット,岩城諒|金山博|竹内幹雄|村岡雅康|倉田岳人,,P7:ポスター
P7-5,PUPPET：タスク性能を維持しながらLLMとして検出されやすくする学習フレームワーク,齋藤幸史郎|小池隆斗|金子正弘|岡崎直観,,P7:ポスター
P7-6,日本語を対象としたLLMの大規模人手評価,井之上直也|安藤まや|後藤美知子|関根聡|中山功太|宮尾祐介,,P7:ポスター
P7-7,chakoshi: カテゴリのカスタマイズが可能な日本語に強いLLM向けガードレール,新井一博|松井遼太|深山健司|山本雄大|杉本海人|岩瀬義昌,,P7:ポスター
P7-8,アライメントが大規模言語モデルの数値バイアスに与える影響,佐藤郁子|金輝燦|陳宙斯|三田雅人|小町守,,P7:ポスター
P7-9,"人間と LLM の ""面白さ"" の感性は一致するのか？",坂部立|金輝燦|小町守,,P7:ポスター
P7-10,大規模言語モデルの文生成確率を用いた教師なし品質推定,樽本空宙|梶原智之|二宮崇,,P7:ポスター
P7-11,大規模言語モデルの多言語社会的バイアス抑制における単言語ラベル付きデータの役割,大葉大輔|金子正弘|DanushkaBollegala|岡崎直観,,P7:ポスター
P7-12,多言語大規模言語モデルにおける英語指示文と対象言語指示文の公平な比較,榎本大晟|金輝燦|陳宙斯|小町守,,P7:ポスター
P7-13,日本語大規模言語モデルの事前訓練過程における下流タスク性能の網羅的な分析,西田悠人|小田悠介|NamgiHan|高木優|宮尾祐介,,P7:ポスター
P7-14,SelfCheckGPTはコード生成におけるハルシネーションを検知できるか,伊東和香|小原有以|佐藤美唯|秋信有花|倉林利行|倉光君郎,,P7:ポスター
P7-15,日本語LLMに含まれる交差バイアスと有害性の評価に向けて,谷中瞳|SunjinOh|XinqiHe|NamgiHan|JieLu|九門涼真|松岡佑磨|渡部和彦|板津木綿子,,P7:ポスター
P7-16,日付入りLLM文書翻訳評価用データセット,岩月憲一|根石将人,,P7:ポスター
P7-17,Constructing Open-source Large Language Model Evaluator for Japanese,孫一坤|八幡早紀子|程飛|村脇有吾|褚晨翚|黒橋禎夫,,P7:ポスター
P7-18,Jailbreakにより生成したフェイクニュースの危険度評価,島田比奈理|金子正弘|岡崎直観,,P7:ポスター
P7-19,大規模言語モデルの事前学習用コーパスにおける要配慮個人情報の検出,源怜維|小田悠介|河原大輔,,P7:ポスター
P7-20,大規模言語モデルが持つ抽象推論能力の分析,清野輝風|青木洋一|斉藤いつみ|坂口慶祐,,P7:ポスター
P7-21,生成AIのための農業データセット構築とモデル評価,板倉亮真|坂地泰紀|野田五十樹|小林暁雄|大友将宏|石原潤一|桂樹哲雄,,P7:ポスター
P7-22,組織を超えたLLM学習データの目的外利用を防げるか？,相馬菜生|小林美結|宮田侑佳|倉光君郎,,P7:ポスター
P7-23,人間が書いた文章を対象としたHallucination検出ベンチマークの構築と評価,岩本和真|大村和正|石原祥太郎,,P7:ポスター
P7-24,大規模言語モデルの利用におけるプライバシー保護の新たな視点,髙田雅之|玉井睦,,P7:ポスター
P7-25,ダイアグラム理解に向けた大規模視覚言語モデルの内部表現の分析,吉田遥音|工藤慧音|青木洋一|田中涼太|斉藤いつみ|坂口慶祐|乾健太郎,,P7:ポスター
Q7-1,構造化知識 RAG・文書ベース RAG を段階的に利用したマルチホップ QA に対する LLM の精度向上,石井愛|井之上直也|鈴木久美|関根聡,,Q7:ポスター
Q7-2,法律分野の統合引用グラフを活用した質問応答の実現,丸山拓海|稲垣有二,,Q7:ポスター
Q7-3,軽量LLMを用いた規則適合判定,矢野大地|小林一郎|平博順,,Q7:ポスター
Q7-4,ハンセン病回復者の語り部の証言記録に対する質問応答システム構築に向けたベクトル検索精度の検証,孝壽真治|竹内孔一,,Q7:ポスター
Q7-5,RAGの生成器におけるSLMの利用,阿部晃弥|新納浩幸,,Q7:ポスター
Q7-6,Sentence-BERTによる分散表現を用いたベストアンサーの推定,間宮壮太|市川治,,Q7:ポスター
Q7-7,OCRを利用したRAGにおけるPDF文書内のタイトルや表の利用,蒲原悠登|竹内孔一,,Q7:ポスター
Q7-8,SQL AgentとマルチモーダルLLMを用いた文書内の表に対する質問応答システム,青栁直人|森田祐介,,Q7:ポスター
Q7-9,適応型負例選択を用いた対照学習による回答検索,伊東秀夫,,Q7:ポスター
Q7-10,Extraction and Generation Tasks with Knowledge-aware Text-to-Text Transfer Transformer,MohammadGolamSohrab|MakotoMiwa,,Q7:ポスター
Q7-11,トップダウン手続きを応用したLLM Agentのプランニングの試み,村上夏輝|加賀屋智之|黄瀬輝,,Q7:ポスター
Q7-12,介護支援システム:CPRASの開発,阿部貴駿|中島陽子|本間宏利|MichalPtaszynski|桝井文人|秋葉友良,,Q7:ポスター
Q7-13,実世界対話における参照関係の統合的解析,稲積駿|植田暢大|吉野幸一郎,,Q7:ポスター
Q7-14,PDF 形式の農業技術文書を用いた表構造認識ベンチマーク TOITA,阿部瑞稀|杉山陽菜乃|中村彩乃|前多陸玖|坂口遥哉|佐藤栄作|木村泰知,,Q7:ポスター
Q7-15,ユーザ属性を考慮した検索拡張生成による学部教育課程相談チャットボット,竹内新|目良和也|梶山朋子,,Q7:ポスター
Q7-16,LLM埋め込みと遷移確率予測を利用した実店舗内顧客行動シミュレーション,宮本遼人|春日瑛,,Q7:ポスター
Q7-17,広告画像ランキングによる視覚言語モデルの評価,大竹啓永|張培楠|坂井優介|三田雅人|大内啓樹|渡辺太郎,,Q7:ポスター
Q7-18,北海道十勝地域における農業政策と営農活動の課題分析の試み,坂口遥哉|木村泰知|河野洋一|東陽介,,Q7:ポスター
Q7-19,拡張現実を用いた歩行型音声対話エージェント,前土佐勇仁|南泰浩,,Q7:ポスター
Q7-20,農林業基準技術に含まれる表を対象としたPDF から CSV へ変換する際の課題分析,杉山陽菜乃|阿部瑞稀|中村彩乃|前多陸玖|坂口遥哉|佐藤栄作|木村泰知|小林暁雄|大友将宏|石原潤一|桂樹哲雄|川村隆浩,,Q7:ポスター
Q7-21,新型コロナワクチンをめぐるTwitter上の話題変化：テキスト精読と頻出単語分析による仮説構築とその検証,武富有香|須田永遠|中山悠理|宇野毅明|橋本隆子|豊田正史|吉永直樹|喜連川優|小林亮太,,Q7:ポスター
Q7-22,農林業基準技術文書を対象としたPDF解析ツールの表構造認識の性能評価,中村彩乃|杉山陽菜乃|阿部瑞稀|前多陸玖|坂口遥哉|佐藤栄作|木村泰知,,Q7:ポスター
Q7-23,クイズコンペティションの結果分析から見た日本語質問応答の到達点と課題,有山知希|鈴木潤|鈴木正敏|田中涼太|赤間怜奈|西田京介,,Q7:ポスター
Q7-24,NAIST Simultaneous Interpretation Corpus: Development and Analyses of Data from Interpreters of Different Levels,KosukeDoi|KatsuhitoSudoh|SatoshiNakamura,,Q7:ポスター
A8-1,似た単語の知識ニューロンは似た形成過程を経る,有山知希|BenjaminHeinzerling|穀田一真|乾健太郎,,A8:NLPモデルの解釈可能性・分析(4)
A8-2,多角的な評価から大規模言語モデルにおける事実知識の想起の要因分析,趙信|吉永直樹|大葉大輔,,A8:NLPモデルの解釈可能性・分析(4)
A8-3,心理測定テストに関するLLMのメタ知識の検証,山本有起|ArjavSingh|YinJouHuang|ChenhuiChu|村脇有吾,,A8:NLPモデルの解釈可能性・分析(4)
A8-4,日本向けにファインチューニングされた中国系大規模言語モデルに北京の検閲は残るか？,伊藤亜聖|高口康太,,A8:NLPモデルの解釈可能性・分析(4)
A8-5,大規模言語モデルは日本語・中国語の状態パーフェクトを理解できるか?,盧捷|金杜|柴田行輝|土井智暉|染谷大河|谷中瞳,,A8:NLPモデルの解釈可能性・分析(4)
A8-6,従属節が分断された不可能言語を言語モデルは学習するのか,指田昌樹|鈴木彩音|安田卓矢|染谷大河|谷中瞳,,A8:NLPモデルの解釈可能性・分析(4)
B8-1,認知症高齢者の発話意図推定に基づく注意発話検出システムの開発 ―帰宅願望や不安などを特定するコーパス構築―,有國開成|神崎享子|井佐原均,,B8:言語資源構築
B8-2,多様な客観的解釈を反映した主体性コーパス構築と予備的分析,林純子|伊藤和浩|永井宥之|矢田竣太郎|若宮翔子|荒牧英治,,B8:言語資源構築
B8-3,日本語文平易化のための疑似パラレルコーパス構築,澤柳翔太|小川泰弘|外山勝彦,,B8:言語資源構築
B8-4,AdParaphrase: 魅力的な広告表現の分析を目的とした広告文言い換えデータセット,村上聡一朗|張培楠|上垣外英剛|高村大也|奥村学,,B8:言語資源構築
B8-5,プロンプトと複数の音声認識候補による青空文庫振り仮名注釈付き音声コーパスの再構築,佐藤文一|吉永直樹|豊田正史|喜連川優,,B8:言語資源構築
B8-6,Sketch2Diagram: 視覚的指示を入力とするダイアグラム生成,斉藤いつみ|吉田遥音|坂口慶祐,,B8:言語資源構築
C8-1,リザバー計算に触発された軽量型Transformer の提案：パラメタ共有を用いた計算の効率化と性能評価,中村仁|加藤万理子|黒岩蒼太郎|崎野也真人|田中剛平|山下洋史|鈴木秀幸|白坂将,,C8:NLPのための効率的/低リソース手法
C8-2,生成文の短縮による言語モデルの計算量削減,海野圭矢|内田真人,,C8:NLPのための効率的/低リソース手法
C8-3,合成データと能動学習を用いた大規模言語モデルへの効率的な知識定着,角谷あおい|河越淳,,C8:NLPのための効率的/低リソース手法
C8-4,モデル拡張を用いた段階的事前学習によるモデル系列の効率的な構築,矢野一樹|高瀬翔|小林颯介|清野舜|鈴木潤,,C8:NLPのための効率的/低リソース手法
C8-5,Gated Recurrent Unitの簡略化と学習型Bloom Filterへの影響,大西雄真|西田拳|林克彦|上垣外英剛,,C8:NLPのための効率的/低リソース手法
C8-6,MCMCを用いた前提検索によるLLMの仮説推論能力の強化,WangYuanyi|小林一郎,,C8:NLPのための効率的/低リソース手法
D8-1,話者特性に基づくターンテイキング速度の分析,大西一誉|大中緋慧|吉野幸一郎,,D8:対話(1)
D8-2,性格特性による感情誘導の効果検証,船迫龍之介|當間愛晃,,D8:対話(1)
D8-3,実インタラクション映像から構築したマルチモーダルモデルを用いた人とロボットのインタラクションにおける異常検出,望月翔太|山下紗苗|星牟禮健也|馬場惇|窪田智徳|小川浩平|東中竜一郎,,D8:対話(1)
D8-4,大規模言語モデルを用いた対話品質評価に関する調査,赤間怜奈|鈴木潤,,D8:対話(1)
D8-5,回答単位を小説登場人物とする大規模言語モデルベース発話者分類,古俣槙山|長谷川遼|銭本友樹|宇津呂武仁,,D8:対話(1)
D8-6,日本語Full-duplex音声対話システムの試作,大橋厚元|飯塚慎也|姜菁菁|東中竜一郎,,D8:対話(1)
E8-1,混合物の強さの度合,高橋速巳,,E8:テーマセッション3: 認知・脳と自然言語処理(1)
E8-2,大規模言語モデルは他者の心をシミュレートしているか,青木洸士郎|河原大輔,,E8:テーマセッション3: 認知・脳と自然言語処理(1)
E8-3,大規模視覚言語モデルは錯視を理解しているか,篠崎大河|土井智暉|綿引周|西田知史|谷中瞳,,E8:テーマセッション3: 認知・脳と自然言語処理(1)
E8-4,大規模言語モデルを用いた言語刺激下の脳内意味表象解読,佐藤杏奈|小林一郎,,E8:テーマセッション3: 認知・脳と自然言語処理(1)
E8-5,Improving Zero-Shot Machine Translation with Fixed Prefix Pair Bootstrapping,Van-HienTran|RajDabre|HourKaing|田中英輝|内山将夫,,E8:テーマセッション3: 認知・脳と自然言語処理(1)
E8-6,記述文選択タスクによる大規模視覚言語モデルのアモーダル補完能力の評価,綿引周|土井智暉|篠崎大河|西田知史|新川拓哉|宮原克典|谷中瞳,,E8:テーマセッション3: 認知・脳と自然言語処理(1)
P8-1,検索付き拡張生成におけるハイパーパラメータとプロンプトの同時最適化,鈴木海渡|水野尚人|柳瀬利彦|佐藤元紀,,P8:ポスター
P8-2,事業セグメントに着目した有価証券報告書からの文脈抽出とキーワード生成による類似企業検索,國吉房貴|井本稔也,,P8:ポスター
P8-3,事故事例文書絞り込み検索システムの構築,福岡康大|大八木悠聖|喜多俊介|深草理貴|森辰則|伊藤拓海|小野寺理恵,,P8:ポスター
P8-4,Wikipedia記事の内容と閲覧時間帯の関係の統計的分析,吉井健敏|持橋大地,,P8:ポスター
P8-5,表記ゆれが文埋め込みモデルに及ぼす影響についての考察,佐々木峻|山本大輝,,P8:ポスター
P8-6,IterKey: LLMを用いた反復的キーワード生成による検索拡張生成の最適化,林和樹|上垣外英剛|幸田慎也|渡辺太郎,,P8:ポスター
P8-7,文対モデリングのための言い換えに基づく対照学習,杉山誠治|近藤里咲|梶原智之|二宮崇,,P8:ポスター
P8-8,大規模言語モデルを用いた学術論文検索におけるブーリアン型検索クエリ作成の支援,福田悟志,,P8:ポスター
P8-9,特定ドメイン向けローカル検索用のサジェスト提示に向けた分析,鈴木琴音|岩本和真|安藤一秋,,P8:ポスター
P8-10,地方議会会議録検索システム「ぎ～みるv2」の概要,乙武北斗|高丸圭一|内田ゆず|木村泰知,,P8:ポスター
P8-11,クリックログと小規模高品質データを併用したEコマースクエリ意図分類モデルの精度向上,田爪聡|伊奈拓郎|馬緤美穂|石原敬大|鍜治伸裕,,P8:ポスター
P8-12,Sentence-BERT による，レコメンドへのユーザー意図の反映,青井孝史|久保田崇文,,P8:ポスター
P8-13,ベクトル検索におけるテキスト構造化の効果分析,梶川怜恩|神田峻介|赤部晃一|小田悠介,,P8:ポスター
P8-14,企業法務向け日本語文書検索評価データセットの構築と分析,菅原祐太|丸山拓海|西野裕貴|稲垣有二,,P8:ポスター
P8-15,逆プロンプトを用いたコールドスタート推薦,草野元紀,,P8:ポスター
P8-16,芸能人への感想を表すX上のポスト集約およびウェブ検索・RAGによるその理由の集約,横山響|土田陸斗|宇津呂武仁,,P8:ポスター
P8-17,ユーザ行動ログに基づくクエリ理解のための検索クエリ埋め込み,西川荘介|平子潤|鍜治伸裕|渡邉幸暉|浅野広樹|山城颯太|佐野峻平,,P8:ポスター
P8-18,論文を対象とした RAG システムにおける質問分類に基づく動的検索,大平颯人|佐藤郁子|真鍋章|谷本恒野|原慎大|小町守,,P8:ポスター
P8-19,文書埋め込みとクラスタリングを組み合わせたトピック分析手法の提案,藤田葵|中山悠理|山本泰智|小林亮太,,P8:ポスター
P8-20,SoftMatcha: 大規模コーパス検索のための柔らかくも高速なパターンマッチャー,出口祥之|鴨田豪|松下祐介|田口智大|末永幸平|和賀正樹|横井祥,,P8:ポスター
P8-21,Bi-encoder と 𝑘NN の組み合わせによる職務記述書に書かれた文のスキルマッピング,牧野拓哉,,P8:ポスター
P8-22,学術情報推薦におけるグラフ構造の有効性検証,長尾浩良|桂井麻里衣,,P8:ポスター
P8-23,インストラクションと複数タスクを利用した日本語向け分散表現モデルの構築,勝又智|木村大翼|西鳥羽二郎,,P8:ポスター
Q8-1,言語モデルを用いたパラメータ異常検出： 複数パラメータの組み合わせに対する異常,内田博規|富永圭太郎|板井秀樹|李玉潔|中藤良久,,Q8:ポスター
Q8-2,マイクロドメインに向けたLLM における知識活用方法の検討,角掛正弥|是枝祐太|薛雅文|住吉貴志|永塚光一|友成光|山田喬|十河泰弘,,Q8:ポスター
Q8-3,継続事前学習によるLLMの知識獲得,高橋洸丞|近江崇宏|有馬幸介|BenjaminHeinzerling|QinDai|乾健太郎,,Q8:ポスター
Q8-4,利用手法の類似性に着目した学術論文推薦手法の提案,YANGQI|成松宏美|南泰浩,,Q8:ポスター
Q8-5,日本語バイト符号化マスク言語モデルの開発と分析,工藤慧音|鴨田豪|塩野大輝|鈴木潤,,Q8:ポスター
Q8-6,日独民法における自動対応付け手法の比較とfine-tuningの実装,髙橋寿記|中村誠,,Q8:ポスター
Q8-7,LLM の学術ドメイン適応のための合成データに基づく統合フレームワーク,小川隼斗|河原大輔|相澤彰子,,Q8:ポスター
Q8-8,法令文解析に適した事前学習モデルの構築,渋谷太朗|中村誠,,Q8:ポスター
Q8-9,モデルマージを用いたLLM翻訳における破滅的忘却の抑制,岩川光一|ZhuHaocheng|鈴木潤|永田昌明,,Q8:ポスター
Q8-10,LLM推定ラベルと弱教師あり学習による反復的アノテーション更新,浅野輝|小津野将|馬場雪乃,,Q8:ポスター
Q8-11,Flashback: 深層系列処理モデルのメモリ効率化・高速化のための記憶機構,関井大気,,Q8:ポスター
Q8-12,SvMoE: MoE ルータの教師あり学習,村田栄樹|河原大輔,,Q8:ポスター
Q8-13,日本語の包括的な指示追従性データセットの構築,堀尾海斗|福田創|小川隼斗|鈴江万碧|織田宥楽|河原大輔|関根聡|安藤まや,,Q8:ポスター
Q8-14,LLMを用いた日本語学習者支援,亀田隆雅|馬青,,Q8:ポスター
Q8-15,Sparse Autoencoders as a Tool for Steering the Output Language of Large Language Models,SebastianZwirner|WentaoHu|青木洸士郎|河原大輔,,Q8:ポスター
Q8-16,日本語 VLM 構築に向けた合成データのフィルタリングの検討,大島遼祐|小澤圭右|品川政太朗|鈴木哲平,,Q8:ポスター
Q8-17,文脈内学習におけるデモの親和性と多様性の提案,加藤万理子|趙羽風|坂井吉弘|井之上直也,,Q8:ポスター
Q8-18,新聞ドメインにおける大規模言語モデルの継続事前学習と下流タスクデータ量の関係,岸波洋介|藤井諒|森下睦,,Q8:ポスター
Q8-19,確率的丸めを用いた言語モデルの量子化を意識した学習,趙開顔|田原司睦|小林健一|本田巧|山崎雅文|鶴岡慶雅,,Q8:ポスター
Q8-20,大規模言語モデルによるテキスト平易化のための意味的類似性と表層的非類似性に基づくパラレルコーパスフィルタリング,前川大輔|梶原智之|二宮崇,,Q8:ポスター
Q8-21,模倣学習による大規模言語モデルの指示チューニング,YoumiMa|水木栄|藤井一喜|中村泰士|大井聖也|島田比奈理|塩谷泰平|齋藤幸史郎|前田航希|服部翔|岡本拓己|石田茂樹|横田理央|高村大也|岡崎直観,,Q8:ポスター
Q8-22,少量ショットに対する大規模言語モデル（LLM）を用いた人工データ生成による精度向上の試み,山本大輝|佐々木峻,,Q8:ポスター
Q8-23,量子化 bit 幅の異なる基盤モデルに対する Adapter の転移性を活用した Low-Rank Adaptation,神田悠斗|波多野賢治,,Q8:ポスター
Q8-24,連合学習におけるLoRAの統合数と精度の関係の検証,尹子旗|村田栄樹|河原大輔,,Q8:ポスター
Q8-25,Weighted Asymmetric Loss for Multi-Label Text Classification on Imbalanced Data,安田有希|宮﨑太郎|後藤淳,,Q8:ポスター
A9-1,段落単位の対訳データによる大規模言語モデルの翻訳精度向上,近藤海夏斗|宇津呂武仁|永田昌明,,A9:機械翻訳(1)
A9-2,対訳単語の対偶を考慮した文パターンの選択とNMTの効果,村上仁一,,A9:機械翻訳(1)
A9-3,特許請求項翻訳における単語対応に基づく節分割モデルの有効性,西村柾人|宇津呂武仁|永田昌明,,A9:機械翻訳(1)
A9-4,ニューラル機械翻訳のモデルレベル双方向学習における単言語データの活用,加藤龍兵|秋葉友良|塚田元,,A9:機械翻訳(1)
A9-5,対訳文のみを用いた翻訳と言い換えのマルチタスク学習における翻訳精度,名村太一|村上仁一,,A9:機械翻訳(1)
A9-6,事例ベース意思決定理論に基づく復号,出口祥之,,A9:機械翻訳(1)
B9-1,ダイエット口コミデータセットにおけるダイエット食品およびダイエット飲料に関する語彙解析,大塚敬義,,B9:語彙資源・辞書
B9-2,JMED-DICT: 大規模医療用語辞書の構築,永井宥之|西山智弘|大槻優佳|藤牧貴子|川端京子|工藤紀子|山崎由佳|白石暖哉|梶原智之|進藤裕之|河添悦昌|今井健|矢田竣太郎|若宮翔子|荒牧英治,,B9:語彙資源・辞書
B9-3,大規模言語モデルを活用した大規模医療用語辞書メンテナンスの効率化,大槻優佳|矢田竣太郎|西山智弘|工藤紀子|川端京子|藤牧貴子|永井宥之|若宮翔子|荒牧英治,,B9:語彙資源・辞書
B9-4,関西方言を対象とした形態素解析用辞書の拡張,小木曽智信|尹熙洙|王竣磊|岡田純子,,B9:語彙資源・辞書
B9-5,『子ども版日本語日常会話コーパス』モニター版の構築,小磯花絵|石本祐一|居關友里子|江口典子|柏野和佳子|川端良子|田中真理子|田中弥生|西川賢哉,,B9:語彙資源・辞書
B9-6,留学生向け看護語彙リスト作成のためのコーパス構築における課題 -『系統看護学講座』シリーズ３巻のパイロットスタディから-,山元一晃|浅川翔子|稲田朋晃|岩間裕司|土屋ともえ,,B9:語彙資源・辞書
C9-1,RAGによる芸能人の話題集約及びその経歴の良否判定,土田陸斗|横山響|宇津呂武仁,,C9:情報検索・テキストマイニング
C9-2,抽象度が高いクエリによるアンケートデータの設問検索,田中稔也|熊谷雄介|藤井遼,,C9:情報検索・テキストマイニング
C9-3,k近傍事例に基づく埋め込み表現のドメイン適応と検索への応用,五藤巧|堤田恭太|村瀬文彦|三谷陽|渡辺太郎,,C9:情報検索・テキストマイニング
C9-4,VDocRAG: 視覚的文書に対する検索拡張生成,田中涼太|壹岐太一|長谷川拓|西田京介|齋藤邦子|鈴木潤,,C9:情報検索・テキストマイニング
C9-5,検索エンジンを指向したLLMのアラインメント,益子怜|木村賢|越仲孝文,,C9:情報検索・テキストマイニング
C9-6,RAGの応答正確性と連続応答性能の自動評価,岩間太|竹内幹雄,,C9:情報検索・テキストマイニング
D9-1,Japanese MT-bench++: より自然なマルチターン対話設定の日本語大規模ベンチマーク,植松拓也|福田創|河原大輔|柴田知秀,,D9:対話(2)
D9-2,Exploring LLM-based Data Synthesis Strategies for Conversational Semantic Frame Analysis,松田思鵬|YinJouHuang|FeiCheng|清丸寛一|村脇有吾,,D9:対話(2)
D9-3,「松下幸之助」 再現AIシステムの開発,大西直|高岸智|鎌田理久|山西宏平|神崎雄介|小林拓|徐暁琳|菅原陸|杉浦いぶき|篠崎友悠|河村岳,,D9:対話(2)
D9-4,MQM-Chat: 対話翻訳のための多次元品質指標,YunmengLi|鈴木潤|森下睦|阿部香央莉|乾健太郎,,D9:対話(2)
D9-5,対話データにおける個人の評価傾向の違いの分析 - 個人の評価傾向を反映した対話システム自動評価に向けて -,亀山京右|駒谷和範,,D9:対話(2)
D9-6,人はなぜ笑うのか？対話における笑いの根拠ラベルの半自動構築,井上昂治|MikeyElmers|DiveshLala|河原達也,,D9:対話(2)
E9-1,統語情報は脳情報デコーディングに寄与するのか？,赤間美香|梶川康平|大関洋平,,E9:テーマセッション3: 認知・脳と自然言語処理(2)
E9-2,Cognitive Preference Optimization: 脳情報による言語モデルの選好最適化,原田宥都|大関洋平,,E9:テーマセッション3: 認知・脳と自然言語処理(2)
E9-3,二重課題は言語モデルの合理的な言語理解ストラテジーを促進する,江村玲|菅原朔,,E9:テーマセッション3: 認知・脳と自然言語処理(2)
E9-4,しりとり単語系列の特徴を制御する認知的要因に関する認知モデルを利用した調査,西川純平|佐々木康佑|森田純哉,,E9:テーマセッション3: 認知・脳と自然言語処理(2)
E9-5,母音想起時における脳信号の周波数特性に基づいた想起区間検出,栗栖駿|入部百合絵,,E9:テーマセッション3: 認知・脳と自然言語処理(2)
E9-6,調音運動前の言語中枢間の位相同期を用いた母音認識,長瀬南帆|入部百合絵,,E9:テーマセッション3: 認知・脳と自然言語処理(2)
P9-1,オンラインニュースコメントを対象としたアスペクトベースのコメントフィルタリングシステム,笠原璃音|大和淳司|菊井玄一郎,,P9:ポスター
P9-2,事前学習コーパス内の特定の属性への言及の急激な変化の調査,大萩雅也|綿岡晃輝|高山隼矢|吉川克正,,P9:ポスター
P9-3,Advancements in Sentiment Analysis: A Methodological Examination of News using multiple LLMs,MuhammadAliMahmood|IffatMaab|MuhammadSibtain|AsimaSarwar|MuhammadArsalan|MasroorHussain,,P9:ポスター
P9-4,Investigating Implicit Reasoning in Counter-Argument Logical Structure Analysis,WenzhiWang|PaulReisert|内藤昭一|井之上直也|震明万智|SurawatPothong|JungminChoi|乾健太郎,,P9:ポスター
P9-5,YouTube動画コメントを用いた視聴者感情の推定と感情処理能力の比較,菅野祐希|坂野遼平,,P9:ポスター
P9-6,LLM を利用した Zero Shot 評判分析の性能調査,佐藤匠真|新納浩幸,,P9:ポスター
P9-7,SNS投稿によるユーザの意見変化の予測と要因分析,増川哲太|狩野芳伸,,P9:ポスター
P9-8,テキスト平易化パラレルコーパスに基づく教師なし文難易度推定,宮田莉奈|浦川通|田森秀明|梶原智之,,P9:ポスター
P9-9,ソーシャルメディアにおける投稿およびユーザの政治的傾向予測と政治的投稿フィルタによる性能向上,佐橋優人|狩野芳伸,,P9:ポスター
P9-10,発話スタイルの類似とユーザ本人による対話の好ましさの相関,沼屋征海|守屋彰二|佐藤志貴|赤間怜奈|鈴木潤,,P9:ポスター
P9-11,Short and long-range comedy generation and understanding using Large Language Models,EdisonMarrese-Taylor|MachelReid|AlfredoSolano,,P9:ポスター
P9-12,係り受け木を考慮するグラフ畳み込みニューラルネットワークによる日本語アスペクトベース感情分析,山口真|狩野芳伸,,P9:ポスター
P9-13,Sentiment Analysis of YouTube Videos in the 2024 Indonesian Presidential Election,ZaidanYahya|秋葉友良|木村泰知|御器谷裕樹|森浩太|吉田光男|粕谷祐子,,P9:ポスター
P9-14,評価対象抽出における関連タスクを利用したfew-shot 選択手法,今里昂樹|嶋田和孝,,P9:ポスター
P9-15,絵文字のマッピングを用いた感情表現の分析手法の検討,津田恵佑|深草理貴|森辰則,,P9:ポスター
P9-16,大規模言語モデルによる日本語スタイル変換の性能評価,花房健太郎|柳本大輝|梶原智之|二宮崇,,P9:ポスター
P9-17,教師有り学習モデルと大規模言語モデルを組み合わせた低評価レビューを考慮したレビュー文書の評価値推定,竹尾匡貴|嶋田和孝,,P9:ポスター
P9-18,バックトラッキングを活用したマルチエージェントシステムによる複数制約充足プランニング,守屋彰二|大萩雅也,,P9:ポスター
P9-19,TEPPAY: ゲームのプレイ動画を入力とする実況AI Tuberシステムの提案,栗原健太郎|吉野哲平|高市暁広|岩田伸治|長澤春希|佐藤志貴|岩崎祐貴,,P9:ポスター
P9-20,行動認識の粒度アライメントに基づく予定の履行認識,藤田一天|河野誠也|吉野幸一郎,,P9:ポスター
P9-21,Psychological Investigation of Personality Knowledge in a Large Language Model,趙梓程|岩井律子|淺井二千夏|熊田孝恒,,P9:ポスター
P9-22,関連研究節自動生成に向けた引用論文の最適配置,大鹿雅史|笹野遼平,,P9:ポスター
P9-23,近傍事例を用いた対話における感情認識,石渡太智|後藤淳|山田寛章|徳永健伸,,P9:ポスター
Q9-1,生成型自動要約の信頼性向上を目的とした数値情報の誤り検出と修正手法,松井我颯|石川晴基|中島陽子|本間宏利|秋葉友良,,Q9:ポスター
Q9-2,言語のインクリメンタルな処理の仕組みは普遍的か？：投機性によるparsing strategy再考,石井太河|宮尾祐介,,Q9:ポスター
Q9-3,近現代の日本語文学作品における発表年次の予測,小川稜真|久野雅樹,,Q9:ポスター
Q9-4,Shift-Reduce 法に基づく漸進的係り受け解析と未入力文節主辞トークン予測の同時実行とその評価,橋本優希|大野誠寛|松原茂,,Q9:ポスター
Q9-5,大規模言語モデルによる要求仕様書の品質評価,鈴木淳|村瀬文彦|水野伸洋|髙木理恵子|不破慎之介|塚原裕史|中江俊博,,Q9:ポスター
Q9-6,大規模言語モデルを用いたシフト還元型句構造解析,中根稜介|前川在|上垣外英剛|平尾努|奥村学,,Q9:ポスター
Q9-7,End-to-Endモデルに基づく漸進的係り受け解析と未入力文節主辞予測の同時実行,海野博揮|大野誠寛|伊藤滉一朗|松原茂樹,,Q9:ポスター
Q9-8,大規模言語モデルを用いたカタカナ語の意味分類における出力傾向分析,小滝主紀|佐々木稔,,Q9:ポスター
Q9-9,Exploring Dynamic Few-Shot Prompting for Word Sense Disambiguation in Historical Chinese,MicahKitsunai|DeborahWatty|Shu-KaiHsieh,,Q9:ポスター
Q9-10,生成データに基づいた日本語の時間関係推定,小國怜美|持橋大地|小林一郎,,Q9:ポスター
Q9-11,複単語表現検出におけるLLMファインチューニングの有効性,井手佑翼|JoshuaTanner|AdamNohejl|JustinVasselli|上垣外英剛|渡辺太郎,,Q9:ポスター
Q9-12,CCGに基づく否定スコープ認識,小島健太郎|加藤芳秀|松原茂樹,,Q9:ポスター
Q9-13,視覚情報による曖昧性解消コーパスの検討,李相明|河野誠也|吉野幸一郎,,Q9:ポスター
Q9-14,和歌の埋め込みに基づく本歌取りの推定,小川隼斗|堀尾海斗|河原大輔,,Q9:ポスター
Q9-15,Towards a Comparison of Japanese and English Metaphor,RowanHallMaudslay|古宮嘉那子|浅原正幸|SimoneTeufel,,Q9:ポスター
Q9-16,比喩検出における大規模言語モデルを用いた前後補助文脈の活用,林拓哉|佐々木稔,,Q9:ポスター
Q9-17,ルールベースの深層格定義および自動付与とそのLLM統合による含意関係認識における効果検証,荒沢康平|狩野芳伸,,Q9:ポスター
Q9-18,ツリーバンクの言語学的妥当性の自動評価,富田朝|谷中瞳|戸次大介,,Q9:ポスター
Q9-19,自動ファクトチェックのための事実の分解による含意関係認識,雨宮正弥|狩野芳伸,,Q9:ポスター
Q9-20,大規模言語モデルを用いたStory Intention Graph の自動生成の精度改善,吉川祐輔|井上壮志|銭本友樹|東中竜一郎,,Q9:ポスター
Q9-21,文の埋め込みに効果的な静的単語ベクトルの獲得,和田崇史|平川優伎|清水良太郎|川島貴大|斎藤侑輝,,Q9:ポスター
Q9-22,訓練不要な条件付きテキスト埋め込み,山田康輔|張培楠,,Q9:ポスター
Q9-23,How Domain Adaptation of BERT Improves Syntactic Parsing of Math Text,吉田琉夏|松崎拓也,,Q9:ポスター
Q9-24,Semantic Shift Stability: 学習コーパス内の単語の意味変化を用いた事前学習済みモデルの時系列性能劣化の監査,石原祥太郎|高橋寛武|白井穂乃,,Q9:ポスター
A10-1,Data Augmentation for Manipuri-English Neural Machine Translation,申小靖|YvesLepage,,A10:機械翻訳(2)
A10-2,llmMT+1: 非英語言語対 LLM 翻訳の実現法の検討,傅星儿|永田昌明|ChenhuiChu,,A10:機械翻訳(2)
A10-3,Towards Equitable Translation: Gender Bias in Large Language Models,HongHaiNgo|YunmengLi|坂口慶祐,,A10:機械翻訳(2)
A10-4,BiMax: Bidirectional MaxSim Score for Bilingual Document Alignment,XiaotianWang|TakehitoUtsuro|MasaakiNagata,,A10:機械翻訳(2)
A10-5,小説会話文の翻訳へ向けた逆翻訳を用いた話者埋め込みの作成,長門亜優奈|松崎拓也,,A10:機械翻訳(2)
A10-6,逆翻訳を用いたアイヌ語・日本語機械翻訳の改善における研究,菅原葵|KarolNowakowski|MichalPtaszynski|NickOveracker,,A10:機械翻訳(2)
B10-1,不均衡最適輸送を用いた意味変化検出,岸野稜|山際宏明|永田亮|横井祥|下平英寿,,B10:形態素・構文・意味解析
B10-2,ドメインモデルに基づいて技術文書中の矛盾を検出する方法,山田隆弘,,B10:形態素・構文・意味解析
B10-3,反語文の情報格納―英語、中国語、日本語の比較から,伊藤さとみ,,B10:形態素・構文・意味解析
B10-4,JDD-PAS:規範的な日本語日常対話コーパスへの意味役割ラベル・述語項構造付与,吉野幸一郎|李相明|波部英子|大村舞|浅原正幸|若狭絢|赤間怜奈|鈴木潤,,B10:形態素・構文・意味解析
B10-5,読み推定のための教師なし単語分割,内海慶|森信介,,B10:形態素・構文・意味解析
B10-6,言語モデルを用いた定量的推論機能の実現に向けて,伊東恵美|小林一郎,,B10:形態素・構文・意味解析
C10-1,新聞記事からつくる 時事と社会に強い日本語LLM,服部翔|水木栄|藤井一喜|中村泰士|塩谷泰平|植木快|新妻巧朗|川畑輝|田森秀明|YoumiMa|前田航希|大井聖也|齋藤幸史郎|岡本拓己|石田茂樹|横田理央|高村大也|岡崎直観,,C10:LLM構築
C10-2,国産農業用LLMのためのインストラクションデータ構築と構築されたLLMシステムの評価,石原潤一|小林暁雄|桂樹哲雄|大友将宏|橋本祥|阪本浩太郎|杉村安都武|米丸淳一|安藤まや|後藤美智子|関根聡|川村隆浩,,C10:LLM構築
C10-3,日本語を主とした日・英・中トリリンガル700億パラメータモデルの構築,中島大|野崎雄太|佐藤諒|池田純一|阿部宏幸|伊藤真也|長谷川慶|中村聡史|麻場直喜,,C10:LLM構築
C10-4,ELAINE-medLLM: 英語、日本語、中国語に対応したバイオ医療ドメイン大規模言語モデル,矢野憲|浅田真生|三輪誠|SophiaAnaniadou|辻井潤一,,C10:LLM構築
C10-5,大規模言語モデルの再パラメタ化に基づく初期化による損失スパイクの抑制,西田光甫|西田京介|齋藤邦子,,C10:LLM構築
C10-6,大規模言語モデルにおけるSupervised Fine-tuningの包括的検証,原田宥都|山内悠輔|小田悠介|大関洋平|宮尾祐介|高木優,,C10:LLM構築
D10-1,LLMによるクイズの自動生成と質問応答への応用,小林俊介|河原大輔,,D10:質問応答，対話(3)
D10-2,RAGに基づく韓国語法令・判例に対する質問応答,徐基皓|宇津呂武仁,,D10:質問応答，対話(3)
D10-3,Fusion-in-LLM: 質問応答タスクにおけるRAG,太刀岡勇気,,D10:質問応答，対話(3)
D10-4,対話要約の種別が対話の引継ぎに及ぼす影響の調査,山下紗苗|東中竜一郎,,D10:質問応答，対話(3)
D10-5,質問誘導に基づくアンケート対話システムの開発,銭本友樹|吉田麻里子|堀涼|浦田真由|井上愛子|林尊弘|東中竜一郎,,D10:質問応答，対話(3)
D10-6,Multi-Relational Multi-Party Chat Corpus: 話者間の関係性に着目したマルチパーティ雑談対話コーパス,津田太郎|山下紗苗|井上昂治|河原達也|東中竜一郎,,D10:質問応答，対話(3)
E10-1,BrainLMを用いた多言語学習での転移学習性能の検証,羅桜|小林一郎,,E10:テーマセッション3: 認知・脳と自然言語処理(3)
E10-2,CCGによる日本語脳波データのモデリング,磯野真之介|梶川康平|杉本侑嗣|浅原正幸|大関洋平,,E10:テーマセッション3: 認知・脳と自然言語処理(3)
E10-3,大規模言語モデルの浅い層が人間の速い言語処理を再現する,栗林樹生|大関洋平|SouhaibBenTaieb|乾健太郎|TimothyBaldwin,,E10:テーマセッション3: 認知・脳と自然言語処理(3)
E10-4,Skip-bigrams reconstruct trigrams in 2-word languages,日髙昇平,,E10:テーマセッション3: 認知・脳と自然言語処理(3)
E10-5,Triple-Phase Transition: 脳との関係から捉える大規模言語モデルの学習ダイナミクス,中木裕子|多田圭吾|吉野草太|西本伸志|高木優,,E10:テーマセッション3: 認知・脳と自然言語処理(3)
P10-1,法的三段論法に基づく段階的プロンプトによる司法試験自動解答,翁長駿光|狩野芳伸,,P10:ポスター
P10-2,Detecting Individual Decision-Making Dialogues in Conversation,苏为文|吉永直樹|豊田正史|王子晗|周宇涵,,P10:ポスター
P10-3,LLM を用いた対話印象評価による対話システム学習とその分析,吉田快|水上雅博|河野誠也|クルンカライカナサイ|杉山弘晃|吉野幸一郎,,P10:ポスター
P10-4,リアルタイム音声対話システムのための応答タイミングと短文応答の同時予測,大中緋慧|河野誠也|大西一誉|吉野幸一郎,,P10:ポスター
P10-5,キャラクターの2面性を表出する発話の生成に関する検討,岩田伸治|伊原滉也|佐藤志貴|馬場惇|邊土名朝飛|山崎眞洋|塩塚勇気|吉本暁文,,P10:ポスター
P10-6,擬似選好チューニングによる対話応答のペルソナ一貫性向上,高山隼矢|大萩雅也|水本智也|吉川克正,,P10:ポスター
P10-7,メモと圧縮を用いた効率的なメモリモジュールを持つ対話システムの構築,谷口伊織|南泰浩,,P10:ポスター
P10-8,ユーザに適応する対話システムのためのLLMを用いた自我状態推定,掛川脩人|山田剛一|増田英孝,,P10:ポスター
P10-9,なりきり雑談システムを評価するためのキャライメージの評価者間一致に関する検証-４択クイズを用いた原作者とファンの比較-,連慎治|伊藤敏彦,,P10:ポスター
P10-10,語り手の発話の言い換えにより語りに傾聴を示す応答の生成,茂木光志|伊藤滉一朗|村田匡輝|松原茂樹,,P10:ポスター
P10-11,対話評価における参照応答集合の妥当性と言語モデルが出力する応答の多様性の関係,佐藤魁|吉野幸一郎|赤間怜奈|鈴木潤,,P10:ポスター
P10-12,状態遷移モデルおよび大規模言語モデルを用いた半構造化インタビューのモデル化,長谷川遼|花一傑|宇津呂武仁|橋本慧海|中野幹生|白松俊,,P10:ポスター
P10-13,AdPsyche: 広告心理学に基づく選好データセット,三田雅人|村上聡一朗|本多右京|岡達志,,P10:ポスター
P10-14,大規模言語モデルを用いたソフトウェア仕様書の用語チェック,金井健一郎|安部夏樹|加羽澤優|内出隼人|斉藤辰彦,,P10:ポスター
P10-15,誤りを経験して修正する：誤りデータの正例扱いによる対照学習,薛強|滝口哲也|有木康雄,,P10:ポスター
P10-16,対話に対する共感のアノテーションと共感制御可能な対話モデルの構築,鈴江万碧|堀尾海斗|折田奈甫|河原大輔,,P10:ポスター
P10-17,LLM ベースのマルチエージェントによる TRPG ゲームマスターシステムの実現,箕成侑音|上乃聖|李晃伸,,P10:ポスター
P10-18,適応的対話システムのための終盤の会話を予測する埋め込みモデルの構築,飯塚慎也|東中竜一郎,,P10:ポスター
P10-19,疑似対話データとPreferenceデータを用いたドメイン特化対話への日本語LLMチューニングの検証,山崎天|高山隼矢|佐藤京也|大萩雅也|吉川克正|水本智也,,P10:ポスター
P10-20,思考発話を利用した個人の発話及び性格特性再現,石倉誠也|山田寛章|平岡達也|山田広明|徳永健伸,,P10:ポスター
P10-21,対話システムにおける個人特性を考慮した破綻度合い推定,山田竜彰|坪倉和哉|入部百合絵|北岡教英,,P10:ポスター
P10-22,小説における台詞と口調，地の文を活用した台詞の発話者特定手法,岩本和真|安藤一秋,,P10:ポスター
P10-23,RAG を利用した傾聴応答生成の検証,松本奈々|安藤一秋,,P10:ポスター
P10-24,カウンセリングドメインに特化してfine-tuning を行ったLLMに対するActive Listening Skillの評価,三浦拓人|NatthawutKertkeidkachorn|小島治幸|白井清昭,,P10:ポスター
Q10-1,技能者インタビュー対話におけるコツ発話の表出に至った発話列の特徴の分析,樽谷洋希|YinJouHuang|松田思鵬|村脇有吾|黒橋禎夫|近大志|岡久太郎,,Q10:ポスター
Q10-2,異種属性の内容的特徴をハイパーグラフにより統合するエンティティ表現学習,西出隆盛|三輪誠,,Q10:ポスター
Q10-3,Hybrid-SET: 意味的類似性とセットカバレッジを考慮したfew-shot例選出手法,朱晨成|谷口友紀|大熊智子|嶋田和孝,,Q10:ポスター
Q10-4,固有表現候補の用語情報を取得するLLMを用いた固有表現抽出,与那覇竜馬|三輪誠,,Q10:ポスター
Q10-5,偏向LLMエージェントの協調による知識階層の誤り訂正,三島輝瑠|佐々木裕,,Q10:ポスター
Q10-6,日本の刑事事件を対象とした法律相談システム,中下咲帆|菊池英明|藤倉将平|則竹理宇,,Q10:ポスター
Q10-7,データセット間の関連性推定におけるメタデータの利用,伊藤滉一朗|松原茂樹,,Q10:ポスター
Q10-8,不動産情報抽出業務の効率化に向けた大規模言語モデルを用いたアンサンブル手法,齊藤佑太郎|叶内晨|松本健太郎|岩成達哉,,Q10:ポスター
Q10-9,視覚的質問応答による文書情報抽出における同時多項目推論,MengsayLoem|保坂大樹,,Q10:ポスター
Q10-10,半教師あり学習を用いた単語アライメントの改善,苗中濤|永田昌明|鶴岡慶雅,,Q10:ポスター
Q10-11,Cosine Similarity as Logits?: Few-shot Knowledge Graph Completion with Embedding Vectors of a Generative PLM and its Application in Knowledge Probing,TomoykiJinno|KazukiHayashi|YusukeSakai|HidetakaKamigaito|TaroWatanabe,,Q10:ポスター
Q10-12,地方議会の予算表を対象としたLLMによる表形式変換を用いたRAGの提案,前多陸玖|木村泰知,,Q10:ポスター
Q10-13,製造業ドメインにおける日本語LLMの性能調査,上原大暉|田中宏治|金井健一郎|内出隼人|伍井啓恭|斉藤辰彦,,Q10:ポスター
Q10-14,健康経営度調査テキストに対する定量評価およびレコメンドアルゴリズムの提案,林和希|參木裕之,,Q10:ポスター
Q10-15,LLM を用いた関係抽出のデータ拡張におけるデータ選定と利用方法の検討,小島大世|三輪誠,,Q10:ポスター
Q10-16,複数文章からの表生成における生成AIの利用と評価手法の比較,野田直哉|村田真樹,,Q10:ポスター
Q10-17,LLMを用いた交通分野固有表現抽出データセットの自動構築,井田龍希|西出隆盛|三輪誠,,Q10:ポスター
Q10-18,Sentence BERTを用いた源氏物語内の古今和歌集引用の検出,叶内琉聖|古宮嘉那子,,Q10:ポスター
Q10-19,デコーダモデルを用いた生物医学イベント抽出,金児一矢|三輪誠,,Q10:ポスター
Q10-20,小説のセリフを利用した登場人物に紐づく人間関係語の抽出,安田大朗|安藤一秋,,Q10:ポスター
Q10-21,固有表現抽出タスクの形式の学習と様々なドメインへの適用,石井奏人|新妻巧朗|田森秀明,,Q10:ポスター
Q10-22,診断のサマリー作成支援に向けた会話記録のトピック分類,橋本和磨|北出祐|辻川剛範|久保雅洋,,Q10:ポスター
Q10-23,生成AIを用いた単語間における類推,田代寛治|村田真樹,,Q10:ポスター
Q10-24,埋め込みモデルベースの教師なしキーフレーズ抽出における長文に対する抽出精度の改善,藤原知樹,,Q10:ポスター
Q10-25,ニュース記事中の企業名のEntity LinkingにおけるQuestion Answeringを用いた曖昧性解消,齋藤慎一朗|髙橋寛治,,Q10:ポスター
