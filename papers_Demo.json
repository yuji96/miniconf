[{"abstract":"There are a growing number of table pre-training methods proposed for reasoning over tabular data (e.g., question answering, fact checking, and faithful text generation). However, most existing methods are benchmarked solely on a limited number of datasets, varying in configuration, which leads to a lack of unified, standardized, fair, and comprehensive comparison between methods. This paper presents OpenRT, the first open-source framework for reasoning over tabular data, to reproduce existing table pre-training models for performance comparison and develop new models quickly. We implemented and compared six table pre-training models on four question answering, one fact checking, and one faithful text generation datasets. Moreover, to enable the community to easily construct new table reasoning datasets, we developed TaRAT, an annotation tool which supports multi-person collaborative annotations for various kinds of table reasoning tasks. The researchers are able to deploy the newly-constructed dataset to OpenRT and compare the performances of different baseline systems.","anthology_url":"https://aclanthology.org/2023.acl-demo.32","authors":["Yilun Zhao","Boyu Mi","Zhenting Qi","Linyong Nan","Minghao Guo","Arman Cohan","Dragomir Radev"],"category":"Demo","demo_url":null,"display_track":"Information Extraction (demo)","event_ids":["demo-session-3_-information-extraction-(demo)-(poster)"],"id":"D89","is_paper":true,"keywords":[],"languages":[],"material":null,"paper_pdf":"https://aclanthology.org/2023.acl-demo.32.pdf","paper_type":"demo","poster_pdf":"https://assets.underline.io/lecture/78259/poster_document/5434aea21322285c28af9f6b133c5cf7.pdf","preview_image":"https://assets.underline.io/lecture/78259/poster/255a27020e55344a879d6484255e220b.jpg","program":"Demo","similar_paper_ids":[],"slides_pdf":null,"title":"[Demo] OpenRT: An Open-source Framework for Reasoning Over Tabular Data","tldr":"There are a growing number of table pre-training methods proposed for reasoning over tabular data (e.g., question answering, fact checking, and faithful text generation). However, most existing methods are benchmarked solely on a limited number of datasets, varying in configuration, which leads to a...","track":"Information Extraction (demo)","underline_id":78259,"underline_url":"https://underline.io/events/395/posters/15228/poster/78259-cross-lingual-amr-aligner-paying-attention-to-cross-attention","video_url":null}]
